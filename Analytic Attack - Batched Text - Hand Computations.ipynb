{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebef44a",
   "metadata": {},
   "source": [
    "# Breaching privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756fc5f",
   "metadata": {},
   "source": [
    "This notebook does the same job as the cmd-line tool `simulate_breach.py`, but also directly visualizes the user data and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b850eabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import breaching\n",
    "import logging, sys\n",
    "logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler(sys.stdout)], format='%(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "376ef846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5e214",
   "metadata": {},
   "source": [
    "### Initialize cfg object and system setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd663b",
   "metadata": {},
   "source": [
    "This will print out all configuration options. \n",
    "There are a lot of possible configurations, but there is usually no need to worry about most of these. Below, a few options are printed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26070d66",
   "metadata": {},
   "source": [
    "Choose `case/data=` `shakespeare`, `wikitext`over `stackoverflow` here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7dc3a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating use case single_imagenet with server type malicious_transformer_parameters.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'device': device(type='cpu'), 'dtype': torch.float32}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with hydra.initialize(config_path=\"config\"):\n",
    "    cfg = hydra.compose(config_name='cfg', overrides=[\"case/data=wikitext\", \"case/server=malicious-transformer\",\n",
    "                                                      \"case.model=transformer3p\",\n",
    "                                                      \"attack=decepticon\"])\n",
    "    print(f'Investigating use case {cfg.case.name} with server type {cfg.case.server.name}.')\n",
    "          \n",
    "device = torch.device(f'cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.backends.cudnn.benchmark = cfg.case.impl.benchmark\n",
    "setup = dict(device=device, dtype=torch.float)\n",
    "setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c5fb1",
   "metadata": {},
   "source": [
    "### Modify config options here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0764ef",
   "metadata": {},
   "source": [
    "You can use `.attribute` access to modify any of these configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac118ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.case.user.num_data_points = 8 # How many sentences?\n",
    "cfg.case.user.user_idx = 1 # From which user?\n",
    "cfg.case.data.shape = [16] # This is the sequence length\n",
    "\n",
    "cfg.case.data.tokenizer = \"word-level\"\n",
    "\n",
    "cfg.case.server.has_external_data = True\n",
    "\n",
    "cfg.case.server.param_modification.v_length = 6\n",
    "cfg.case.server.param_modification.imprint_sentence_position = 0\n",
    "cfg.case.server.param_modification.softmax_skew = 10000000\n",
    "cfg.case.server.param_modification.sequence_token_weight = 1\n",
    "\n",
    "cfg.case.server.param_modification.eps = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f64389",
   "metadata": {},
   "source": [
    "### Instantiate all parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30235b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "Model architecture transformer3p loaded with 10,751,281 parameters and 0 buffers.\n",
      "Overall this is a data ratio of   83994:1 for target shape [8, 16] given that num_queries=1.\n",
      "User (of type UserSingleStep) with settings:\n",
      "    Number of data points: 8\n",
      "\n",
      "    Threat model:\n",
      "    User provides labels: False\n",
      "    User provides buffers: False\n",
      "    User provides number of data points: True\n",
      "\n",
      "    Data:\n",
      "    Dataset: wikitext\n",
      "    user: 1\n",
      "    \n",
      "        \n",
      "Server (of type MaliciousTransformerServer) with settings:\n",
      "    Threat model: Malicious (Parameters)\n",
      "    Number of planned queries: 1\n",
      "    Has external/public data: True\n",
      "\n",
      "    Model:\n",
      "        model specification: transformer3p\n",
      "        model state: default\n",
      "        \n",
      "\n",
      "    Secrets: {}\n",
      "    \n",
      "Attacker (of type DecepticonAttacker).\n"
     ]
    }
   ],
   "source": [
    "user, server, model, loss_fn = breaching.cases.construct_case(cfg.case, setup)\n",
    "attacker = breaching.attacks.prepare_attack(server.model, server.loss, cfg.attack, setup)\n",
    "breaching.utils.overview(server, user, attacker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c0ad6",
   "metadata": {},
   "source": [
    "### Simulate an attacked FL protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058bcc2",
   "metadata": {},
   "source": [
    "True user data is returned only for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f997f972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([96, 1536])\n",
      "torch.Size([96, 1536])\n",
      "torch.Size([96, 1536])\n",
      "Computing feature distribution before the linear1 layer from external data.\n",
      "Feature mean is 0.183049738407135, feature std is 0.9330437779426575.\n"
     ]
    }
   ],
   "source": [
    "server_payload = server.distribute_payload()\n",
    "shared_data, true_user_data = user.compute_local_updates(server_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69c6ff1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] the tower building of the little rock arsenal, also known as u. s\n",
      ". arsenal building, is a building located in macarthur park in downtown little rock,\n",
      "arkansas. built in 1 8 4 0, it was part of little rock '\n",
      "s first military installation. since its decommissioning, the tower building has housed two museums\n",
      ". it was home to the arkansas museum of natural history and antiquities from 1 9\n",
      "4 2 to 1 9 9 7 and the macarthur museum of arkansas military history since\n",
      "2 0 0 1. it has also been the headquarters of the little rock [UNK]\n",
      "club since 1 8 9 4. [SEP] [CLS] the building receives its name from its\n"
     ]
    }
   ],
   "source": [
    "user.print(true_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73a3a26",
   "metadata": {},
   "source": [
    "## Run through the initial transformer blocks \"by hand\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8baebbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = true_user_data[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68891371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  4.7943e-01,\n",
       "          -9.4823e-02, -1.6600e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  6.1479e-01,\n",
       "           1.9321e-01,  3.4803e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  7.1997e-02,\n",
       "           7.6359e-01, -2.9553e-01],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.0644e-01,\n",
       "          -5.0040e-02,  1.4114e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.9372e-01,\n",
       "          -6.2184e-01, -8.4477e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  6.6921e-01,\n",
       "           2.0388e-01, -1.2414e-01]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  5.7615e-01,\n",
       "          -1.0311e-02, -1.6338e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  4.9967e-01,\n",
       "           4.5018e-02,  3.8816e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  2.0127e-02,\n",
       "           6.7603e-01, -3.5482e-01],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.3277e-01,\n",
       "          -3.9010e-02,  2.2634e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -3.0893e-01,\n",
       "          -6.5813e-01, -7.6797e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  6.3872e-01,\n",
       "           2.9541e-01, -4.5049e-02]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  5.3320e-01,\n",
       "          -1.4933e-02, -2.2171e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  6.1906e-01,\n",
       "           1.8098e-01,  3.5406e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  7.0577e-02,\n",
       "           7.1618e-01, -2.3954e-01],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.3277e-01,\n",
       "          -3.9010e-02,  2.2634e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -3.0893e-01,\n",
       "          -6.5813e-01, -7.6797e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  5.9179e-01,\n",
       "           3.3219e-01, -2.3761e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  4.6898e-01,\n",
       "           3.0687e-02, -1.7183e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  4.8282e-01,\n",
       "           1.9372e-01,  4.5748e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -7.1593e-02,\n",
       "           7.2826e-01, -3.4408e-01],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -8.4474e-02,\n",
       "          -2.0524e-01,  9.9474e-02],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -3.1199e-01,\n",
       "          -7.2633e-01, -7.7149e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  5.9604e-01,\n",
       "           1.8746e-01, -1.4656e-01]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  4.3991e-01,\n",
       "           2.4252e-03, -5.9959e-02],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  5.2568e-01,\n",
       "           2.0196e-01,  3.9783e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.6896e-02,\n",
       "           7.9087e-01, -2.6628e-01],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.3277e-01,\n",
       "          -3.9010e-02,  2.2634e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -3.0893e-01,\n",
       "          -6.5813e-01, -7.6797e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  5.0878e-01,\n",
       "           2.8407e-01, -8.8108e-02]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  5.8622e-01,\n",
       "          -5.0145e-02, -2.1106e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  5.4596e-01,\n",
       "           4.4301e-02,  3.3803e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  2.7164e-04,\n",
       "           7.9293e-01, -3.1538e-01],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -7.4675e-02,\n",
       "          -9.6123e-02,  1.1338e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -3.4904e-01,\n",
       "          -5.7950e-01, -7.2391e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  5.6162e-01,\n",
       "           3.4691e-01, -7.3681e-02]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trafo_inputs = user.model.pos_encoder(user.model.encoder(true_user_data[\"data\"]))#[0, 0, :]\n",
    "trafo_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09ae9fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0402,  0.0109, -0.0007,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0402,  0.0109, -0.0007,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0402,  0.0109, -0.0007,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0402,  0.0109, -0.0007,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0402,  0.0109, -0.0007,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0402,  0.0109, -0.0007,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0687,  0.0345, -0.0520,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0687,  0.0345, -0.0520,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0687,  0.0345, -0.0520,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [-0.0687,  0.0345, -0.0520,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0687,  0.0345, -0.0520,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0687,  0.0345, -0.0520,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0640, -0.0671, -0.0518,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0640, -0.0671, -0.0518,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0640, -0.0671, -0.0518,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [-0.0640, -0.0671, -0.0518,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0640, -0.0671, -0.0518,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0640, -0.0671, -0.0518,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0030,  0.0262, -0.0335,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0030,  0.0262, -0.0335,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0030,  0.0262, -0.0335,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [-0.0030,  0.0262, -0.0335,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0030,  0.0262, -0.0335,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0030,  0.0262, -0.0335,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0687,  0.0219, -0.0636,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0687,  0.0219, -0.0636,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0687,  0.0219, -0.0636,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [-0.0687,  0.0219, -0.0636,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0687,  0.0219, -0.0636,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0687,  0.0219, -0.0636,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0204,  0.0578,  0.0979,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0204,  0.0578,  0.0979,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0204,  0.0578,  0.0979,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [-0.0204,  0.0578,  0.0979,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0204,  0.0578,  0.0979,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0204,  0.0578,  0.0979,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_outputs, attn_weights = user.model.transformer_encoder.layers[0].self_attn(trafo_inputs, trafo_inputs, trafo_inputs)\n",
    "attn_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a599198c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1797, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547,\n",
       "         0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547],\n",
       "        [0.1797, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547,\n",
       "         0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547],\n",
       "        [0.1797, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547,\n",
       "         0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547],\n",
       "        [0.1797, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547,\n",
       "         0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547],\n",
       "        [0.1797, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547,\n",
       "         0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547],\n",
       "        [0.1797, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547,\n",
       "         0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547],\n",
       "        [0.1797, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547,\n",
       "         0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547],\n",
       "        [0.1797, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547,\n",
       "         0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547],\n",
       "        [0.1797, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547,\n",
       "         0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547],\n",
       "        [0.1797, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547,\n",
       "         0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547],\n",
       "        [0.1797, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547,\n",
       "         0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547],\n",
       "        [0.1797, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547,\n",
       "         0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547],\n",
       "        [0.1797, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547,\n",
       "         0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547],\n",
       "        [0.1797, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547,\n",
       "         0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547],\n",
       "        [0.1797, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547,\n",
       "         0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547],\n",
       "        [0.1797, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547,\n",
       "         0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56b8ab7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1770,  0.2280,\n",
       "         0.1074,  0.5431,  0.7669, -0.1483,  0.2076, -0.3055,  0.3640, -0.7401,\n",
       "        -0.5209, -0.1187,  0.1231, -0.4671, -0.1890,  0.2152, -0.3508, -0.0056,\n",
       "         0.6533,  0.1395,  0.7076, -0.1795,  0.2169,  0.4864, -1.0051, -0.3695,\n",
       "        -0.8945,  0.4070, -0.1487,  0.1361, -0.7375,  0.2543, -0.0372, -0.9370,\n",
       "        -0.1709, -0.6158, -0.6881, -0.3572, -0.0142, -0.5055,  0.1897, -0.6006,\n",
       "         0.1013,  0.2649,  0.5978,  0.1730, -0.2327,  0.7050,  0.7245, -1.0375,\n",
       "        -0.8151,  0.0318,  0.1363,  0.0388, -0.7223,  0.7262,  0.4783,  0.8711,\n",
       "        -0.0232, -0.0805, -0.5905,  0.5422, -0.1950, -0.7621, -0.5102,  0.2781,\n",
       "        -0.0736, -1.0784, -0.0466, -0.4237,  0.5858,  0.5966,  0.2962, -0.3502,\n",
       "         0.2835, -0.3872, -0.6417, -0.0093,  0.7894, -0.4822,  1.0927,  1.1332,\n",
       "        -1.0411, -0.2208,  0.4607, -0.1643,  0.8225,  0.7318, -0.0391,  0.0970],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pos_encoder.embedding.weight[511]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fcf9bca2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        , -0.09715469, -0.09715469, -0.09715469, -0.09715469,\n",
       "       -0.09715469, -0.09715469, -0.09715469, -0.09715469, -0.09715469,\n",
       "       -0.09715469, -0.09715469, -0.09715469, -0.09715469, -0.09715469,\n",
       "       -0.09715469, -0.09715469, -0.24021406, -0.24021406, -0.24021406,\n",
       "       -0.24021406, -0.24021406, -0.24021406, -0.24021406, -0.24021406,\n",
       "       -0.24021406, -0.24021406, -0.24021406, -0.24021406, -0.24021406,\n",
       "       -0.24021406, -0.24021406, -0.24021406,  0.3116914 ,  0.3116914 ,\n",
       "        0.3116914 ,  0.3116914 ,  0.3116914 ,  0.3116914 ,  0.3116914 ,\n",
       "        0.3116914 ,  0.3116914 ,  0.3116914 ,  0.3116914 ,  0.3116914 ,\n",
       "        0.3116914 ,  0.3116914 ,  0.3116914 ,  0.3116914 , -0.09715469,\n",
       "       -0.09715469, -0.09715469, -0.09715469, -0.09715469, -0.09715469,\n",
       "       -0.09715469, -0.09715469, -0.09715469, -0.09715469, -0.09715469,\n",
       "       -0.09715469, -0.09715469, -0.09715469, -0.09715469, -0.09715469,\n",
       "       -0.34041853, -0.34041853, -0.34041853, -0.34041853, -0.34041853,\n",
       "       -0.34041853, -0.34041853, -0.34041853, -0.34041853, -0.34041853,\n",
       "       -0.34041853, -0.34041853, -0.34041853, -0.34041853, -0.34041853,\n",
       "       -0.34041853,  0.11424818,  0.11424818,  0.11424818,  0.11424818,\n",
       "        0.11424818,  0.11424818,  0.11424818,  0.11424818,  0.11424818,\n",
       "        0.11424818,  0.11424818,  0.11424818,  0.11424818,  0.11424818,\n",
       "        0.11424818,  0.11424818, -0.09767041, -0.09767041, -0.09767041,\n",
       "       -0.09767041, -0.09767041, -0.09767041, -0.09767041, -0.09767041,\n",
       "       -0.09767041, -0.09767041, -0.09767041, -0.09767041, -0.09767041,\n",
       "       -0.09767041, -0.09767041, -0.09767041])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(attn_outputs.reshape(-1, 96).detach())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "63f5eb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.5663e-02, -3.6469e-02, -6.8974e-02,  ...,  1.2792e+00,\n",
       "          -3.3336e-01, -5.3323e-01],\n",
       "         [ 5.5545e-02, -3.1538e-02, -6.6002e-02,  ...,  1.7664e+00,\n",
       "           5.1123e-01,  9.7218e-01],\n",
       "         [ 2.5312e-02, -3.5248e-02, -5.9216e-02,  ...,  9.1242e-02,\n",
       "           1.5232e+00, -6.6974e-01],\n",
       "         ...,\n",
       "         [ 3.2307e-01,  2.1231e-01,  1.6847e-01,  ..., -6.1078e-01,\n",
       "          -1.8494e-02,  7.0549e-01],\n",
       "         [ 6.6977e-02,  7.0598e-03, -1.6653e-02,  ..., -6.1697e-01,\n",
       "          -1.2891e+00, -1.7458e+00],\n",
       "         [-1.5927e-01, -2.1453e-01, -2.3640e-01,  ...,  1.0292e+00,\n",
       "           1.5006e-01, -4.6968e-01]],\n",
       "\n",
       "        [[-2.6954e-01,  2.1861e-02, -2.2241e-01,  ...,  1.5514e+00,\n",
       "          -1.0458e-01, -5.3680e-01],\n",
       "         [-2.6254e-01,  4.8872e-02, -2.1218e-01,  ...,  1.4527e+00,\n",
       "           8.0709e-02,  1.1162e+00],\n",
       "         [-1.9883e-01,  1.7124e-02, -1.6390e-01,  ..., -1.2886e-02,\n",
       "           1.3597e+00, -7.9751e-01],\n",
       "         ...,\n",
       "         [-8.0954e-02,  3.0347e-01, -1.8780e-02,  ..., -6.9203e-01,\n",
       "           2.9751e-02,  1.0182e+00],\n",
       "         [-1.7390e-01,  3.7767e-02, -1.3967e-01,  ..., -6.6657e-01,\n",
       "          -1.3828e+00, -1.6081e+00],\n",
       "         [-3.4812e-01, -1.5263e-01, -3.1651e-01,  ...,  9.9204e-01,\n",
       "           3.4169e-01, -3.0327e-01]],\n",
       "\n",
       "        [[-2.3740e-01, -2.4598e-01, -2.0406e-01,  ...,  1.3986e+00,\n",
       "          -1.0309e-01, -6.6956e-01],\n",
       "         [-2.2155e-01, -2.3086e-01, -1.8539e-01,  ...,  1.8077e+00,\n",
       "           5.0616e-01,  1.0204e+00],\n",
       "         [-1.6502e-01, -1.7169e-01, -1.3915e-01,  ...,  1.2106e-01,\n",
       "           1.4939e+00, -5.3837e-01],\n",
       "         ...,\n",
       "         [-5.9637e-02, -7.1317e-02, -1.4277e-02,  ..., -6.8888e-01,\n",
       "           3.3366e-02,  1.0225e+00],\n",
       "         [-1.6213e-01, -1.6856e-01, -1.3717e-01,  ..., -6.6455e-01,\n",
       "          -1.3808e+00, -1.6060e+00],\n",
       "         [-3.5413e-01, -3.6001e-01, -3.3130e-01,  ...,  8.7631e-01,\n",
       "           3.8920e-01, -2.7870e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-8.0837e-02,  1.5598e-03, -1.6654e-01,  ...,  1.2490e+00,\n",
       "           1.4191e-02, -5.5633e-01],\n",
       "         [-4.4032e-02,  4.4986e-02, -1.3663e-01,  ...,  1.4347e+00,\n",
       "           5.5484e-01,  1.3576e+00],\n",
       "         [-5.1163e-02,  9.9868e-03, -1.1477e-01,  ..., -1.9448e-01,\n",
       "           1.4778e+00, -7.6419e-01],\n",
       "         ...,\n",
       "         [ 1.5172e-01,  2.5994e-01,  3.9161e-02,  ..., -1.4957e-01,\n",
       "          -5.9639e-01,  5.3104e-01],\n",
       "         [-1.9965e-03,  5.8485e-02, -6.4908e-02,  ..., -6.4088e-01,\n",
       "          -1.4977e+00, -1.5911e+00],\n",
       "         [-2.3321e-01, -1.7823e-01, -2.9040e-01,  ...,  8.9293e-01,\n",
       "           1.2489e-01, -5.0299e-01]],\n",
       "\n",
       "        [[-2.7025e-01, -1.8381e-02, -2.5606e-01,  ...,  1.1440e+00,\n",
       "          -7.2471e-02, -2.4594e-01],\n",
       "         [-2.6651e-01,  5.2032e-03, -2.5121e-01,  ...,  1.5165e+00,\n",
       "           5.4541e-01,  1.1330e+00],\n",
       "         [-2.0117e-01, -1.1006e-02, -1.9046e-01,  ..., -9.2408e-02,\n",
       "           1.6034e+00, -6.1597e-01],\n",
       "         ...,\n",
       "         [-8.9718e-02,  2.4734e-01, -7.0736e-02,  ..., -7.0024e-01,\n",
       "           2.0763e-02,  1.0082e+00],\n",
       "         [-1.7883e-01,  7.0084e-03, -1.6837e-01,  ..., -6.7171e-01,\n",
       "          -1.3882e+00, -1.6136e+00],\n",
       "         [-3.6874e-01, -1.9690e-01, -3.5906e-01,  ...,  7.2684e-01,\n",
       "           3.0053e-01, -4.0556e-01]],\n",
       "\n",
       "        [[-1.1279e-01,  1.0582e-01,  2.1804e-01,  ...,  1.5839e+00,\n",
       "          -1.9609e-01, -6.4619e-01],\n",
       "         [-1.1587e-01,  1.2051e-01,  2.4186e-01,  ...,  1.5970e+00,\n",
       "           7.9705e-02,  9.6812e-01],\n",
       "         [-9.7581e-02,  6.5254e-02,  1.4885e-01,  ..., -5.4590e-02,\n",
       "           1.5969e+00, -7.1223e-01],\n",
       "         ...,\n",
       "         [ 1.0876e-01,  4.1029e-01,  5.6509e-01,  ..., -1.0078e-01,\n",
       "          -1.8352e-01,  6.2476e-01],\n",
       "         [-6.1072e-02,  1.0388e-01,  1.8856e-01,  ..., -7.5477e-01,\n",
       "          -1.2412e+00, -1.5460e+00],\n",
       "         [-2.6232e-01, -1.1348e-01, -3.7066e-02,  ...,  8.4604e-01,\n",
       "           4.3713e-01, -3.6386e-01]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals = attn_outputs + trafo_inputs\n",
    "linear_inputs = user.model.transformer_encoder.layers[0].norm1(residuals)\n",
    "linear_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7179f21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.5663e-02, -3.6469e-02, -6.8974e-02, -9.9637e-03,  2.0062e-01,\n",
       "         -9.3716e-02,  4.8927e-01, -1.4520e+00],\n",
       "        [ 5.5545e-02, -3.1538e-02, -6.6002e-02, -3.4350e-03,  2.1984e-01,\n",
       "         -9.2236e-02, -2.4198e-01,  6.3667e-01],\n",
       "        [ 2.5312e-02, -3.5248e-02, -5.9216e-02, -1.5704e-02,  1.3957e-01,\n",
       "         -7.7459e-02, -4.0289e-01, -1.3720e+00],\n",
       "        [-3.0242e-02, -1.2270e-01, -1.5928e-01, -9.2859e-02,  1.4418e-01,\n",
       "         -1.8714e-01,  1.2675e+00,  3.8573e-01],\n",
       "        [ 1.5114e-01,  8.1710e-02,  5.4231e-02,  1.0412e-01,  2.8213e-01,\n",
       "          3.3315e-02,  6.7414e-02, -6.3159e-01],\n",
       "        [ 7.7029e-02,  1.6085e-02, -8.0334e-03,  3.5753e-02,  1.9201e-01,\n",
       "         -2.6393e-02, -1.2966e+00, -1.0135e+00],\n",
       "        [ 5.4249e-03, -4.3135e-02, -6.2353e-02, -2.7464e-02,  9.7039e-02,\n",
       "         -7.6982e-02, -1.6991e-01,  3.5393e-01],\n",
       "        [ 4.3760e-02,  2.7011e-04, -1.6941e-02,  1.4305e-02,  1.2581e-01,\n",
       "         -3.0043e-02,  1.3899e-01, -5.3577e-02],\n",
       "        [ 5.1909e-03, -8.4883e-02, -1.2053e-01, -5.5815e-02,  1.7513e-01,\n",
       "         -1.4767e-01, -1.9635e+00, -9.4350e-01],\n",
       "        [ 1.3631e-01,  6.4094e-02,  3.5512e-02,  8.7401e-02,  2.7257e-01,\n",
       "          1.3756e-02,  1.8940e+00, -2.6318e-01],\n",
       "        [ 1.8053e-01,  1.0206e-01,  7.1002e-02,  1.2738e-01,  3.2858e-01,\n",
       "          4.7361e-02, -1.1896e+00,  5.8191e-01],\n",
       "        [ 1.1535e-01, -1.2342e-03, -4.7372e-02,  3.6389e-02,  3.3529e-01,\n",
       "         -8.2492e-02, -8.3684e-01, -2.8623e+00],\n",
       "        [ 1.9039e-01,  1.4358e-01,  1.2506e-01,  1.5869e-01,  2.7869e-01,\n",
       "          1.1096e-01,  4.8764e-01, -7.6393e-01],\n",
       "        [ 3.2307e-01,  2.1231e-01,  1.6847e-01,  2.4805e-01,  5.3204e-01,\n",
       "          1.3510e-01,  9.1328e-01,  6.9311e-01],\n",
       "        [ 6.6977e-02,  7.0598e-03, -1.6653e-02,  2.6396e-02,  1.8002e-01,\n",
       "         -3.4703e-02,  1.8670e-01,  1.2204e+00],\n",
       "        [-1.5927e-01, -2.1453e-01, -2.3640e-01, -1.9669e-01, -5.5013e-02,\n",
       "         -2.5304e-01, -3.6543e-01,  5.7267e-01]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_inputs[0, :, 0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68914402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 96])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445a8b0f",
   "metadata": {},
   "source": [
    "### Simulate breached features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afc50937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 31, 20, 12,  2, 15, 30, 25,  8, 27, 28,  3, 17, 22,  9, 16, 19,  6,\n",
       "         4, 14, 21, 10, 11,  1, 13,  5, 24, 18, 23, 26, 29,  7])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation = torch.randperm(32) # torch.randperm(32) # torch.arange(32)\n",
    "num_breached_embeddings = 20\n",
    "reverse_perm = torch.argsort(permutation[:num_breached_embeddings])\n",
    "permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d168faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 8])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_features = linear_inputs.permute(0, 1, 2).reshape(-1, 96)[:, :8][permutation][:num_breached_embeddings]\n",
    "seq_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee87d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = torch.as_tensor(np.corrcoef(seq_features.detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "60dda8bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3\n",
      "1 1\n",
      "2 3\n",
      "4 1\n",
      "5 2\n",
      "6 2\n",
      "7 2\n",
      "8 1\n",
      "9 1\n",
      "11 1\n",
      "12 1\n",
      "16 1\n",
      "18 1\n",
      "19 1\n"
     ]
    }
   ],
   "source": [
    "group_dict = dict()\n",
    "num_groups = 0\n",
    "seen = set()\n",
    "for i in range(corrs.shape[0]):\n",
    "    if i not in seen:\n",
    "        flag = corrs[i].argmax()\n",
    "        # What threshhold to pick here? there should be a better way?\n",
    "        new_group = (corrs[i] >= 0.98).nonzero().tolist()\n",
    "        print(i, len(new_group))\n",
    "        new_group = [x[0] for x in new_group]\n",
    "        if flag in group_dict:\n",
    "            group_num = corrs[flag]\n",
    "        else:\n",
    "            group_num = num_groups\n",
    "            num_groups += 1\n",
    "        for x in new_group:\n",
    "            group_dict[x] = group_num\n",
    "            seen.add(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e8b429c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10,  1, 15, 10,  4, 17, 13, 14,  8,  9, 15, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape= [cfg.case.user.num_data_points, cfg.case.data.shape[0]]\n",
    "sentence_labels = -torch.ones(corrs.shape[0], dtype=torch.long)\n",
    "already_assigned = set()\n",
    "for idx in range(corrs.shape[0]):\n",
    "    if idx not in already_assigned:\n",
    "        matches = (corrs[idx] >= 0.98).nonzero().squeeze(0)\n",
    "\n",
    "        if len(matches) > 0:\n",
    "            filtered_matches = torch.as_tensor([m for m in matches if m not in already_assigned])\n",
    "            if len(filtered_matches) > shape[1]:\n",
    "                filtered_matches = corrs[idx][filtered_matches].topk(k=shape[1]).indices\n",
    "            sentence_labels[filtered_matches] = idx\n",
    "sentence_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2867bcc",
   "metadata": {},
   "source": [
    "# Reconstruct user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "064adced",
   "metadata": {},
   "outputs": [],
   "source": [
    "attacker.cfg.sentence_algorithm = \"k-means\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e7caae75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] the tower building of the little rock arsenal, also known as u. s\n",
      ". arsenal building, is a building located in macarthur park in downtown little rock,\n",
      "arkansas. built in 1 8 4 0, it was part of little rock '\n",
      "s first military installation. since its decommissioning, the tower building has housed two museums\n",
      ". it was home to the arkansas museum of natural history and antiquities from 1 9\n",
      "4 2 to 1 9 9 7 and the macarthur museum of arkansas military history since\n",
      "2 0 0 1. it has also been the headquarters of the little rock [UNK]\n",
      "club since 1 8 9 4. [SEP] [CLS] the building receives its name from its\n"
     ]
    }
   ],
   "source": [
    "user.print(true_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6be88654",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens [[0, 1, 2, 5, 6, 7, 8, 10, 11, 12, 14, 16, 17, 19, 22, 25], [26, 29, 31, 32, 35, 38, 40, 43, 50, 56, 62, 63, 64, 72, 108, 184], [291, 310, 400, 494, 566, 652, 846, 926, 940, 993, 1084, 1495, 1936, 2195, 2971, 3688], [5, 5, 5, 5, 649, 5231, 5470, 6084, 6489, 8107, 8323, 18637, 21489, 21964, 22724, 24378], [5, 5, 6, 6, 7, 7, 11, 11, 11, 19, 22, 22, 566, 1084, 1084, 1936], [5, 6, 6, 7, 11, 12, 17, 19, 22, 31, 35, 291, 566, 1084, 1084, 1936], [7, 8, 12, 14, 17, 19, 22, 31, 35, 38, 40, 43, 291, 566, 1936, 18637], [5, 6, 7, 11, 19, 22, 50, 62, 310, 494, 652, 846, 1084, 3688, 6084, 6489]] through strategy decoder-bias.\n",
      "Recovered 121 embeddings with positional data from imprinted layer.\n",
      "Assigned [15, 16, 15, 14, 15, 15, 16, 15] breached embeddings to each sentence.\n",
      "tensor([0.3583, 0.6902, 0.7893, 0.6761, 0.4612, 0.6772, 0.4425, 0.5698, 0.5027,\n",
      "        0.5639, 0.7018, 0.5728, 0.5799, 0.4100, 0.5101])\n",
      "tensor([0.3583, 0.6148, 0.7827, 0.5703, 0.8136, 0.6303, 0.4672, 0.7771, 0.0325,\n",
      "        0.7018, 0.4810, 0.4100, 0.5434, 0.6238, 0.4888, 0.6827])\n",
      "tensor([0.5044, 0.4118, 0.4888, 0.7776, 0.7381, 0.7441, 0.6345, 0.5223, 0.7018,\n",
      "        0.6074, 0.6659, 0.4100, 0.5252, 0.6175, 0.4688])\n",
      "tensor([0.5830, 0.5353, 0.4844, 0.5703, 0.7256, 0.8141, 0.4498, 0.5144, 0.5928,\n",
      "        0.4379, 0.7274, 0.2657, 0.4107, 0.6137])\n",
      "tensor([0.5809, 0.7833, 0.5744, 0.2148, 0.4100, 0.4743, 0.5674, 0.5975, 0.7860,\n",
      "        0.6341, 0.5902, 0.6671, 0.4507, 0.4688, 0.4528])\n",
      "tensor([0.5878, 0.4480, 0.3583, 0.7255, 0.6183, 0.5681, 0.4596, 0.6891, 0.6620,\n",
      "        0.7720, 0.5223, 0.8008, 0.4135, 0.4888, 0.4264])\n",
      "tensor([0.0919, 0.5814, 0.5154, 0.3971, 0.7577, 0.4519, 0.7309, 0.6068, 0.5034,\n",
      "        0.5975, 0.6738, 0.7087, 0.8001, 0.5157, 0.5674, 0.3698])\n",
      "tensor([0.7993, 0.4915, 0.7274, 0.6148, 0.5093, 0.5027, 0.5703, 0.6264, 0.4425,\n",
      "        0.2689, 0.7603, 0.5526, 0.6645, 0.6279, 0.6482])\n",
      "METRICS: | Accuracy: 0.4688 | S-BLEU: 0.84 | FMSE: 2.2783e-01 | \n",
      " G-BLEU: 0.81 | ROUGE1: 0.63| ROUGE2: 0.44 | ROUGE-L: 0.59| Token Acc: 95.31% | Label Acc: 95.31%\n",
      ". arsenal building, is a building located in macarthur park in downtown little rock museums\n",
      "1 the tower building of the little rock arsenal, also known as u, since\n",
      ", 0 0 1. it has also been the headquarters of the little rock 9\n",
      "s first military installation the since its decommissioning, the tower [UNK] has housed two building\n",
      ". it was home to the 9 museum of natural history and antiquities from 1 9\n",
      "4 2 to 1 9 9 7 and the macarthur museum of arkansas military history its\n",
      "arkansas. built in 1 8 4 0, it was part of little rock of\n",
      "club since 1 8. '. [SEP] [CLS] the building receives its name from building\n"
     ]
    }
   ],
   "source": [
    "reconstructed_user_data, stats = attacker.reconstruct([server_payload], [shared_data], \n",
    "                                                      server.secrets, dryrun=cfg.dryrun)\n",
    "\n",
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "                                    server.model, cfg_case=cfg.case, setup=setup)\n",
    "user.print(reconstructed_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0421b9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'order': tensor([7, 0, 5, 1, 3, 2, 4, 6]),\n",
       " 'intra-sentence_token_acc': [0.5,\n",
       "  0.125,\n",
       "  0.9375,\n",
       "  0.3125,\n",
       "  0.0625,\n",
       "  0.9375,\n",
       "  0.1875,\n",
       "  0.3125],\n",
       " 'accuracy': 0.25,\n",
       " 'bleu': 0.8120457916499574,\n",
       " 'google_bleu': 0.7924528301886793,\n",
       " 'sacrebleu': 0.8127906204345446,\n",
       " 'rouge1': 0.3904647435897436,\n",
       " 'rouge2': 0.2814102564102564,\n",
       " 'rougeL': 0.3418161121286122,\n",
       " 'token_acc': 0.953125,\n",
       " 'feat_mse': 0.28205350041389465,\n",
       " 'parameters': 10751281,\n",
       " 'label_acc': 0.953125}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedbe36c",
   "metadata": {},
   "source": [
    "# Manually compute attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "6a20fb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.8122,  0.4188, -0.2031],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.4060,  0.5875, -0.1769],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ..., -0.8559,  0.0129, -0.5893],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0184,  0.1439,  0.6559],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.2084,  1.1975,  0.0657],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  1.3845, -0.1595, -1.0408]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inputs = user.model.pos_encoder(user.model.encoder(inputs))\n",
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b7c6afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = user.model.transformer_encoder.layers[0].self_attn.in_proj_weight[:96, :]\n",
    "K = user.model.transformer_encoder.layers[0].self_attn.in_proj_weight[96:192, :]\n",
    "V = user.model.transformer_encoder.layers[0].self_attn.in_proj_weight[192:, :]\n",
    "q_b = user.model.transformer_encoder.layers[0].self_attn.in_proj_bias[:96]\n",
    "k_b = user.model.transformer_encoder.layers[0].self_attn.in_proj_bias[96:192]\n",
    "v_b = user.model.transformer_encoder.layers[0].self_attn.in_proj_bias[192:]\n",
    "\n",
    "O =  user.model.transformer_encoder.layers[0].self_attn.out_proj.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d5f24bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f8162026",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_attn = user.model.transformer_encoder.layers[0].self_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3307b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_attn.batch_first = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "96cf1602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([96, 96]),\n",
       " torch.Size([96, 16]),\n",
       " torch.Size([96, 96]),\n",
       " torch.Size([96, 96]),\n",
       " torch.Size([96]))"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.shape, inputs[0].T.shape, V.shape, K.shape, q_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "74baa641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 96])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3b8305fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qv = ((Q@inputs[0].T).T + q_b)\n",
    "Kv = ((K@inputs[0].T).T + k_b)\n",
    "Vv = ((V@inputs[0].T).T + v_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "9e175119",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (16) must match the size of tensor b (12) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1518333/1244661700.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mQv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mKv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (16) must match the size of tensor b (12) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "M = (Qv.reshape(16, 8, 12) @ Kv.reshape(16, 8, 12).T).softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "09385670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b3392821",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_map = torch.zeros(16, 16)\n",
    "for head in range(8):\n",
    "    mapp = (Qv.reshape(16, 8, 12)[:, head, :] @ Kv.reshape(16, 8, 12)[:, head, :].T).softmax(dim=-1)\n",
    "    attn_map += mapp\n",
    "    print(mapp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d3242f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([       0.0000,        0.0000,        0.0000,        0.0000,\n",
       "               0.0000,        0.0000,  9107805.0000,  6274965.0000,\n",
       "         2448828.7500,  -319700.9375, -4172115.0000,  -920698.5625],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qv.reshape(16, 8, 12)[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "275eac82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.3070,  0.3718, -0.3866,  0.2660,  0.8883, -0.1823, -0.1444,  0.6259,\n",
       "          1.0129,  0.7975,  0.2791,  0.2966,  0.6264, -0.3569,  1.7803, -1.2690],\n",
       "        [-0.6594, -2.2490, -1.2219, -1.9452,  0.6079,  1.7571,  1.2826,  1.0593,\n",
       "         -0.1973,  0.2317, -0.9088, -0.0448, -1.6864, -2.6321, -0.9576, -1.2157],\n",
       "        [ 1.6457, -0.6931, -0.2091, -1.8263,  0.1936, -0.2423, -1.6548,  1.1576,\n",
       "          0.4159,  0.0619,  0.7779,  1.4380,  0.7446,  2.1674,  0.8678, -0.8043],\n",
       "        [ 0.1517,  0.2099,  1.6327,  0.0994,  0.0464, -0.4813,  0.6097, -0.8296,\n",
       "         -0.0744,  0.7920,  0.3962,  2.2693,  1.2400,  0.9013,  0.3836,  0.8098],\n",
       "        [ 0.5467, -1.7634, -1.3807, -1.0486, -0.4548,  0.6929,  0.4848, -0.3379,\n",
       "         -0.1568,  0.5202,  0.9070, -0.9440,  0.3003,  0.0761, -0.1952,  0.4876],\n",
       "        [-1.5142, -0.9564,  0.6844, -0.8599, -0.0759,  2.0821,  0.5243, -1.5710,\n",
       "          0.1715,  0.2949,  0.2696,  0.3965, -0.3586,  1.6654,  0.1763, -0.9695]],\n",
       "       grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kv.reshape(16, 8, 12)[:, 0, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f6d9d74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7530e+06, -4.2532e+06, -7.0920e+06, -9.1211e+06,  1.4331e+07,\n",
       "          4.1181e+06, -1.8958e+04,  1.8304e+07,  9.5259e+06,  6.1742e+06,\n",
       "         -5.4148e+06,  8.7899e+06, -4.3724e+06, -1.6599e+07,  1.2860e+07,\n",
       "         -2.2557e+07],\n",
       "        [ 1.7530e+06, -4.2532e+06, -7.0920e+06, -9.1211e+06,  1.4331e+07,\n",
       "          4.1181e+06, -1.8958e+04,  1.8304e+07,  9.5259e+06,  6.1742e+06,\n",
       "         -5.4148e+06,  8.7899e+06, -4.3724e+06, -1.6599e+07,  1.2860e+07,\n",
       "         -2.2557e+07],\n",
       "        [ 1.7530e+06, -4.2532e+06, -7.0920e+06, -9.1211e+06,  1.4331e+07,\n",
       "          4.1181e+06, -1.8958e+04,  1.8304e+07,  9.5259e+06,  6.1742e+06,\n",
       "         -5.4148e+06,  8.7899e+06, -4.3724e+06, -1.6599e+07,  1.2860e+07,\n",
       "         -2.2557e+07],\n",
       "        [ 1.7530e+06, -4.2532e+06, -7.0920e+06, -9.1211e+06,  1.4331e+07,\n",
       "          4.1181e+06, -1.8958e+04,  1.8304e+07,  9.5259e+06,  6.1742e+06,\n",
       "         -5.4148e+06,  8.7899e+06, -4.3724e+06, -1.6599e+07,  1.2860e+07,\n",
       "         -2.2557e+07],\n",
       "        [ 1.7530e+06, -4.2532e+06, -7.0920e+06, -9.1211e+06,  1.4331e+07,\n",
       "          4.1181e+06, -1.8958e+04,  1.8304e+07,  9.5259e+06,  6.1742e+06,\n",
       "         -5.4148e+06,  8.7899e+06, -4.3724e+06, -1.6599e+07,  1.2860e+07,\n",
       "         -2.2557e+07],\n",
       "        [ 1.7530e+06, -4.2532e+06, -7.0920e+06, -9.1211e+06,  1.4331e+07,\n",
       "          4.1181e+06, -1.8958e+04,  1.8304e+07,  9.5259e+06,  6.1742e+06,\n",
       "         -5.4148e+06,  8.7899e+06, -4.3724e+06, -1.6599e+07,  1.2860e+07,\n",
       "         -2.2557e+07],\n",
       "        [ 1.7530e+06, -4.2532e+06, -7.0920e+06, -9.1211e+06,  1.4331e+07,\n",
       "          4.1181e+06, -1.8958e+04,  1.8304e+07,  9.5259e+06,  6.1742e+06,\n",
       "         -5.4148e+06,  8.7899e+06, -4.3724e+06, -1.6599e+07,  1.2860e+07,\n",
       "         -2.2557e+07],\n",
       "        [ 1.7530e+06, -4.2532e+06, -7.0920e+06, -9.1211e+06,  1.4331e+07,\n",
       "          4.1181e+06, -1.8958e+04,  1.8304e+07,  9.5259e+06,  6.1742e+06,\n",
       "         -5.4148e+06,  8.7899e+06, -4.3724e+06, -1.6599e+07,  1.2860e+07,\n",
       "         -2.2557e+07],\n",
       "        [ 1.7530e+06, -4.2532e+06, -7.0920e+06, -9.1211e+06,  1.4331e+07,\n",
       "          4.1181e+06, -1.8958e+04,  1.8304e+07,  9.5259e+06,  6.1742e+06,\n",
       "         -5.4148e+06,  8.7899e+06, -4.3724e+06, -1.6599e+07,  1.2860e+07,\n",
       "         -2.2557e+07],\n",
       "        [ 1.7530e+06, -4.2532e+06, -7.0920e+06, -9.1211e+06,  1.4331e+07,\n",
       "          4.1181e+06, -1.8958e+04,  1.8304e+07,  9.5259e+06,  6.1742e+06,\n",
       "         -5.4148e+06,  8.7899e+06, -4.3724e+06, -1.6599e+07,  1.2860e+07,\n",
       "         -2.2557e+07],\n",
       "        [ 1.7530e+06, -4.2532e+06, -7.0920e+06, -9.1211e+06,  1.4331e+07,\n",
       "          4.1181e+06, -1.8958e+04,  1.8304e+07,  9.5259e+06,  6.1742e+06,\n",
       "         -5.4148e+06,  8.7899e+06, -4.3724e+06, -1.6599e+07,  1.2860e+07,\n",
       "         -2.2557e+07],\n",
       "        [ 1.7530e+06, -4.2532e+06, -7.0920e+06, -9.1211e+06,  1.4331e+07,\n",
       "          4.1181e+06, -1.8958e+04,  1.8304e+07,  9.5259e+06,  6.1742e+06,\n",
       "         -5.4148e+06,  8.7899e+06, -4.3724e+06, -1.6599e+07,  1.2860e+07,\n",
       "         -2.2557e+07],\n",
       "        [ 1.7530e+06, -4.2532e+06, -7.0920e+06, -9.1211e+06,  1.4331e+07,\n",
       "          4.1181e+06, -1.8958e+04,  1.8304e+07,  9.5259e+06,  6.1742e+06,\n",
       "         -5.4148e+06,  8.7899e+06, -4.3724e+06, -1.6599e+07,  1.2860e+07,\n",
       "         -2.2557e+07],\n",
       "        [ 1.7530e+06, -4.2532e+06, -7.0920e+06, -9.1211e+06,  1.4331e+07,\n",
       "          4.1181e+06, -1.8958e+04,  1.8304e+07,  9.5259e+06,  6.1742e+06,\n",
       "         -5.4148e+06,  8.7899e+06, -4.3724e+06, -1.6599e+07,  1.2860e+07,\n",
       "         -2.2557e+07],\n",
       "        [ 1.7530e+06, -4.2532e+06, -7.0920e+06, -9.1211e+06,  1.4331e+07,\n",
       "          4.1181e+06, -1.8958e+04,  1.8304e+07,  9.5259e+06,  6.1742e+06,\n",
       "         -5.4148e+06,  8.7899e+06, -4.3724e+06, -1.6599e+07,  1.2860e+07,\n",
       "         -2.2557e+07],\n",
       "        [ 1.7530e+06, -4.2532e+06, -7.0920e+06, -9.1211e+06,  1.4331e+07,\n",
       "          4.1181e+06, -1.8958e+04,  1.8304e+07,  9.5259e+06,  6.1742e+06,\n",
       "         -5.4148e+06,  8.7899e+06, -4.3724e+06, -1.6599e+07,  1.2860e+07,\n",
       "         -2.2557e+07]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qv @ Kv.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "26129e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3070, -0.6594,  1.6457,  0.1517, -0.3641, -2.1417, -0.2449,  0.0320,\n",
       "         0.4172,  0.0921,  0.0000,  0.0000], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vv.reshape(16, 8, 12)[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1b68af05",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x16 and 8x12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1518333/2994640537.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mKv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mVv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x16 and 8x12)"
     ]
    }
   ],
   "source": [
    "(((Qv.reshape(16, 8, 12)[:, head, :] @ Kv.reshape(16, 8, 12)[:, head, :].T).softmax(dim=-1) @ Vv.reshape(16, 8, 12)[:, head, :])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3c0455da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Qv.reshape(16, 8, 12)[:, head, :] @ Kv.reshape(16, 8, 12)[:, head, :].T).softmax(dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b5f2db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, attn_outputs = self_attn(inputs, inputs, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "79614b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.8750, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.8750, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.8750, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.8750, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.8750, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.8750, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.8750, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.8750, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.8750, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.8750, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.8750, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.8750, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.8750, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.8750, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.8750, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.8750, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "81416200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.4727,  1.0941, -1.7501,  ...,  0.9189, -1.3061,  1.7540],\n",
       "         [ 1.4291,  1.0808, -1.5362,  ..., -1.3048, -0.0021, -0.4693],\n",
       "         [ 1.1662,  0.8427, -1.5879,  ...,  0.0426,  0.6857, -1.4162],\n",
       "         ...,\n",
       "         [ 1.5034,  1.1219, -1.7438,  ...,  0.5844, -1.8480,  0.5581],\n",
       "         [ 1.4337,  1.0777, -1.5964,  ..., -1.5132, -0.4092, -0.0043],\n",
       "         [ 1.4806,  1.1188, -1.5993,  ..., -1.1123, -0.9756, -1.4105]],\n",
       "\n",
       "        [[ 1.4700,  1.1464, -1.7656,  ...,  0.7979, -1.3338,  1.8512],\n",
       "         [ 1.4463,  1.1483, -1.5345,  ..., -1.2155,  0.0200, -0.5267],\n",
       "         [ 1.1768,  0.8996, -1.5947,  ...,  0.1699,  0.7308, -1.5538],\n",
       "         ...,\n",
       "         [ 1.5107,  1.1851, -1.7453,  ...,  0.5372, -1.7618,  0.4430],\n",
       "         [ 1.4421,  1.1386, -1.5935,  ..., -1.3600, -0.4224, -0.1168],\n",
       "         [ 1.4880,  1.1801, -1.5911,  ..., -1.1316, -0.9726, -1.2776]],\n",
       "\n",
       "        [[ 0.3724,  1.0343, -1.1759,  ...,  0.8789, -1.4866,  1.8370],\n",
       "         [ 0.4205,  1.0310, -1.0074,  ..., -1.4300,  0.1233, -0.4934],\n",
       "         [ 0.2395,  0.8028, -1.0780,  ...,  0.1066,  0.7563, -1.4887],\n",
       "         ...,\n",
       "         [ 0.4078,  1.0792, -1.1627,  ...,  0.5422, -1.8211,  0.4453],\n",
       "         [ 0.4131,  1.0366, -1.0452,  ..., -1.4017, -0.4418, -0.1290],\n",
       "         [ 0.4559,  1.0882, -1.0229,  ..., -1.0189, -1.0334, -1.3832]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.3958,  1.0078, -1.7041,  ...,  0.9030, -1.3756,  1.7434],\n",
       "         [ 1.3880,  1.0262, -1.5033,  ..., -1.4047,  0.0777, -0.5978],\n",
       "         [ 1.1104,  0.7799, -1.5305,  ...,  0.1467,  0.6439, -1.4551],\n",
       "         ...,\n",
       "         [ 1.4498,  1.0587, -1.6756,  ...,  0.6894, -1.8193,  0.4566],\n",
       "         [ 1.3969,  1.0269, -1.5594,  ..., -1.5107, -0.4284, -0.0675],\n",
       "         [ 1.4466,  1.0735, -1.5344,  ..., -1.1662, -0.9815, -1.3123]],\n",
       "\n",
       "        [[ 1.3566,  1.1645, -1.7514,  ...,  0.7936, -1.3871,  1.7194],\n",
       "         [ 1.3599,  1.1807, -1.5400,  ..., -1.3383,  0.0481, -0.5760],\n",
       "         [ 1.0813,  0.9183, -1.5559,  ...,  0.0851,  0.6783, -1.4934],\n",
       "         ...,\n",
       "         [ 1.3901,  1.1965, -1.7422,  ...,  0.5387, -1.7594,  0.4445],\n",
       "         [ 1.3298,  1.1493, -1.5907,  ..., -1.3580, -0.4207, -0.1152],\n",
       "         [ 1.3729,  1.1910, -1.5700,  ..., -1.1131, -1.0024, -1.3805]],\n",
       "\n",
       "        [[ 1.5244,  1.0133, -1.5842,  ...,  0.9781, -1.4110,  1.7525],\n",
       "         [ 1.5079,  1.0314, -1.3907,  ..., -1.3851,  0.1430, -0.5409],\n",
       "         [ 1.2168,  0.7803, -1.4381,  ...,  0.0267,  0.6803, -1.4693],\n",
       "         ...,\n",
       "         [ 1.5760,  1.0577, -1.5769,  ...,  0.6941, -1.7309,  0.4822],\n",
       "         [ 1.5046,  1.0219, -1.4316,  ..., -1.4388, -0.4527, -0.0148],\n",
       "         [ 1.5672,  1.0714, -1.4485,  ..., -1.0820, -0.9967, -1.3399]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user.model.transformer_encoder.layers[0].norm1(outputs + inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f84345",
   "metadata": {},
   "outputs": [],
   "source": [
    "normy = torch.nn.LayerNorm(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367c70d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2, 1, 2], [5, 5, 5, 5], [7, 7,7, 7]]).float()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11683d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "normy(a[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7fc42b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749a4e1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.in_proj_bias[:96].pe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbbf2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, attn_weights = model(inputs, inputs, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcbaa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17c4ffdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens [[1, 5, 5, 6, 7, 11, 16, 29, 72, 494, 566, 846, 940, 1084, 1936, 6084]] through strategy decoder-bias.\n",
      "Recovered 17 embeddings with positional data from imprinted layer.\n",
      "the the arsenal of u little tower [CLS] s. also, known building as rock\n",
      "METRICS: | Accuracy: 0.1250 | S-BLEU: 0.13 | FMSE: 6.3067e-08 | \n",
      " G-BLEU: 0.30 | ROUGE1: 1.00| ROUGE2: 0.08 | ROUGE-L: 0.43| Token Acc: 100.00% | Label Acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "reconstructed_user_data, stats = attacker.reconstruct_single_sentence([server_payload], [shared_data], \n",
    "                                                      server.secrets, dryrun=cfg.dryrun)\n",
    "user.print(reconstructed_user_data)\n",
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "                                    server.model, cfg_case=cfg.case, setup=setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63300a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens [[1, 5, 5, 6, 7, 11, 16, 29, 72, 494, 566, 846, 940, 1084, 1936, 6084]] through strategy decoder-bias.\n",
      "Recovered 17 tokens with positional data from imprinted layer.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1421641/951946753.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m reconstructed_user_data, stats = attacker.reconstruct2([server_payload], [shared_data], \n\u001b[0m\u001b[1;32m      2\u001b[0m                                                       server.secrets, dryrun=cfg.dryrun)\n\u001b[1;32m      3\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstructed_user_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n\u001b[1;32m      5\u001b[0m                                     server.model, cfg_case=cfg.case, setup=setup)\n",
      "\u001b[0;32m~/Dropbox/Documents_Hyperion/Python/breaching/breaching/attacks/analytic_attack.py\u001b[0m in \u001b[0;36mreconstruct2\u001b[0;34m(self, server_payload, shared_data, server_secrets, dryrun)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# Getting multiple user's sentences back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_match_words_to_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimated_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjust_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_with_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# Pad recovered sentences:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Documents_Hyperion/Python/breaching/breaching/attacks/analytic_attack.py\u001b[0m in \u001b[0;36m_match_words_to_sentences\u001b[0;34m(self, estimated_pos, just_pos, new_with_pos, len_data, sorted_tokens)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# Start the sentences with first words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_w\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfirst_w\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# Go through the rest of the word groups, assigning words to their appropriate sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "reconstructed_user_data, stats = attacker.reconstruct2([server_payload], [shared_data], \n",
    "                                                      server.secrets, dryrun=cfg.dryrun)\n",
    "user.print(reconstructed_user_data)\n",
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "                                    server.model, cfg_case=cfg.case, setup=setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac408b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "permuted_true_data = dict(data=true_user_data[\"data\"][[3, 2, 1, 0]], labels=true_user_data[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a480b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = breaching.analysis.report(permuted_true_data, true_user_data, [server_payload], \n",
    "                                    server.model, cfg_case=cfg.case, setup=setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c39e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = breaching.analysis.report(true_user_data, true_user_data, [server_payload], \n",
    "                                    server.model, cfg_case=cfg.case, setup=setup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
