{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebef44a",
   "metadata": {},
   "source": [
    "# Fishing for User Data in Large-Batch Federated Learning via Gradient Magnification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756fc5f",
   "metadata": {},
   "source": [
    "This notebook shows an example for a **arbitrary batch image gradient inversion** as described in \"Fishing for User Data in Large-Batch Federated Learning via Gradient Magnification\". The setting is a pretrained ResNet-18 and the federated learning algorithm is **fedSGD** in a **cross-device** setting.\n",
    "\n",
    "Paper URL: https://arxiv.org/abs/2202.00580"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808157c7",
   "metadata": {},
   "source": [
    "This variant fishes for user data of the target user by estimating the feature distribution based on a group of other users. This is especially practical in a cross-device setting, where the server has access to many users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4107d723",
   "metadata": {},
   "source": [
    "#### Abstract\n",
    "Federated learning (FL) has rapidly risen in popularity due to its promise of privacy and efficiency. Previous works have exposed privacy vulnerabilities in the FL pipeline by recovering user data from gradient updates. However, existing attacks fail to address realistic settings because they either 1) require a `toy' settings with very small batch sizes, or 2) require unrealistic and conspicuous architecture modifications. We introduce a new strategy that dramatically elevates existing attacks to operate on batches of arbitrarily large size, and without architectural modifications. Our model-agnostic strategy only requires modifications to the model parameters sent to the user, which is a realistic threat model in many scenarios. We demonstrate the strategy in challenging large-scale settings, obtaining high-fidelity data extraction in both cross-device and cross-silo federated learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dcd6cb",
   "metadata": {},
   "source": [
    "### Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import breaching\n",
    "except ModuleNotFoundError:\n",
    "    # You only really need this safety net if you want to run these notebooks directly in the examples directory\n",
    "    # Don't worry about this if you installed the package or moved the notebook to the main directory.\n",
    "    import os; os.chdir(\"..\")\n",
    "    import breaching\n",
    "    \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf, open_dict\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Redirects logs directly into the jupyter notebook\n",
    "import logging, sys\n",
    "logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler(sys.stdout)], format='%(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5e214",
   "metadata": {},
   "source": [
    "### Initialize cfg object and system setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd663b",
   "metadata": {},
   "source": [
    "This will load the full configuration object. This includes the configuration for the use case and threat model as `cfg.case` and the hyperparameters and implementation of the attack as `cfg.attack`. All parameters can be modified below, or overriden with `overrides=` as if they were cmd-line arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc3a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = breaching.get_config(overrides=[\"case/server=malicious-fishing\", \"attack=april_analytic\"])\n",
    "          \n",
    "device = torch.device('cpu')\n",
    "torch.backends.cudnn.benchmark = cfg.case.impl.benchmark\n",
    "setup = dict(device=device, dtype=getattr(torch, cfg.case.impl.dtype))\n",
    "setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c5fb1",
   "metadata": {},
   "source": [
    "### Modify config options here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0764ef",
   "metadata": {},
   "source": [
    "You can use `.attribute` access to modify any of these configurations for the attack, or the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac118ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In principle the attack can work with a normal split like this:\n",
    "cfg.case.data.name = \"ImageNet\"\n",
    "cfg.case.data.examples_from_split = \"validation\"\n",
    "cfg.case.data.default_clients = 25\n",
    "cfg.case.server.target_cls_idx = 0 # Which class to attack?\n",
    "\n",
    "cfg.case.data.partition=\"balanced\"\n",
    "\n",
    "cfg.case.server.pretrained=False # this notebook \"often\" works when the model is also pretrained...\n",
    "\n",
    "cfg.case.user.num_data_points = 8\n",
    "\n",
    "cfg.case.user.user_idx = 0\n",
    "cfg.case.user.provide_labels = True # Mostly out of convenience\n",
    "\n",
    "cfg.case.model=\"vit_small_april\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5bd45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.case.server.class_multiplier = 0.5\n",
    "cfg.case.server.bias_multiplier = 0\n",
    "cfg.case.server.feat_multiplier = 400\n",
    "\n",
    "cfg.case.server.reweight_collisions = 1\n",
    "cfg.case.server.reset_param_weights = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f64389",
   "metadata": {},
   "source": [
    "### Instantiate all parties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db2272f",
   "metadata": {},
   "source": [
    "The following lines generate \"server, \"user\" and \"attacker\" objects and print an overview of their configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3abd955",
   "metadata": {},
   "outputs": [],
   "source": [
    "user, server, model, loss_fn = breaching.cases.construct_case(cfg.case, setup)\n",
    "attacker = breaching.attacks.prepare_attack(server.model, server.loss, cfg.attack, setup)\n",
    "breaching.utils.overview(server, user, attacker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c0ad6",
   "metadata": {},
   "source": [
    "### Simulate an attacked FL protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b64e78",
   "metadata": {},
   "source": [
    "In this scenario, other users also exist, which we simulate below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d16b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_users = []\n",
    "for user_idx in range(1, cfg.case.data.default_clients): # The target user is user 0\n",
    "    cfg.case.user.user_idx = user_idx\n",
    "    extra_user = breaching.cases.construct_user(model, loss_fn, cfg.case, setup)\n",
    "    additional_users += [extra_user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d86eb17",
   "metadata": {},
   "source": [
    "We then run a modified server protocol, which first finds the feature by querying the other users and attacks the user ith a modified parameter vector based on the feature distribution gauged from the other users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25be1563",
   "metadata": {},
   "outputs": [],
   "source": [
    "[shared_data], [server_payload], true_user_data = server.run_protocol(user, additional_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c68628",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.plot(true_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c821560",
   "metadata": {},
   "source": [
    "#### We can also evaluate the measured feature distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9cb29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(true_user_data[\"distribution\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c9462",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_payload[\"parameters\"][-2][server_payload[\"parameters\"][-2] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5805ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_payload[\"parameters\"][-1][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3721b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_data[\"gradients\"][-1][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b697db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from breaching.cases.malicious_modifications.classattack_utils import print_gradients_norm, cal_single_gradients\n",
    "single_gradients, single_losses = cal_single_gradients(user.model, loss_fn, true_user_data, setup=setup)\n",
    "print_gradients_norm(single_gradients, single_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17255c5a",
   "metadata": {},
   "source": [
    "### Now reconstruct  a single \"fished\" user data point:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82360c14",
   "metadata": {},
   "source": [
    "Now we launch the attack, reconstructing user data based on only the `server_payload` and the `shared_data`. \n",
    "\n",
    "You can interrupt the computation early to see a partial solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a32fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_user_data, stats = attacker.reconstruct([server_payload], [shared_data], \n",
    "                                                      server.secrets, dryrun=cfg.dryrun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc4943f",
   "metadata": {},
   "source": [
    "Next we'll evaluate metrics, comparing the `reconstructed_user_data` to the `true_user_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f2685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "                                    server.model, order_batch=True, compute_full_iip=False, \n",
    "                                    cfg_case=cfg.case, setup=setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a200797e",
   "metadata": {},
   "source": [
    "And finally, we also plot the reconstructed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631f4a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.plot(reconstructed_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcb085f",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "* You can use `cal_single_gradients` and `print_gradients_norm` from `breaching.cases.classattack_utils` to verify that only one of the user data points has a non-neglible gradient norm\n",
    "* This attack has a $1/e \\approx 37\\%$ success chance for a single target user. Do not be alarmed if it does not work immediately (In those casese the reconstruction may return NaN immediately). In the cross-device setting, the attack can be deployed against a large number of users.\n",
    "* This example shows the attack in a (fast to compute) setting where each user has only 4 goldfish images. You can also launch this attack in the general setting where each user has a large amount of data (and for example, the same number of goldfish images among them, or also much more), by tweaking the data settings and waiting longer. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
