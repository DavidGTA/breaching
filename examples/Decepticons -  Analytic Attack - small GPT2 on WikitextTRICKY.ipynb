{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebef44a",
   "metadata": {},
   "source": [
    "# Decepticons: Corrupted Transformers Breach Privacy in Federated Learning for Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756fc5f",
   "metadata": {},
   "source": [
    "This notebook shows an example for the threat model and attack described in \"Decepticons: Corrupted Transformers Breach Privacy in Federated Learning for Language Models\n",
    "\". This example deviates from the other \"honest-but-curious\" server models and investigates a malicious server that may send malicious server updates. The attack succeeds for a range of common transformer architectures and works merely by sending a single malicious query to the user model.\n",
    "\n",
    "In this notebook, we attack the (small) GPT-2 model (120mil parameters).\n",
    "\n",
    "\n",
    "\n",
    "Paper URL: https://arxiv.org/abs/2201.12675"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd1107",
   "metadata": {},
   "source": [
    "### Abstract:\n",
    "A central tenet of Federated learning (FL), which trains models without centralizing user data, is privacy. However, previous work has shown that the gradient updates used in FL can leak user information. While the most industrial uses of FL are for text applications (e.g. keystroke prediction), nearly all attacks on FL privacy have focused on simple image classifiers. We propose a novel attack that reveals private user text by deploying malicious parameter vectors, and which succeeds even with mini-batches, multiple users, and long sequences. Unlike previous attacks on FL, the attack exploits characteristics of both the Transformer architecture and the token embedding, separately extracting tokens and positional embeddings to retrieve high-fidelity text. This work suggests that FL on text, which has historically been resistant to privacy attacks, is far more vulnerable than previously thought."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7676c5",
   "metadata": {},
   "source": [
    "### Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b850eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import breaching\n",
    "except ModuleNotFoundError:\n",
    "    # You only really need this safety net if you want to run these notebooks directly in the examples directory\n",
    "    # Don't worry about this if you installed the package or moved the notebook to the main directory.\n",
    "    import os; os.chdir(\"..\")\n",
    "    import breaching\n",
    "    \n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Redirects logs directly into the jupyter notebook\n",
    "import logging, sys\n",
    "logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler(sys.stdout)], format='%(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5e214",
   "metadata": {},
   "source": [
    "### Initialize cfg object and system setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd663b",
   "metadata": {},
   "source": [
    "This will load the full configuration object. This includes the configuration for the use case and threat model as `cfg.case` and the hyperparameters and implementation of the attack as `cfg.attack`. All parameters can be modified below, or overriden with `overrides=` as if they were cmd-line arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7dc3a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating use case causal_lang_training with server type malicious_transformer_parameters.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'device': device(type='cpu'), 'dtype': torch.float32}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = breaching.get_config(overrides=[\"attack=decepticon\", \"case=10_causal_lang_training\", \n",
    "                                     \"case/server=malicious-transformer\"])\n",
    "          \n",
    "device = torch.device('cpu')\n",
    "torch.backends.cudnn.benchmark = cfg.case.impl.benchmark\n",
    "setup = dict(device=device, dtype=getattr(torch, cfg.case.impl.dtype))\n",
    "setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c5fb1",
   "metadata": {},
   "source": [
    "### Modify config options here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0764ef",
   "metadata": {},
   "source": [
    "You can use `.attribute` access to modify any of these configurations for the attack, or the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac118ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.case.user.num_data_points = 1 # How many sentences?\n",
    "cfg.case.user.user_idx = 1 # From which user?\n",
    "cfg.case.data.shape = [32] # This is the sequence length\n",
    "\n",
    "cfg.case.server.provide_public_buffers = True # Send server signal to disable dropout\n",
    "cfg.case.server.has_external_data = True  # Not strictly necessary, but could also use random text (see Appendix)\n",
    "cfg.case.data.tokenizer = \"gpt2\"\n",
    "cfg.case.model = \"transformerS\" # Could also choose \"gpt2S\" which contains ReLU activations\n",
    "cfg.case.server.pretrained = False\n",
    "\n",
    "## Attack hyperparameters:\n",
    "\n",
    "# Server side:\n",
    "cfg.case.server.param_modification.v_length = 8 # Length of the sentence component\n",
    "cfg.case.server.param_modification.eps = 1\n",
    "cfg.case.server.param_modification.measurement_scale=1  # 1e12 # Circumvent GELU\n",
    "cfg.case.server.param_modification.imprint_sentence_position = 0\n",
    "cfg.case.server.param_modification.softmax_skew = 1e8\n",
    "cfg.case.server.param_modification.sequence_token_weight = 1\n",
    "\n",
    "\n",
    "# Attacker side:\n",
    "\n",
    "# this option requires installation of `k-means-constrained` which can be tricky:\n",
    "# If this doesn't work for you, falling back to \"dynamic-threshold\" is still a decent option.\n",
    "cfg.attack.sentence_algorithm = \"k-means\" \n",
    "cfg.attack.token_strategy=\"embedding-norm\" # no decoder bias in GPT\n",
    "cfg.attack.embedding_token_weight=0.0 # Setting e.g. 0.25 here can improve performance slightly for long sequences\n",
    "cfg.attack.separation = \"subtraction\"#\"decorrelation\"\n",
    "\n",
    "cfg.attack.breach_reduction = \"total-weight\"\n",
    "cfg.attack.undivided=True\n",
    "## DP\n",
    "\n",
    "cfg.case.user.local_diff_privacy.input_noise = 0.0  # input up to 1.0 is ok\n",
    "cfg.case.user.local_diff_privacy.gradient_noise =1e-8\n",
    "cfg.case.user.local_diff_privacy.per_example_clipping = 0\n",
    "cfg.case.user.local_diff_privacy.distribution = 'gaussian'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f64389",
   "metadata": {},
   "source": [
    "### Instantiate all parties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71983edf",
   "metadata": {},
   "source": [
    "The following lines generate \"server, \"user\" and \"attacker\" objects and print an overview of their configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3abd955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Model architecture transformerS loaded with 53,091,409 parameters and 2,560,000 buffers.\n",
      "Overall this is a data ratio of 1659106:1 for target shape [1, 32] given that num_queries=1.\n",
      "User (of type UserSingleStep) with settings:\n",
      "    Number of data points: 1\n",
      "\n",
      "    Threat model:\n",
      "    User provides labels: False\n",
      "    User provides buffers: False\n",
      "    User provides number of data points: True\n",
      "\n",
      "    Data:\n",
      "    Dataset: wikitext\n",
      "    user: 1\n",
      "    Defense: Local gaussian gradient noise with strength 9.99999993922529e-09.\n",
      "        \n",
      "Server (of type MaliciousTransformerServer) with settings:\n",
      "    Threat model: Malicious (Parameters)\n",
      "    Number of planned queries: 1\n",
      "    Has external/public data: True\n",
      "\n",
      "    Model:\n",
      "        model specification: transformerS\n",
      "        model state: default\n",
      "        public buffers: True\n",
      "\n",
      "    Secrets: {}\n",
      "    \n",
      "Attacker (of type DecepticonAttacker).\n"
     ]
    }
   ],
   "source": [
    "user, server, model, loss_fn = breaching.cases.construct_case(cfg.case, setup)\n",
    "attacker = breaching.attacks.prepare_attack(server.model, server.loss, cfg.attack, setup)\n",
    "breaching.utils.overview(server, user, attacker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c0ad6",
   "metadata": {},
   "source": [
    "### Simulate an attacked FL protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058bcc2",
   "metadata": {},
   "source": [
    "This exchange is a simulation of a single query in a federated learning protocol. The server sends out a `server_payload` and the user computes an update based on their private local data. This user update is `shared_data` and contains, for example, the parameter gradient of the model in the simplest case. `true_user_data` is also returned by `.compute_local_updates`, but of course not forwarded to the server or attacker and only used for (our) analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0dbd868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([1536, 512]).\n",
      "Computing feature distribution before the probe layer Linear(in_features=512, out_features=512, bias=True) from external data.\n",
      "Feature mean is -0.03757932037115097, feature std is 0.9479761719703674.\n",
      "Computing user update on user 1 in model mode: eval.\n"
     ]
    }
   ],
   "source": [
    "server_payload = server.distribute_payload()\n",
    "shared_data, true_user_data = user.compute_local_updates(server_payload)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69a48d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "['transformer_encoder.layers.0.self_attn.in_proj_weight:0.0',\n",
    " 'transformer_encoder.layers.0.self_attn.in_proj_bias:0.0',\n",
    " 'transformer_encoder.layers.0.self_attn.out_proj.weight:0.8733341097831726',\n",
    " 'transformer_encoder.layers.0.self_attn.out_proj.bias:0.21867378056049347',\n",
    " 'transformer_encoder.layers.0.linear1.weight:0.00801785197108984',\n",
    " 'transformer_encoder.layers.0.linear1.bias:0.00039870699401944876',\n",
    " 'transformer_encoder.layers.0.linear2.weight:6.721737384796143',\n",
    " 'transformer_encoder.layers.0.linear2.bias:0.3053097128868103',\n",
    " 'transformer_encoder.layers.0.norm1.weight:0.2597469091415405',\n",
    " 'transformer_encoder.layers.0.norm1.bias:0.3053097128868103',\n",
    " 'transformer_encoder.layers.0.norm2.weight:0.2685771584510803',\n",
    " 'transformer_encoder.layers.0.norm2.bias:0.3059074580669403',\n",
    " 'encoder.weight:3.918757915496826',\n",
    " 'decoder.weight:4.312182426452637'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af3309cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transformer_encoder.layers.0.self_attn.in_proj_weight:8.88554859557189e-06',\n",
       " 'transformer_encoder.layers.0.self_attn.in_proj_bias:3.814743081420602e-07',\n",
       " 'transformer_encoder.layers.0.self_attn.out_proj.weight:0.5064964294433594',\n",
       " 'transformer_encoder.layers.0.self_attn.out_proj.bias:0.20190459489822388',\n",
       " 'transformer_encoder.layers.0.linear1.weight:0.31360772252082825',\n",
       " 'transformer_encoder.layers.0.linear1.bias:0.00013857729209121317',\n",
       " 'transformer_encoder.layers.0.linear2.weight:6.309071063995361',\n",
       " 'transformer_encoder.layers.0.linear2.bias:0.2870209813117981',\n",
       " 'transformer_encoder.layers.0.norm1.weight:0.2538856565952301',\n",
       " 'transformer_encoder.layers.0.norm1.bias:0.2870004177093506',\n",
       " 'transformer_encoder.layers.0.norm2.weight:0.2675231993198395',\n",
       " 'transformer_encoder.layers.0.norm2.bias:0.28992146253585815',\n",
       " 'encoder.weight:3.869091749191284',\n",
       " 'decoder.weight:4.290277481079102']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"{n}:{g.norm().item()}\" for (n, p), g in zip(user.model.named_parameters(), shared_data[\"gradients\"])][:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49c68628",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Tower Building of the Little Rock Arsenal, also known as U.S. Arsenal Building, is a building located in MacArthur Park in downtown Little Rock, Arkansas\n"
     ]
    }
   ],
   "source": [
    "user.print(true_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17255c5a",
   "metadata": {},
   "source": [
    "### Reconstruct user data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93e8cd6",
   "metadata": {},
   "source": [
    "Now we launch the attack, reconstructing user data based on only the `server_payload` and the `shared_data`. \n",
    "\n",
    "For this attack, we also share secret information from the malicious server with the attack (`server.secrets`), which here is the location and structure of the imprint block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9a32fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceeded to cut estimated token distribution at 1.50.\n",
      "Recovered tokens tensor([   13,    13,    50,   257,   262,   286,   287,   287,   318,   318,\n",
      "          355,   383,   471,   635,   837,   837,  1900,  2615,  3250,  4631,\n",
      "         4631,  5140,  7703,  7703,  7703,  8765,  9436, 11819, 11819, 13837,\n",
      "        13837, 46626]) through strategy embedding-norm.\n",
      "Recovered 512 embeddings with positional data from imprinted layer.\n",
      "tensor([6.4407e-04, 6.0268e-04, 5.6434e-04, 5.5086e-04, 5.4691e-04, 2.3977e-04,\n",
      "        2.2925e-04, 1.1306e-04, 1.1056e-04, 1.1686e-05, 2.9096e-06, 1.9644e-09,\n",
      "        1.8579e-09, 1.5881e-09, 1.5716e-09, 1.5319e-09, 1.4875e-09, 1.4527e-09,\n",
      "        1.3173e-09, 1.2234e-09, 1.2016e-09, 1.1956e-09, 1.1621e-09, 1.1506e-09,\n",
      "        1.1063e-09, 1.1015e-09, 1.0939e-09, 1.0896e-09, 1.0713e-09, 1.0702e-09,\n",
      "        1.0673e-09, 1.0657e-09, 1.0501e-09, 9.9716e-10, 9.9595e-10, 9.9374e-10,\n",
      "        9.7673e-10, 9.7430e-10, 9.6475e-10, 9.6247e-10, 9.4863e-10, 9.2029e-10,\n",
      "        9.1802e-10, 9.1711e-10, 9.0830e-10, 9.0813e-10, 9.0370e-10, 8.9995e-10,\n",
      "        8.9869e-10, 8.9774e-10, 8.9346e-10, 8.8762e-10, 8.8585e-10, 8.3446e-10,\n",
      "        8.3145e-10, 8.2778e-10, 8.1229e-10, 8.1019e-10, 8.0905e-10, 7.9973e-10,\n",
      "        7.7527e-10, 7.7483e-10, 7.6097e-10, 7.5949e-10])\n",
      "tensor([6.4407e-04, 6.0268e-04, 5.7251e-04, 5.7147e-04, 5.6434e-04, 5.6331e-04,\n",
      "        5.5086e-04, 5.4691e-04, 5.0432e-04, 4.9033e-04, 4.8617e-04, 4.8420e-04,\n",
      "        4.4701e-04, 3.7834e-04, 3.2686e-04, 2.3977e-04, 2.2925e-04, 2.1287e-04,\n",
      "        1.4598e-04, 1.1306e-04, 1.1151e-04, 1.1056e-04, 1.0636e-04, 5.2328e-05,\n",
      "        3.4695e-05, 3.4004e-05, 2.1955e-05, 1.2104e-05, 1.2037e-05, 1.1686e-05,\n",
      "        2.9096e-06, 1.2416e-08, 1.2243e-08, 1.2220e-08, 1.2167e-08, 1.2124e-08,\n",
      "        1.2115e-08, 1.2112e-08, 1.2111e-08, 1.2097e-08, 1.2081e-08, 1.2079e-08,\n",
      "        1.2069e-08, 1.2006e-08, 1.1967e-08, 1.1929e-08, 1.1924e-08, 1.1924e-08,\n",
      "        1.1903e-08, 1.1888e-08, 1.1878e-08, 1.1874e-08, 1.1868e-08, 1.1863e-08,\n",
      "        1.1855e-08, 1.1834e-08, 1.1831e-08, 1.1830e-08, 1.1815e-08, 1.1810e-08,\n",
      "        1.1799e-08, 1.1795e-08, 1.1794e-08, 1.1786e-08])\n",
      "Reduced to 32 hits.\n"
     ]
    }
   ],
   "source": [
    "reconstructed_user_data, stats = attacker.reconstruct([server_payload], [shared_data], server.secrets, \n",
    "                                                      dryrun=cfg.dryrun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c35e12",
   "metadata": {},
   "source": [
    "Next we'll evaluate metrics, comparing the `reconstructed_user_data` to the `true_user_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31f2685a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.1250 | S-BLEU: 0.06 | FMSE: 2.6643e+00 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.89| ROUGE2: 0.08 | ROUGE-L: 0.37| Token Acc: 93.75% | Label Acc: 93.75%\n"
     ]
    }
   ],
   "source": [
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "                                    server.model, order_batch=True, compute_full_iip=False, \n",
    "                                    cfg_case=cfg.case, setup=setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f920aca0",
   "metadata": {},
   "source": [
    "And finally, we also plot the reconstructed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "631f4a84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " as Tower Building Rock Little located known Little Park also building Little MacArthur Rock The a Arsenal Arsenal is of the. US in in,, is downtown Building.\n"
     ]
    }
   ],
   "source": [
    "user.print(reconstructed_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04adeafc",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "* There are a variety of hyperparameters to the attack which are set to reasonable defaults. Performance of the attack could be improved in some unusual use cases (datasets or models) by tuning these parameters further.\n",
    "* In this example, dropout is disabled under the assumption that this is a parameter that can be controlled in the server update. The optimal attack simply disables dropout. However, the attack can still succeed when dropout is enforced by the user, albeit with a minor loss in reconstruction quality.\n",
    "* This example also assumes complete freedom to choose the parameter vector, for this reason we circumvent the smooth part of the GELU activation with a \"very\" large measurement vector magnitude. This is arguably excessive for only a small again in accuracy.\n",
    "* We also want to re-emphasize that the design space of these parameter modification attacks is large. A defense against the specific parameter modification described here is unlikely to be safe in general!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f621470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
