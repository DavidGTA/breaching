# TAG: Gradient Attack on Transformer-based Language Models
# Deng et al. 2021
# proposed as attack for text with transformer models
defaults:
  - _default_optimization_attack
type: tag
attack_type: joint-optimization
label_strategy: None

token_recovery: from-embedding

objective:
  type: tag-euclidean
  scale: 1.0
  task_regularization: 0.0
  tag_scale: 0.1
  scale_scheme: linear # This is a guess based on similar rules working for inverting gradients

optim:
  optimizer: bert-adam
  step_size: 0.05
  boxed: False
  max_iterations: 1000
  grad_clip: 1.0

  callback: 100 # Print objective value every callback many iterations
