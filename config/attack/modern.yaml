
type: invertinggradients

attack_type: optimization   # analytic, equation solver

objective: cosine-similarity
restarts:
  num_trials: 8
  scoring: cosine-similarity

init: randn

optim:
  optimizer: adam
  signed: False
  step_size: 0.1
  boxed: True
  max_iterations: 24_000
  step_size_decay: cosine-decay
  langevin_noise: 0.1
  warmup: 50

  callback: 500  # Print objective value every callback many iterations

regularization:
  total_variation:
    scale: 0.1
    inner_exp: 2
    outer_exp: 0.5
  orthogonality:
    scale: 0.1
  norm:
    scale: 1e-5
    pnorm: 2
  deep_inversion:  # This is batchnorm matching to buffers provided by the user [which can be either actual stats or global]
    scale: 0.0
  # group_regularization: # Not implemented. Unclear how this was done without accesss to the source code
  #  scale: 0.01
