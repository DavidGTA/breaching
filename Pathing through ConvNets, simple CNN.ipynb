{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebef44a",
   "metadata": {},
   "source": [
    "# Breaching privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756fc5f",
   "metadata": {},
   "source": [
    "This notebook does the same job as the cmd-line tool `breach.py`, but also directly visualizes the user data and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import breaching\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f668ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _return_model_features(model, inputs):\n",
    "    features = dict()  # The named-hook + dict construction should be a bit more robust\n",
    "    if inputs.ndim == 3:\n",
    "        inputs = inputs.unsqueeze(0)\n",
    "\n",
    "    def named_hook(name):\n",
    "        def hook_fn(module, input, output):\n",
    "            features[name] = input[0]\n",
    "        return hook_fn\n",
    "    for name, module in reversed(list(model.named_modules())):\n",
    "        if isinstance(module, (torch.nn.Hardtanh)):\n",
    "            hook = module.register_forward_hook(named_hook(name))\n",
    "            feature_layer_name = name\n",
    "            break\n",
    "    model(inputs)\n",
    "    hook.remove()\n",
    "    return features[feature_layer_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5e214",
   "metadata": {},
   "source": [
    "### Initialize cfg object and system setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd663b",
   "metadata": {},
   "source": [
    "This will print out all configuration options. \n",
    "There are a lot of possible configurations, but there is usually no need to worry about most of these. Below, a few options are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc3a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize(config_path=\"config\"):\n",
    "    cfg = hydra.compose(config_name='cfg', overrides=['attack=invertinggradients',\n",
    "                                                      'case=1_single_image_small'])\n",
    "    print(f'Investigating use case {cfg.case.name} with server type {cfg.case.server.name}.')\n",
    "    print('Attack settings are:')\n",
    "    print(OmegaConf.to_yaml(cfg.attack))\n",
    "          \n",
    "device = torch.device(f'cuda:2') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.backends.cudnn.benchmark = cfg.case.impl.benchmark\n",
    "setup = dict(device=device, dtype=getattr(torch, cfg.case.impl.dtype))\n",
    "setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c5fb1",
   "metadata": {},
   "source": [
    "### Modify config options here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0764ef",
   "metadata": {},
   "source": [
    "You can use `.attribute` access to modify any of these configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac118ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.case.user.data_idx = 0\n",
    "cfg.case.model='ConvNetSmall'\n",
    "\n",
    "cfg.case.user.num_data_points = 1\n",
    "\n",
    "cfg.case.data.batch_size = 512\n",
    "cfg.case.server.has_external_data = True\n",
    "\n",
    "cfg.attack.objective.type='masked-cosine-similarity'\n",
    "# The total variation scale should be small for CIFAR images\n",
    "cfg.attack.regularization.total_variation.scale = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f64389",
   "metadata": {},
   "source": [
    "### Instantiate all parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3abd955",
   "metadata": {},
   "outputs": [],
   "source": [
    "user, server = breaching.cases.construct_case(cfg.case, setup)\n",
    "attacker = breaching.attacks.prepare_attack(server.model, server.loss, cfg.attack, setup)\n",
    "server.model.to(**setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7273d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(user)\n",
    "print(server)\n",
    "print(attacker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795d3901",
   "metadata": {},
   "source": [
    "## Malicious server I : Modify the model architecture first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9199dcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_paths = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39855e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = server.model.model[-5].out_channels\n",
    "server.model.model[-1] = torch.nn.Sequential(torch.nn.Linear(feature_dim, num_paths),\n",
    "                                             torch.nn.Hardtanh(min_val=0, max_val=1), \n",
    "                                             torch.nn.Linear(num_paths, feature_dim),\n",
    "                                             server.model.model[-1]).to(**setup)\n",
    "\n",
    "\n",
    "attacker.model_template = copy.deepcopy(server.model)\n",
    "user.model = copy.deepcopy(server.model)\n",
    "user.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec9575",
   "metadata": {},
   "source": [
    "## Malicious server II: Include paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd71634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old first layer:\n",
    "# new_weight = module.weight.new_zeros(module.in_channels, module.in_channels, *module.kernel_size)\n",
    "# torch.nn.init.orthogonal_(new_weight)\n",
    "# new_bias = module.bias.new_zeros(module.in_channels)\n",
    "# fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(new_weight)\n",
    "# torch.nn.init.uniform_(new_bias, -1 / math.sqrt(fan_in), 1 / math.sqrt(fan_in))\n",
    "\n",
    "# # Replicate filters:\n",
    "# replication_dim = module.out_channels // module.in_channels\n",
    "# replicated_weight = torch.cat([new_weight] * replication_dim).contiguous()\n",
    "# replicated_bias = torch.cat([new_bias] * replication_dim).contiguous()\n",
    "\n",
    "# module.weight.data[:replication_dim * module.in_channels] = replicated_weight\n",
    "# module.bias.data[:replication_dim * module.in_channels] = replicated_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24891f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path_width = 3\n",
    "first_conv = True\n",
    "with torch.no_grad():\n",
    "    for name, module in server.model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            # Initialize existing params at zero:\n",
    "            module.weight.data = torch.zeros_like(module.weight)\n",
    "            module.bias.data = torch.zeros_like(module.bias)\n",
    "            \n",
    "            output_path_width = module.out_channels // num_paths\n",
    "            \n",
    "            new_weight = module.weight.new_zeros(output_path_width, input_path_width,  *module.kernel_size)\n",
    "            torch.nn.init.orthogonal_(new_weight)\n",
    "\n",
    "            new_bias = module.bias.new_zeros(output_path_width)\n",
    "            fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(new_weight)\n",
    "            torch.nn.init.uniform_(new_bias, -1 / math.sqrt(fan_in), 1 / math.sqrt(fan_in))\n",
    "\n",
    "            # Group channels:\n",
    "            ii, io = 0, 0 # index-in index-out\n",
    "            if first_conv:\n",
    "                for path in range(num_paths):\n",
    "                    module.weight.data[io:io+output_path_width, :] = new_weight.clone()\n",
    "                    io += output_path_width\n",
    "                    ii += input_path_width\n",
    "                first_conv = False\n",
    "            else:\n",
    "                for path in range(num_paths):\n",
    "                    module.weight.data[io:io+output_path_width, ii:ii+input_path_width] = new_weight.clone()\n",
    "                    io += output_path_width\n",
    "                    ii += input_path_width\n",
    "                \n",
    "            module.bias.data[:output_path_width * num_paths] = torch.cat([new_bias] * num_paths).contiguous()\n",
    "            \n",
    "            # Set input->output\n",
    "            input_path_width = output_path_width\n",
    "            \n",
    "            \n",
    "            print(module.weight.shape, module.bias.shape)\n",
    "            # Test channel:\n",
    "            inputs = torch.cat([torch.randn(1, 1, 32, 32, **setup)] * module.in_channels, dim=1)\n",
    "            feats = module(inputs)\n",
    "            print(feats[0,0:4, 0, 0], feats[0,output_path_width:output_path_width+4, 0, 0])\n",
    "        if isinstance(module, torch.nn.Linear) and module.out_features == num_paths:\n",
    "            # prep averaging layer here\n",
    "            module.weight.data = torch.zeros_like(module.weight.data)\n",
    "            module.bias.data = torch.zeros_like(module.bias.data)\n",
    "            new_block = module.weight.data.new_ones(input_path_width)/ input_path_width\n",
    "            idx = 0\n",
    "            for path in range(num_paths):\n",
    "                module.weight.data[path, idx:idx+input_path_width] = new_block.clone()\n",
    "                idx += input_path_width\n",
    "            adaptation_layer = module\n",
    "        if isinstance(module, torch.nn.Linear) and module.in_features == num_paths:\n",
    "            # prep return layer here, all inputs need to be picked up\n",
    "            # module.weight.data = torch.ones_like(module.weight.data) / num_paths\n",
    "            #torch.nn.init.orthogonal_(module.weight.data)\n",
    "            # module.bias.data = torch.zeros_like(module.bias.data)\n",
    "            pass\n",
    "            # dont mess with the return layer\n",
    "            \n",
    "num_params = sum([(p.abs() > 1e-7).sum() for p in server.model.parameters()])\n",
    "linear_params = sum([(p.abs() > 1e-7).sum() for m in server.model.modules() for p in m.parameters()  \n",
    "                     if isinstance(m, torch.nn.Linear)])\n",
    "print(f'Model architecture {server.model.__class__} loaded with {num_params:,} non-zero parameters of which '\n",
    "      f'{linear_params} are in linear layers.')\n",
    "\n",
    "target_information = cfg.case.user.num_data_points * torch.as_tensor(cfg.case.data.shape).prod()\n",
    "\n",
    "print(f'Overall this is a data ratio of {(num_params - linear_params) / target_information:2.2f}:1 '\n",
    "      f'for target shape {[cfg.case.user.num_data_points, *cfg.case.data.shape]} if pathcount was optimal.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b2087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(1, 3, 32, 32, **setup)\n",
    "feats = _return_model_features(server.model, inputs)\n",
    "feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897468b8",
   "metadata": {},
   "source": [
    "# Compute bins and set feature distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063b0c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import NormalDist\n",
    "\n",
    "def get_bins_by_mass(num_bins):\n",
    "    bins = []\n",
    "    mass = 0\n",
    "    for path in range(num_bins + 1):\n",
    "        mass += 1 / (num_bins + 2)\n",
    "        bins += [NormalDist(mu=0, sigma=1).inv_cdf(mass)]\n",
    "    bin_sizes = [bins[i + 1] - bins[i] for i in range(len(bins) - 1)]\n",
    "    return bins[:-1], bin_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da31e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_bins_by_mass(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict()\n",
    "def named_hook(name):\n",
    "    def hook_fn(module, input, output):\n",
    "        features[name] = output\n",
    "    return hook_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cf3c2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    for name, module in server.model.named_modules():\n",
    "        if isinstance(module, (torch.nn.Conv2d, torch.nn.Linear)):\n",
    "            hook = module.register_forward_hook(named_hook(name))\n",
    "\n",
    "            random_data_sample = next(iter(server.external_dataloader))[0].to(**setup)\n",
    "            # random_data_sample = torch.randn(1024, 3, 32, 32, **setup)\n",
    "            # random_data_sample = true_user_data['data'] #ground truth data sampâle for testing\n",
    "\n",
    "            server.model(random_data_sample)\n",
    "            std, mu = torch.std_mean(features[name])\n",
    "            # print(f'Initial mean of layer {name} is {mu.item()}, std is {std.item()}')\n",
    "            with torch.no_grad():\n",
    "                module.weight.data /= std + 1e-8\n",
    "                module.bias.data -= mu / (std  + 1e-8)\n",
    "            \n",
    "            server.model(random_data_sample)\n",
    "            std, mu = torch.std_mean(features[name])\n",
    "            print(f'Fixed mean of layer {name} is {mu.item()}, std is {std.item()}')  \n",
    "            \n",
    "            \n",
    "            hook.remove()\n",
    "            if isinstance(module, torch.nn.Linear) and module.out_features == num_paths:\n",
    "                # Verify:\n",
    "                print(f'Input to hardtanh before bias and scale is set: {features[name][0]}')\n",
    "\n",
    "                adapt_module = module\n",
    "                # Modify bins in this layer\n",
    "                bins, bin_sizes = get_bins_by_mass(num_paths)\n",
    "                # Safety wheels:\n",
    "                #bins = [b * 2 for b in bins]\n",
    "                #bin_sizes = [b * 2 for b in bin_sizes]\n",
    "                #bins = torch.linspace(-1.96, 1.96, num_paths + 1)\n",
    "                #bin_sizes = [bins[i + 1] - bins[i] for i in range(len(bins) - 1)]\n",
    "                #bins = bins[:-1]\n",
    "                \n",
    "                # Old mod:\n",
    "                module.weight.data /= torch.as_tensor(bin_sizes, **setup)[:, None]\n",
    "                module.bias.data -= torch.as_tensor(bins, **setup) \n",
    "                module.bias.data /= torch.as_tensor(bin_sizes, **setup)\n",
    "\n",
    "                # New computation with extend bin extension?:\n",
    "#                 I = -NormalDist(mu=0, sigma=1).inv_cdf(0.90)\n",
    "#                 module.weight.data *= 2 * I / torch.as_tensor(bin_sizes, **setup)[:, None]\n",
    "#                 module.bias.data -= torch.as_tensor(bins, **setup) \n",
    "#                 module.bias.data *= 2 * I / torch.as_tensor(bin_sizes, **setup)\n",
    "#                 module.bias.data -= I\n",
    "                break\n",
    "                \n",
    "            del features[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80c88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    hook = adapt_module.register_forward_hook(named_hook('hardtanh_input'))\n",
    "    random_data_sample = next(iter(server.external_dataloader))[0].to(**setup)\n",
    "    # random_data_sample = torch.randn(1024, 3, 32, 32, **setup)\n",
    "    # random_data_sample = true_user_data['data'] #ground truth data sample for testing\n",
    "\n",
    "    server.model(random_data_sample)\n",
    "    hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c8290",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features['hardtanh_input'][0])\n",
    "threshold = torch.nn.functional.hardtanh(features['hardtanh_input'][0], min_val=0, max_val=1)\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d28f4eb",
   "metadata": {},
   "source": [
    "### Threshold stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eefbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = torch.nn.functional.hardtanh(features['hardtanh_input'], min_val=0, max_val=1)\n",
    "print(((threshold != 1) & (threshold != 0)).sum() / random_data_sample.shape[0])\n",
    "((threshold != 1) & (threshold != 0)).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ca273",
   "metadata": {},
   "outputs": [],
   "source": [
    "del features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b5f391",
   "metadata": {},
   "source": [
    "### Simulate an attacked FL protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058bcc2",
   "metadata": {},
   "source": [
    "True user data is returned only for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dbd868",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_payload = server.distribute_payload()\n",
    "shared_data, true_user_data = user.compute_local_updates(server_payload)  \n",
    "\n",
    "true_user_data['data'].mean(), true_user_data['data'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7374dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(g.mean(), g.std()) for g in shared_data['gradients'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c68628",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.plot(true_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17255c5a",
   "metadata": {},
   "source": [
    "### Reconstruct user data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2f0092",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_user_data, stats = attacker.reconstruct(server_payload, shared_data, \n",
    "                                                      server.secrets, dryrun=cfg.dryrun)\n",
    "\n",
    "# How good is the reconstruction?\n",
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, \n",
    "                                    server_payload, server.model, user.dataloader, setup=setup,\n",
    "                                    order_batch=True, compute_full_iip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631f4a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.plot(reconstructed_user_data, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c266bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
