{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebef44a",
   "metadata": {},
   "source": [
    "# Breaching privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756fc5f",
   "metadata": {},
   "source": [
    "This notebook does the same job as the cmd-line tool `breach.py`, but also directly visualizes the user data and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b850eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import breaching\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17fdf1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _return_model_features(model, inputs):\n",
    "    features = dict()  # The named-hook + dict construction should be a bit more robust\n",
    "    if inputs.ndim == 3:\n",
    "        inputs = inputs.unsqueeze(0)\n",
    "\n",
    "    def named_hook(name):\n",
    "        def hook_fn(module, input, output):\n",
    "            features[name] = input[0]\n",
    "        return hook_fn\n",
    "    for name, module in reversed(list(model.named_modules())):\n",
    "        if isinstance(module, (torch.nn.Hardtanh)):\n",
    "            hook = module.register_forward_hook(named_hook(name))\n",
    "            feature_layer_name = name\n",
    "            break\n",
    "    model(inputs)\n",
    "    hook.remove()\n",
    "    return features[feature_layer_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5e214",
   "metadata": {},
   "source": [
    "### Initialize cfg object and system setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd663b",
   "metadata": {},
   "source": [
    "This will print out all configuration options. \n",
    "There are a lot of possible configurations, but there is usually no need to worry about most of these. Below, a few options are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7dc3a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating use case single_image_small with server type honest_but_curious.\n",
      "Attack settings are:\n",
      "type: invertinggradients\n",
      "attack_type: optimization\n",
      "objective:\n",
      "  type: cosine-similarity\n",
      "  scale: 1.0\n",
      "restarts:\n",
      "  num_trials: 1\n",
      "  scoring: cosine-similarity\n",
      "init: randn\n",
      "optim:\n",
      "  optimizer: adam\n",
      "  signed: true\n",
      "  step_size: 0.1\n",
      "  boxed: true\n",
      "  max_iterations: 24000\n",
      "  step_size_decay: step-lr\n",
      "  langevin_noise: 0.0\n",
      "  warmup: 0\n",
      "  callback: 1000\n",
      "regularization:\n",
      "  total_variation:\n",
      "    scale: 0.2\n",
      "    inner_exp: 1\n",
      "    outer_exp: 1\n",
      "  orthogonality:\n",
      "    scale: 0.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'device': device(type='cuda', index=1), 'dtype': torch.float32}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with hydra.initialize(config_path=\"config\"):\n",
    "    cfg = hydra.compose(config_name='cfg', overrides=['attack=invertinggradients',\n",
    "                                                      'case=1_single_image_small'])\n",
    "    print(f'Investigating use case {cfg.case.name} with server type {cfg.case.server.name}.')\n",
    "    print('Attack settings are:')\n",
    "    print(OmegaConf.to_yaml(cfg.attack))\n",
    "          \n",
    "device = torch.device(f'cuda:1') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.backends.cudnn.benchmark = cfg.case.impl.benchmark\n",
    "setup = dict(device=device, dtype=getattr(torch, cfg.case.impl.dtype))\n",
    "setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c5fb1",
   "metadata": {},
   "source": [
    "### Modify config options here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0764ef",
   "metadata": {},
   "source": [
    "You can use `.attribute` access to modify any of these configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac118ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.case.user.data_idx = 2\n",
    "cfg.case.model='ConvNetSmall'\n",
    "\n",
    "cfg.case.user.num_data_points = 1\n",
    "\n",
    "cfg.case.data.batch_size = 512\n",
    "cfg.case.server.has_external_data = True\n",
    "\n",
    "cfg.attack.objective.type='masked-cosine-similarity'\n",
    "cfg.attack.objective.scale = 0.25\n",
    "# The total variation scale should be small for CIFAR images\n",
    "cfg.attack.regularization.total_variation.scale = 1e-4\n",
    "cfg.attack.init = 'randn'\n",
    "\n",
    "cfg.attack.optim.signed=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f64389",
   "metadata": {},
   "source": [
    "### Instantiate all parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3abd955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Model architecture <class 'breaching.cases.models.model_preparation.ConvNetSmall'> loaded with 15,355,402 parameters and 0 buffers.\n",
      "Overall this is a data ratio of    4999:1 for target shape [1, 3, 32, 32] given that num_queries=1.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvNetSmall(\n",
       "  (model): Sequential(\n",
       "    (conv0): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu0): ReLU()\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu1): ReLU()\n",
       "    (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (relu2): ReLU()\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (relu3): ReLU()\n",
       "    (pool1): AdaptiveAvgPool2d(output_size=1)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (linear): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user, server = breaching.cases.construct_case(cfg.case, setup)\n",
    "attacker = breaching.attacks.prepare_attack(server.model, server.loss, cfg.attack, setup)\n",
    "server.model.to(**setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c7273d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User (of type UserSingleStep with settings:\n",
      "            number of local updates: 1\n",
      "            number of data points: 1\n",
      "            number of user queries 1\n",
      "\n",
      "            Threat model:\n",
      "            User provides labels: True\n",
      "            User provides number of data points: True\n",
      "\n",
      "            Model:\n",
      "            model specification: ConvNetSmall\n",
      "            loss function: CrossEntropyLoss()\n",
      "\n",
      "            Data:\n",
      "            Dataset: CIFAR10\n",
      "            data_idx: 2\n",
      "        \n",
      "<breaching.cases.servers.HonestServer object at 0x7f1be1fd4d30>\n",
      "<breaching.attacks.optimization_based_attack.OptimizationBasedAttack object at 0x7f1d48693a00>\n"
     ]
    }
   ],
   "source": [
    "print(user)\n",
    "print(server)\n",
    "print(attacker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415ed234",
   "metadata": {},
   "source": [
    "## Malicious server I : Modify the model architecture first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9155afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_paths = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bceb1476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNetSmall(\n",
       "  (model): Sequential(\n",
       "    (conv0): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu0): ReLU()\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu1): ReLU()\n",
       "    (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (relu2): ReLU()\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (relu3): ReLU()\n",
       "    (pool1): AdaptiveAvgPool2d(output_size=1)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (1): Hardtanh(min_val=0, max_val=1)\n",
       "      (2): Linear(in_features=2, out_features=1024, bias=True)\n",
       "      (3): Linear(in_features=1024, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dim = server.model.model[-5].out_channels\n",
    "server.model.model[-1] = torch.nn.Sequential(torch.nn.Linear(feature_dim, num_paths),\n",
    "                                             torch.nn.Hardtanh(min_val=0, max_val=1), \n",
    "                                             torch.nn.Linear(num_paths, feature_dim),\n",
    "                                             server.model.model[-1]\n",
    "                                             #torch.nn.Linear(num_paths, server.model.model[-1].out_features)\n",
    "                                            ).to(**setup)\n",
    "\n",
    "\n",
    "attacker.model_template = copy.deepcopy(server.model)\n",
    "user.model = copy.deepcopy(server.model)\n",
    "user.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b64eb3",
   "metadata": {},
   "source": [
    "## Malicious server II: Include paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da02a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old first layer:\n",
    "# new_weight = module.weight.new_zeros(module.in_channels, module.in_channels, *module.kernel_size)\n",
    "# torch.nn.init.orthogonal_(new_weight)\n",
    "# new_bias = module.bias.new_zeros(module.in_channels)\n",
    "# fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(new_weight)\n",
    "# torch.nn.init.uniform_(new_bias, -1 / math.sqrt(fan_in), 1 / math.sqrt(fan_in))\n",
    "\n",
    "# # Replicate filters:\n",
    "# replication_dim = module.out_channels // module.in_channels\n",
    "# replicated_weight = torch.cat([new_weight] * replication_dim).contiguous()\n",
    "# replicated_bias = torch.cat([new_bias] * replication_dim).contiguous()\n",
    "\n",
    "# module.weight.data[:replication_dim * module.in_channels] = replicated_weight\n",
    "# module.bias.data[:replication_dim * module.in_channels] = replicated_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "600d1550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 3, 3]) torch.Size([256])\n",
      "tensor([ 0.0372, -0.4762, -0.0203, -0.9738], device='cuda:1') tensor([ 0.0372, -0.4762, -0.0203, -0.9738], device='cuda:1')\n",
      "torch.Size([512, 256, 3, 3]) torch.Size([512])\n",
      "tensor([-0.2809,  0.6275, -0.7757,  0.0211], device='cuda:1') tensor([-0.2809,  0.6275, -0.7757,  0.0211], device='cuda:1')\n",
      "torch.Size([1024, 512, 3, 3]) torch.Size([1024])\n",
      "tensor([ 0.2047,  0.1981, -0.4277,  0.2228], device='cuda:1') tensor([ 0.2047,  0.1981, -0.4277,  0.2228], device='cuda:1')\n",
      "torch.Size([1024, 1024, 3, 3]) torch.Size([1024])\n",
      "tensor([ 1.0229,  0.9889, -0.1559,  0.2184], device='cuda:1') tensor([ 1.0229,  0.9889, -0.1559,  0.2184], device='cuda:1')\n",
      "Model architecture <class 'breaching.cases.models.model_preparation.ConvNetSmall'> loaded with 7,690,730 non-zero parameters of which 13322 are in linear layers.\n",
      "Overall this is a data ratio of 2499.16:1 for target shape [1, 3, 32, 32] if pathcount was optimal.\n"
     ]
    }
   ],
   "source": [
    "input_path_width = 3\n",
    "first_conv = True\n",
    "with torch.no_grad():\n",
    "    for name, module in server.model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            # Initialize existing params at zero:\n",
    "            module.weight.data = torch.zeros_like(module.weight)\n",
    "            module.bias.data = torch.zeros_like(module.bias)\n",
    "            \n",
    "            output_path_width = module.out_channels // num_paths\n",
    "            \n",
    "            new_weight = module.weight.new_zeros(output_path_width, input_path_width,  *module.kernel_size)\n",
    "            torch.nn.init.orthogonal_(new_weight)\n",
    "\n",
    "            new_bias = module.bias.new_zeros(output_path_width)\n",
    "            fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(new_weight)\n",
    "            torch.nn.init.uniform_(new_bias, -1 / math.sqrt(fan_in), 1 / math.sqrt(fan_in))\n",
    "\n",
    "            # Group channels:\n",
    "            ii, io = 0, 0 # index-in index-out\n",
    "            if first_conv:\n",
    "                for path in range(num_paths):\n",
    "                    module.weight.data[io:io+output_path_width, :] = new_weight.clone()\n",
    "                    io += output_path_width\n",
    "                    ii += input_path_width\n",
    "                first_conv = False\n",
    "            else:\n",
    "                for path in range(num_paths):\n",
    "                    module.weight.data[io:io+output_path_width, ii:ii+input_path_width] = new_weight.clone()\n",
    "                    io += output_path_width\n",
    "                    ii += input_path_width\n",
    "                \n",
    "            module.bias.data[:output_path_width * num_paths] = torch.cat([new_bias] * num_paths).contiguous()\n",
    "            \n",
    "            # Set input->output\n",
    "            input_path_width = output_path_width\n",
    "            \n",
    "            \n",
    "            print(module.weight.shape, module.bias.shape)\n",
    "            # Test channel:\n",
    "            inputs = torch.cat([torch.randn(1, 1, 32, 32, **setup)] * module.in_channels, dim=1)\n",
    "            feats = module(inputs)\n",
    "            print(feats[0,0:4, 0, 0], feats[0,output_path_width:output_path_width+4, 0, 0])\n",
    "        if isinstance(module, torch.nn.Linear) and module.out_features == num_paths:\n",
    "            # prep averaging layer here\n",
    "            module.weight.data = torch.zeros_like(module.weight.data)\n",
    "            module.bias.data = torch.zeros_like(module.bias.data)\n",
    "            new_block = module.weight.data.new_zeros(input_path_width) / input_path_width\n",
    "            # new_block[0] = 1\n",
    "            torch.nn.init.uniform_(new_block)\n",
    "            idx = 0\n",
    "            for path in range(num_paths):\n",
    "                module.weight.data[path, idx:idx+input_path_width] = new_block.clone()\n",
    "                idx += input_path_width\n",
    "            adaptation_layer = module\n",
    "        if isinstance(module, torch.nn.Linear) and module.in_features == num_paths:\n",
    "            # prep return layer here, all inputs need to be picked up\n",
    "            module.weight.data = torch.ones_like(module.weight.data) \n",
    "            torch.nn.init.orthogonal_(module.weight.data) * num_paths**2\n",
    "            module.bias.data = torch.zeros_like(module.bias.data)\n",
    "            # pass\n",
    "            # dont mess with the return layer\n",
    "            \n",
    "num_params = sum([(p.abs() > 1e-7).sum() for p in server.model.parameters()])\n",
    "linear_params = sum([(p.abs() > 1e-7).sum() for m in server.model.modules() for p in m.parameters()  \n",
    "                     if isinstance(m, torch.nn.Linear)])\n",
    "print(f'Model architecture {server.model.__class__} loaded with {num_params:,} non-zero parameters of which '\n",
    "      f'{linear_params} are in linear layers.')\n",
    "\n",
    "target_information = cfg.case.user.num_data_points * torch.as_tensor(cfg.case.data.shape).prod()\n",
    "\n",
    "print(f'Overall this is a data ratio of {(num_params - linear_params) / target_information:2.2f}:1 '\n",
    "      f'for target shape {[cfg.case.user.num_data_points, *cfg.case.data.shape]} if pathcount was optimal.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a84e80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.4257, 20.4257]], device='cuda:1', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.randn(1, 3, 32, 32, **setup)\n",
    "feats = _return_model_features(server.model, inputs)\n",
    "feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d937d183",
   "metadata": {},
   "source": [
    "# Compute bins and set feature distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61f8e64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import NormalDist\n",
    "\n",
    "def get_bins_by_mass(num_bins, mu=0, sigma=1):\n",
    "    bins = []\n",
    "    mass = 0\n",
    "    for path in range(num_bins + 1):\n",
    "        mass += 1 / (num_bins + 2)\n",
    "        bins += [NormalDist(mu=mu, sigma=sigma).inv_cdf(mass)]\n",
    "    bin_sizes = [bins[i + 1] - bins[i] for i in range(len(bins) - 1)]\n",
    "    return bins[:-1], bin_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "064ec994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-0.43072729929545744], [0.8614545985909148])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bins_by_mass(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a6c581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict()\n",
    "def named_hook(name):\n",
    "    def hook_fn(module, input, output):\n",
    "        features[name] = output\n",
    "    return hook_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a9728cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial mean of layer model.conv0 is -0.012619388289749622, std is 0.45998886227607727\n",
      "Fixed mean of layer model.conv0 is 0.015213984064757824, std is 0.9770948886871338\n",
      "Initial mean of layer model.conv1 is -0.024468757212162018, std is 0.7137800455093384\n",
      "Fixed mean of layer model.conv1 is -0.00039177294820547104, std is 0.9995455741882324\n",
      "Initial mean of layer model.conv2 is -0.03470901399850845, std is 0.6715343594551086\n",
      "Fixed mean of layer model.conv2 is 4.3511390686035156e-05, std is 1.0001041889190674\n",
      "Initial mean of layer model.conv3 is -0.029414596036076546, std is 0.8184526562690735\n",
      "Fixed mean of layer model.conv3 is -2.429307460261043e-05, std is 0.9999672174453735\n",
      "Initial mean of layer model.linear.0 is 99.83885192871094, std is 18.845849990844727\n",
      "Fixed mean of layer model.linear.0 is 1.1920928955078125e-07, std is 1.0\n",
      "Input to hardtanh before bias and scale is set: tensor([-0.3252, -0.3252], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    for name, module in server.model.named_modules():\n",
    "        if isinstance(module, (torch.nn.Conv2d, torch.nn.Linear)):\n",
    "            hook = module.register_forward_hook(named_hook(name))\n",
    "\n",
    "            random_data_sample = next(iter(server.external_dataloader))[0].to(**setup)\n",
    "            # random_data_sample = torch.randn(1024, 3, 32, 32, **setup)\n",
    "            # random_data_sample = true_user_data['data'] #ground truth data sampâle for testing\n",
    "\n",
    "            server.model(random_data_sample)\n",
    "            std, mu = torch.std_mean(features[name])\n",
    "            print(f'Initial mean of layer {name} is {mu.item()}, std is {std.item()}')\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                module.weight.data /= std + 1e-8\n",
    "                module.bias.data -= mu / (std  + 1e-8)\n",
    "\n",
    "            server.model(random_data_sample)\n",
    "            std, mu = torch.std_mean(features[name])\n",
    "            print(f'Fixed mean of layer {name} is {mu.item()}, std is {std.item()}')  \n",
    "            hook.remove()\n",
    "            \n",
    "            if isinstance(module, torch.nn.Linear) and module.out_features == num_paths:\n",
    "                # Verify:\n",
    "                print(f'Input to hardtanh before bias and scale is set: {features[name][0]}')\n",
    "\n",
    "                adapt_module = module\n",
    "                # Modify bins in this layer\n",
    "                bins, bin_sizes = get_bins_by_mass(num_paths, mu=mu, sigma=std)\n",
    "                # Safety wheels:\n",
    "                #bins = [b * 2 for b in bins]\n",
    "                #bin_sizes = [b * 2 for b in bin_sizes]\n",
    "                #bins = torch.linspace(-1.96, 1.96, num_paths + 1)\n",
    "                #bin_sizes = [bins[i + 1] - bins[i] for i in range(len(bins) - 1)]\n",
    "                #bins = bins[:-1]\n",
    "                \n",
    "                # Old mod:\n",
    "                module.weight.data /= torch.as_tensor(bin_sizes, **setup)[:, None]\n",
    "                module.bias.data -= torch.as_tensor(bins, **setup)\n",
    "                module.bias.data /= torch.as_tensor(bin_sizes, **setup)\n",
    "\n",
    "                # New computation with extend bin extension?:\n",
    "#                 I = -NormalDist(mu=0, sigma=1).inv_cdf(0.90)\n",
    "#                 module.weight.data *= 2 * I / torch.as_tensor(bin_sizes, **setup)[:, None]\n",
    "#                 module.bias.data -= torch.as_tensor(bins, **setup) \n",
    "#                 module.bias.data *= 2 * I / torch.as_tensor(bin_sizes, **setup)\n",
    "#                 module.bias.data -= I\n",
    "                hook.remove()\n",
    "                break\n",
    "            del features[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dad08e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_payload = server.distribute_payload()\n",
    "shared_data, true_user_data = user.compute_local_updates(server_payload)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c3d6f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    hook = adapt_module.register_forward_hook(named_hook('hardtanh_input'))\n",
    "    # random_data_sample = next(iter(server.external_dataloader))[0].to(**setup)\n",
    "    # random_data_sample = torch.randn(1024, 3, 32, 32, **setup)\n",
    "    random_data_sample = true_user_data['data'] #ground truth data sample for testing\n",
    "\n",
    "    server.model(random_data_sample)\n",
    "    hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90beb2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5992, -0.4008], device='cuda:1')\n",
      "tensor([0.5992, 0.0000], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "print(features['hardtanh_input'][0])\n",
    "threshold = torch.nn.functional.hardtanh(features['hardtanh_input'][0], min_val=0, max_val=1)\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcd3b94",
   "metadata": {},
   "source": [
    "### Threshold stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1b07dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:1')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 0], device='cuda:1')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = torch.nn.functional.hardtanh(features['hardtanh_input'], min_val=0, max_val=1)\n",
    "print(((threshold != 1) & (threshold != 0)).sum() / random_data_sample.shape[0])\n",
    "((threshold != 1) & (threshold != 0)).sum(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e56b03",
   "metadata": {},
   "source": [
    "### Simulate an attacked FL protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058bcc2",
   "metadata": {},
   "source": [
    "True user data is returned only for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0dbd868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1798, device='cuda:1'), tensor(1.0388, device='cuda:1'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_payload = server.distribute_payload()\n",
    "shared_data, true_user_data = user.compute_local_updates(server_payload)  \n",
    "\n",
    "true_user_data['data'].mean(), true_user_data['data'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b460cadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor(-0.0006, device='cuda:1'), tensor(0.0025, device='cuda:1')),\n",
       " (tensor(-0.0015, device='cuda:1'), tensor(0.0022, device='cuda:1')),\n",
       " (tensor(-0.0003, device='cuda:1'), tensor(0.0009, device='cuda:1')),\n",
       " (tensor(-0.0007, device='cuda:1'), tensor(0.0013, device='cuda:1')),\n",
       " (tensor(-0.0002, device='cuda:1'), tensor(0.0005, device='cuda:1')),\n",
       " (tensor(-0.0004, device='cuda:1'), tensor(0.0008, device='cuda:1')),\n",
       " (tensor(-0.0005, device='cuda:1'), tensor(0.0006, device='cuda:1')),\n",
       " (tensor(-0.0009, device='cuda:1'), tensor(0.0008, device='cuda:1')),\n",
       " (tensor(-0.0170, device='cuda:1'), tensor(0.0157, device='cuda:1')),\n",
       " (tensor(-0.0429, device='cuda:1'), tensor(nan, device='cuda:1')),\n",
       " (tensor(-9.1128e-05, device='cuda:1'), tensor(0.0105, device='cuda:1')),\n",
       " (tensor(-0.0002, device='cuda:1'), tensor(0.0175, device='cuda:1')),\n",
       " (tensor(-1.1360e-10, device='cuda:1'), tensor(0.0056, device='cuda:1')),\n",
       " (tensor(-5.9605e-09, device='cuda:1'), tensor(0.3160, device='cuda:1'))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(g[g.abs() > 1e-6].mean(), g[g.abs() > 1e-6].std()) for g in shared_data['gradients'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ea3d810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000, device='cuda:1')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparsity:\n",
    "(shared_data['gradients'][0][0].abs() > 1e-8).sum() / shared_data['gradients'][0][0].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f67c9b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9529, device='cuda:1')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([g.pow(2).sum() for g in shared_data['gradients'][0][:-4]]).sum().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49c68628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "user.plot(true_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17255c5a",
   "metadata": {},
   "source": [
    "### Reconstruct user data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cce472fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNetSmall(\n",
       "  (model): Sequential(\n",
       "    (conv0): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu0): ReLU()\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu1): ReLU()\n",
       "    (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (relu2): ReLU()\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (relu3): ReLU()\n",
       "    (pool1): AdaptiveAvgPool2d(output_size=1)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (1): Identity()\n",
       "      (2): Linear(in_features=2, out_features=1024, bias=True)\n",
       "      (3): Linear(in_features=1024, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacker.model_template.model.linear[1] = torch.nn.Identity()\n",
    "attacker.model_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a2f0092",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 1. Rec. loss: 0.0867. T: 0.06s\n",
      "It: 1001. Rec. loss: 0.0057. T: 20.38s\n",
      "It: 2001. Rec. loss: 0.0061. T: 20.13s\n",
      "It: 3001. Rec. loss: 0.0046. T: 20.13s\n",
      "It: 4001. Rec. loss: 0.0065. T: 20.08s\n",
      "It: 5001. Rec. loss: 0.0062. T: 20.08s\n",
      "It: 6001. Rec. loss: 0.0053. T: 20.09s\n",
      "It: 7001. Rec. loss: 0.0052. T: 20.08s\n",
      "It: 8001. Rec. loss: 0.0051. T: 20.12s\n",
      "It: 9001. Rec. loss: 0.0045. T: 20.11s\n",
      "It: 10001. Rec. loss: 0.0029. T: 20.19s\n",
      "It: 11001. Rec. loss: 0.0029. T: 20.09s\n",
      "It: 12001. Rec. loss: 0.0029. T: 20.09s\n",
      "It: 13001. Rec. loss: 0.0030. T: 20.09s\n",
      "It: 14001. Rec. loss: 0.0028. T: 20.10s\n",
      "It: 15001. Rec. loss: 0.0028. T: 20.14s\n",
      "It: 16001. Rec. loss: 0.0026. T: 20.07s\n",
      "It: 17001. Rec. loss: 0.0026. T: 20.11s\n",
      "It: 18001. Rec. loss: 0.0027. T: 20.09s\n",
      "It: 19001. Rec. loss: 0.0027. T: 20.10s\n",
      "It: 20001. Rec. loss: 0.0027. T: 20.10s\n",
      "It: 21001. Rec. loss: 0.0027. T: 20.08s\n",
      "It: 22001. Rec. loss: 0.0027. T: 20.10s\n",
      "It: 23001. Rec. loss: 0.0026. T: 20.11s\n",
      "It: 24000. Rec. loss: 0.0027. T: 20.11s\n",
      "Optimal condidate solution with rec. loss 0.0265 selected.\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/jonas/miniconda3/envs/dl/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth\n",
      "METRICS: | MSE: 0.0014 | PSNR: 28.51 | FMSE: 2.2397e-05 | LPIPS: 0.00| R-PSNR: 28.51 | IIP-pixel: 100.00%\n"
     ]
    }
   ],
   "source": [
    "reconstructed_user_data, stats = attacker.reconstruct(server_payload, shared_data, \n",
    "                                                      server.secrets, dryrun=cfg.dryrun)\n",
    "\n",
    "# How good is the reconstruction?\n",
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, \n",
    "                                    server_payload, server.model, user.dataloader, setup=setup,\n",
    "                                    order_batch=True, compute_full_iip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "631f4a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "user.plot(reconstructed_user_data, scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03d28b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/jonas/miniconda3/envs/dl/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth\n",
      "METRICS: | MSE: 0.0014 | PSNR: 28.51 | FMSE: 2.2397e-05 | LPIPS: 0.00| R-PSNR: 28.51 | IIP-pixel: 100.00% | IIP-lpips: 100.00% | IIP-self: 100.00%\n"
     ]
    }
   ],
   "source": [
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, \n",
    "                                    server_payload, server.model, user.dataloader, setup=setup,\n",
    "                                    order_batch=True, compute_full_iip=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
