{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebef44a",
   "metadata": {},
   "source": [
    "# Breaching privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756fc5f",
   "metadata": {},
   "source": [
    "This notebook does the same job as the cmd-line tool `simulate_breach.py`, but also directly visualizes the user data and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import breaching\n",
    "import logging, sys\n",
    "logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler(sys.stdout)], format='%(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5e214",
   "metadata": {},
   "source": [
    "### Initialize cfg object and system setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd663b",
   "metadata": {},
   "source": [
    "This will print out all configuration options. \n",
    "There are a lot of possible configurations, but there is usually no need to worry about most of these. Below, a few options are printed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26070d66",
   "metadata": {},
   "source": [
    "Choose `case/data=` `shakespeare`, `wikitext`over `stackoverflow` here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc3a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize(config_path=\"config\"):\n",
    "    cfg = hydra.compose(config_name='cfg', overrides=['case/data=stackoverflow', \n",
    "                                                      'attack=tag'])\n",
    "    print(f'Investigating use case {cfg.case.name} with server type {cfg.case.server.name}.')\n",
    "          \n",
    "device = torch.device(f'cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.backends.cudnn.benchmark = cfg.case.impl.benchmark\n",
    "setup = dict(device=device, dtype=torch.float)\n",
    "setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c5fb1",
   "metadata": {},
   "source": [
    "### Modify config options here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0764ef",
   "metadata": {},
   "source": [
    "You can use `.attribute` access to modify any of these configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac118ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.case.user.num_data_points = 1 # How many sentences?\n",
    "cfg.case.user.user_idx = 0 # From which user?\n",
    "cfg.case.data.shape = [32] # This is the sequence length\n",
    "\n",
    "cfg.case.model=\"linear\"\n",
    "cfg.case.server.pretrained=False\n",
    "cfg.case.data.tokenizer = \"bert-base-uncased\"\n",
    "cfg.case.data.task =  \"causal-lm\"\n",
    "# cfg.case.data.vocab_size =  30522\n",
    "cfg.case.data.mlm_probability =  0.1\n",
    "\n",
    "cfg.attack.attack_type = \"permutation-optimization\"\n",
    "cfg.attack.label_strategy = \"bias-text\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f64389",
   "metadata": {},
   "source": [
    "### Instantiate all parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30235b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user, server, model, loss_fn = breaching.cases.construct_case(cfg.case, setup)\n",
    "attacker = breaching.attacks.prepare_attack(server.model, server.loss, cfg.attack, setup)\n",
    "breaching.utils.overview(server, user, attacker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c0ad6",
   "metadata": {},
   "source": [
    "### Simulate an attacked FL protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058bcc2",
   "metadata": {},
   "source": [
    "True user data is returned only for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aebc03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a2e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_payload = server.distribute_payload()\n",
    "shared_data, true_user_data = user.compute_local_updates(server_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.print(true_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2867bcc",
   "metadata": {},
   "source": [
    "# Reconstruct user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04521004",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reconstructed_user_data, stats = attacker.reconstruct([server_payload], [shared_data], \n",
    "#                                                       server.secrets, dryrun=cfg.dryrun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c4ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally return a dict with keys data and labels\n",
    "reconstructed_user_data = dict(data=None, labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b7388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user.print(reconstructed_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fdbf58",
   "metadata": {},
   "source": [
    "### Check metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b4750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "#                                    server.model, cfg_case=cfg.case, setup=setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd727074",
   "metadata": {},
   "outputs": [],
   "source": [
    "[g.shape for g in shared_data[\"gradients\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b431ca1",
   "metadata": {},
   "source": [
    "# Tokens from decoder bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b58b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_data[\"gradients\"][-5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = cfg.case.data.shape\n",
    "num_data_points = cfg.case.user.num_data_points\n",
    "\n",
    "num_missing_tokens = num_data_points * data_shape[0]\n",
    "\n",
    "# This is slightly modified analytic label recovery in the style of Wainakh\n",
    "bias_per_query = [shared_data[\"gradients\"][-5]]\n",
    "token_list = []\n",
    "# Stage 1\n",
    "average_bias = torch.stack(bias_per_query).mean(dim=0)\n",
    "valid_classes = (average_bias < 0).nonzero()\n",
    "token_list += [*valid_classes.squeeze(dim=-1)]\n",
    "# tokens_in_input = shared_data[\"gradients\"][0].norm(dim=-1).nonzero().squeeze(dim=-1)\n",
    "# for token in tokens_in_input:\n",
    "#     if token not in token_list:\n",
    "#         token_list.append(token)\n",
    "\n",
    "m_impact = average_bias_correct_label = average_bias[valid_classes].sum() / num_missing_tokens\n",
    "\n",
    "average_bias[valid_classes] = average_bias[valid_classes] - m_impact\n",
    "# Stage 2\n",
    "while len(token_list) < num_missing_tokens:\n",
    "    selected_idx = average_bias.argmin()\n",
    "    token_list.append(selected_idx)\n",
    "    average_bias[selected_idx] -= m_impact\n",
    "tokens = torch.stack(token_list).view(num_data_points, data_shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93668d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "breaching.analysis.analysis.count_integer_overlap(tokens.view(-1), true_user_data[\"labels\"].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1961c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(shared_data[\"gradients\"][-5]  0).nonzero().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3483f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = true_user_data[\"data\"].view(-1).unique()\n",
    "breaching.analysis.analysis.count_integer_overlap(valid_classes.view(-1), \n",
    "                                                  unique_tokens[:len(valid_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174fe817",
   "metadata": {},
   "outputs": [],
   "source": [
    "(shared_data[\"gradients\"][-5].min(), shared_data[\"gradients\"][-5].max(), shared_data[\"gradients\"][-5].mean(),\n",
    "shared_data[\"gradients\"][-5].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f03daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(shared_data[\"gradients\"][-5] < 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d16e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(#true_tokens=shared_data[\"gradients\"][0][true_user_data[\"data\"].view(-1)].abs().sum(dim=-1).log().tolist(),\n",
    "    all_tokens=shared_data[\"gradients\"][-5].tolist())\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "fig = px.histogram(df, log_y=True, nbins=32, marginal=\"violin\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc88c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_user_data[\"data\"].view(-1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e15a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(#true_tokens=shared_data[\"gradients\"][0][true_user_data[\"data\"].view(-1)].abs().sum(dim=-1).log().tolist(),\n",
    "    all_tokens=shared_data[\"gradients\"][-5].tolist())\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "true_hits = shared_data[\"gradients\"][-5][true_user_data[\"data\"].view(-1)]\n",
    "#df[\"true_tokens\"] = pd.Series(true_hits.tolist())\n",
    "fig = px.histogram(df, x=[\"all_tokens\"], opacity=0.8,log_y=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da4aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(true_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1291cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "rec_labels = tokens.view(-1)\n",
    "true_labels = true_user_data[\"labels\"].view(-1)\n",
    "df = pd.DataFrame(dict(rec_labels=rec_labels.tolist(), true_labels=true_labels.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c75c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x=[\"rec_labels\", \"true_labels\"], opacity=0.8,log_y=True, marginal=\"violin\",\n",
    "                  labels={'rec_labels':'Recovered tokens', \"true_labels\": \"True tokens\"})\n",
    "fig.update_layout(\n",
    "    title_text='Recovered Token Frequency', # title of plot\n",
    "    xaxis_title_text='Token ID', # xaxis label\n",
    "    yaxis_title_text='Count', # yaxis label\n",
    "    bargap=0.2, # gap between bars of adjacent location coordinates\n",
    "    bargroupgap=0.1, # gap between bars of the same location coordinates\n",
    "    barmode='overlay'\n",
    ")\n",
    "fig.update_traces(opacity=0.75)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef886c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df = px.data.tips()\n",
    "fig = px.histogram(df, x=\"total_bill\",\n",
    "                   title='Histogram of bills',\n",
    "                   labels={'total_bill':'total bill'}, # can specify one label per df column\n",
    "                   opacity=0.8,\n",
    "                   log_y=True, # represent bars with log scale\n",
    "                   color_discrete_sequence=['indianred'] # color of histogram bars\n",
    "                   )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af9db14",
   "metadata": {},
   "source": [
    "# Tokens from encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737f6880",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_data[\"gradients\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b28196",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = cfg.case.data.shape\n",
    "num_data_points = cfg.case.user.num_data_points\n",
    "\n",
    "num_missing_tokens = num_data_points * data_shape[0]\n",
    "\n",
    "wte_per_query = [shared_data[\"gradients\"][0]]\n",
    "token_list = []\n",
    "# Stage 1\n",
    "average_wte_norm = torch.stack(wte_per_query).mean(dim=0).norm(dim=1)\n",
    "std, mean = torch.std_mean(average_wte_norm.log())\n",
    "cutoff = mean + 2.5 * std\n",
    "valid_classes = (average_wte_norm.log() > cutoff).nonzero()\n",
    "token_list += [*valid_classes.squeeze(dim=-1)]\n",
    "\n",
    "top2 = average_wte_norm.log().topk(k=2).values\n",
    "m_impact = top2[0] - top2[1]\n",
    "# m_impact = average_wte_norm[valid_classes].sum() / num_missing_tokens\n",
    "# average_wte_norm_log[valid_classes] = average_wte_norm_log[valid_classes] - m_impact\n",
    "\n",
    "average_wte_norm[valid_classes] = average_wte_norm[valid_classes] - m_impact\n",
    "# Stage 2\n",
    "while len(token_list) < num_missing_tokens:\n",
    "    selected_idx = valid_classes[average_wte_norm[valid_classes].argmax()].squeeze()\n",
    "    token_list.append(selected_idx)\n",
    "    # print(selected_idx, average_wte_norm_log[selected_idx])\n",
    "    average_wte_norm[selected_idx] -= m_impact\n",
    "tokens = torch.stack(token_list).view(num_data_points, data_shape[0])\n",
    "breaching.analysis.analysis.count_integer_overlap(tokens.view(-1), true_user_data[\"labels\"].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7bcc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = true_user_data[\"data\"].view(-1).unique()\n",
    "breaching.analysis.analysis.count_integer_overlap(valid_classes.view(-1)[:len(unique_tokens)], \n",
    "                                                  unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da8db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(#true_tokens=shared_data[\"gradients\"][0][true_user_data[\"data\"].view(-1)].abs().sum(dim=-1).log().tolist(),\n",
    "    all_tokens=shared_data[\"gradients\"][0].norm(dim=-1).log().tolist())\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "true_hits = shared_data[\"gradients\"][0].norm(dim=-1)[true_user_data[\"data\"].view(-1).unique()]\n",
    "df[\"true_tokens\"] = pd.Series(true_hits.log().tolist())\n",
    "fig = px.histogram(df, x=[\"all_tokens\", \"true_tokens\"], opacity=0.8,log_y=False, marginal=\"violin\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991dfc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57cfe2f",
   "metadata": {},
   "source": [
    "# Test embedding tie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8158324",
   "metadata": {},
   "outputs": [],
   "source": [
    "user, server, model, loss_fn = breaching.cases.construct_case(cfg.case, setup)\n",
    "attacker = breaching.attacks.prepare_attack(server.model, server.loss, cfg.attack, setup)\n",
    "\n",
    "server_payload = server.distribute_payload()\n",
    "shared_data, true_user_data = user.compute_local_updates(server_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8a35e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_embeddings = user.model.encoder(true_user_data[\"data\"]).detach()\n",
    "true_labels = true_user_data[\"labels\"]\n",
    "\n",
    "obj = attacker.objective\n",
    "obj.initialize(attacker.loss_fn, cfg.case.impl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83202ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_payload[\"parameters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f871e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient, task_loss = attacker.objective._grad_fn(user.model.decoder, true_embeddings, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466f8f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.dist(gradient[0], shared_data[\"gradients\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26edfad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rec_grad, shared_grad in zip(gradient, shared_data[\"gradients\"]):\n",
    "    print(torch.dist(rec_grad, shared_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a87b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(shared_data[\"gradients\"][1] - gradient[1]).norm(dim=-1).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e0f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_positions = shared_data[\"gradients\"][0].norm(dim=-1).nonzero().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c02af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "(shared_data[\"gradients\"][0] - gradient[0])[relevant_positions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_data[\"gradients\"][1].nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc471b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_user_data[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f551c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15278080",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = user.dataloader.dataset.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9d230f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_tokens = []\n",
    "for year in range(0, 1000):\n",
    "    token = tokenizer(str(year))\n",
    "    untokenized = [tokenizer.decode(t) for t in token[\"input_ids\"]]\n",
    "    if len(untokenized) == 3:\n",
    "        full_tokens.append(year)\n",
    "        # print(token[\"input_ids\"])\n",
    "    \n",
    "len(full_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf708f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = []\n",
    "for token in range(tokenizer.vocab_size):\n",
    "    decoded = tokenizer.decode(token)\n",
    "    if any([d.isdigit() for d in decoded]) and \"unused\" not in decoded:\n",
    "        if \"1\" in decoded and not any([decoded in str(year) for year in range(1000, 2022)]):\n",
    "            numbers.append(decoded)\n",
    "    # if decoded.isdigit():\n",
    "    #    # print(decoded)\n",
    "    #    try:\n",
    "    #        numbers.append(int(decoded))\n",
    "    #    except:\n",
    "    #        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162564f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\",\".join(sorted(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb9ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = list(set(numbers))\n",
    "numbers.sort()\n",
    "print(\",\".join([str(n) for n in numbers]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a3d5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
