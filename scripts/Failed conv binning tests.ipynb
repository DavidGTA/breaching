{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebef44a",
   "metadata": {},
   "source": [
    "# Breaching privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756fc5f",
   "metadata": {},
   "source": [
    "This notebook does the same job as the cmd-line tool `breach.py`, but also directly visualizes the user data and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import breaching\n",
    "\n",
    "import copy\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5e214",
   "metadata": {},
   "source": [
    "### Initialize cfg object and system setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd663b",
   "metadata": {},
   "source": [
    "This will print out all configuration options. \n",
    "There are a lot of possible configurations, but there is usually no need to worry about most of these. Below, a few options are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc3a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize(config_path=\"config\"):\n",
    "    cfg = hydra.compose(config_name='cfg', overrides=['attack=invertinggradients',\n",
    "                                                      'case=1_single_image_small'])\n",
    "    print(f'Investigating use case {cfg.case.name} with server type {cfg.case.server.name}.')\n",
    "    print('Attack settings are:')\n",
    "    print(OmegaConf.to_yaml(cfg.attack))\n",
    "          \n",
    "device = torch.device(f'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.backends.cudnn.benchmark = cfg.case.impl.benchmark\n",
    "setup = dict(device=device, dtype=getattr(torch, cfg.case.impl.dtype))\n",
    "setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c5fb1",
   "metadata": {},
   "source": [
    "### Modify config options here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0764ef",
   "metadata": {},
   "source": [
    "You can use `.attribute` access to modify any of these configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac118ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.case.user.data_idx = 0\n",
    "cfg.case.model='ConvNetSmall'\n",
    "\n",
    "cfg.case.user.num_data_points=10\n",
    "\n",
    "\n",
    "cfg.case.server.model_state = 'trained'\n",
    "\n",
    "# The total variation scale should be small for CIFAR images\n",
    "cfg.attack.regularization.total_variation.scale = 1e-4\n",
    "\n",
    "cfg.attack.objective.type = 'cosine-similarity'\n",
    "cfg.attack.objective.scale = 1\n",
    "cfg.attack.optim.signed=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f64389",
   "metadata": {},
   "source": [
    "### Instantiate all parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3abd955",
   "metadata": {},
   "outputs": [],
   "source": [
    "user, server = breaching.cases.construct_case(cfg.case, setup)\n",
    "attacker = breaching.attacks.prepare_attack(server.model, server.loss, cfg.attack, setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7273d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(user)\n",
    "print(server)\n",
    "print(attacker)\n",
    "\n",
    "server.model.to(**setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1ffba9",
   "metadata": {},
   "source": [
    "## Malicious server: Modify the model parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4298b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_set = False\n",
    "with torch.no_grad():\n",
    "    for module in server.model.modules():\n",
    "        # if isinstance(module, torch.nn.BatchNorm2d):\n",
    "            # module.weight.data = module.running_var.data.clone()\n",
    "            # module.bias.data = module.running_mean.data.clone() + 10\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "# Grouping stuff:\n",
    "#             num_groups = module.out_channels // module.in_channels\n",
    "#             surviving_features = module.weight[:module.in_channels, 0:1]\n",
    "#             torch.nn.init.orthogonal_(surviving_features)\n",
    "#             module.weight.data = torch.zeros_like(module.weight)\n",
    "                \n",
    "#             idx = 0\n",
    "#             for group in range(num_groups):\n",
    "#                 module.weight.data[idx:idx+module.in_channels, group:group+1] = surviving_features\n",
    "#                 idx += module.in_channels\n",
    "\n",
    "# Other replication stuff:            \n",
    "            initial_filters = module.weight[0:1]\n",
    "            torch.nn.init.orthogonal_(initial_filters)\n",
    "            #torch.nn.init.dirac_(initial_filters)\n",
    "            # torch.nn.init.constant_(initial_filters, 1.0)\n",
    "            #print(initial_filters.data)\n",
    "            initial_filters = torch.eye(3, **setup).repeat(1, module.in_channels, 1, 1)\n",
    "            module.weight.data = torch.cat([initial_filters] * module.out_channels).contiguous()\n",
    "            module.bias.data = torch.zeros_like(module.bias.data)\n",
    "            \n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            # module.bias.data = torch.zeros_like(module.bias.data)\n",
    "            # module.weight.data = torch.cat([module.weight.data[0:1]] * module.weight.shape[0], dim=0).contiguous()\n",
    "            torch.nn.init.orthogonal_(module.weight.data)\n",
    "            \n",
    "#     for module in user.model.modules():\n",
    "#         if isinstance(module, torch.nn.Conv2d):\n",
    "#             module.groups = module.in_channels        \n",
    "#     for module in attacker.model_template.modules():\n",
    "#         if isinstance(module, torch.nn.Conv2d):\n",
    "#             module.groups = module.in_channels   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da065f50",
   "metadata": {},
   "source": [
    "### Mess up activations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4c10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModdedHardTanh(torch.nn.Module):\n",
    "    def __init__(self, min_val=-1, max_val=1):\n",
    "        super().__init__()\n",
    "        self.hardtanh = torch.nn.Hardtanh(min_val, max_val)\n",
    "        self.min_val = self.hardtanh.min_val\n",
    "        self.max_val = self.hardtanh.max_val\n",
    "    def forward(self, inputs):\n",
    "        return (self.hardtanh(inputs) + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc5a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_relu_to(model, activation=torch.nn.Sigmoid, args=[]):\n",
    "    for child_name, child in model.named_children():\n",
    "        if isinstance(child, torch.nn.ReLU):\n",
    "            setattr(model, child_name, activation(*args))\n",
    "        else:\n",
    "            convert_relu_to(child, activation, args)\n",
    "            \n",
    "\n",
    "new_activation = ModdedHardTanh\n",
    "args = [0, 1]\n",
    "\n",
    "convert_relu_to(server.model, activation=new_activation, args=args)\n",
    "convert_relu_to(user.model, activation=new_activation, args=args)\n",
    "convert_relu_to(attacker.model_template, activation=new_activation, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe2f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "server.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca20f11",
   "metadata": {},
   "source": [
    "### Space biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf43dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict()\n",
    "in_features = dict()\n",
    "def named_hook(name):\n",
    "    def hook_fn(module, input, output):\n",
    "        features[name] = output\n",
    "        in_features[name] = input[0]\n",
    "    return hook_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289e2b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for name, module in server.model.named_modules():\n",
    "        if isinstance(module, (torch.nn.Conv2d)):\n",
    "            hook = module.register_forward_hook(named_hook(name))\n",
    "\n",
    "\n",
    "            # random_data_sample = torch.randn(1024, 3, 32, 32, **setup)\n",
    "            random_data_sample = true_user_data['data'] #ground truth data sample for testing\n",
    "\n",
    "            module.bias.data = torch.zeros_like(module.bias)\n",
    "\n",
    "            server.model(random_data_sample)\n",
    "            std, mu = torch.std_mean(features[name])\n",
    "            print(f'mean of layer {name} is {mu.item()}, std is {std.item()}')\n",
    "            with torch.no_grad():\n",
    "                module.weight.data = module.weight.data / (std  + 1e-6)\n",
    "                module.bias.data = torch.linspace(-1.96 - mu, 1.96 + mu, module.bias.numel()).to(**setup)\n",
    "                bin_val = module.bias.data[1] - module.bias.data[0]\n",
    "                print(bin_val)\n",
    "            \n",
    "            server.model(random_data_sample)\n",
    "            std, mu = torch.std_mean(features[name])\n",
    "            print(f'mean of layer {name} is {mu.item()}, std is {std.item()}')  \n",
    "            \n",
    "            hook.remove()\n",
    "            \n",
    "        if isinstance(module, (torch.nn.Hardtanh, ModdedHardTanh)):\n",
    "            module.min_val = 0\n",
    "            module.max_val = bin_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de231f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features['model.conv1'][0,:,0,0] - server.model.model[2].bias)\n",
    "print(features['model.conv1'][:,0,0,0] - server.model.model[2].bias[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b3b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map(feature_map):\n",
    "    min_val, max_val = feature_map.amin(dim=[2,3], keepdim=True), feature_map.amax(dim=[2,3], keepdim=True)\n",
    "    renorm_map = (feature_map - min_val) / (max_val - min_val)\n",
    "    print(renorm_map[0, :3].permute(1, 2, 0).detach().cpu().shape)\n",
    "    plt.imshow(renorm_map[0, :3].permute(1, 2, 0).detach().cpu())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70666881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_features(data):\n",
    "    grid_shape = int(torch.as_tensor(data.shape[0]).sqrt().ceil())\n",
    "    s = 10\n",
    "    fig, axes = plt.subplots(grid_shape, grid_shape, figsize=(s, s))\n",
    "    label_classes = []\n",
    "    min_val, max_val = data.amin(dim=[1,2], keepdim=True), data.amax(dim=[1,2], keepdim=True)\n",
    "    # data = (data - min_val) / (data - min_val)\n",
    "    for i, (im, axis) in enumerate(zip(data, axes.flatten())):\n",
    "        axis.imshow(im.cpu())\n",
    "        axis.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def5543",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid_features(features['model.conv1'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1836cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_map(in_features['model.conv0'])\n",
    "plot_map(in_features['model.conv1'].sum(dim=1, keepdim=True))\n",
    "plot_map(in_features['model.conv2'].sum(dim=1, keepdim=True))\n",
    "plot_map(in_features['model.conv3'].sum(dim=1, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df83beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "attacker.model_template = copy.deepcopy(server.model)\n",
    "user.model = copy.deepcopy(server.model)\n",
    "user.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c0ad6",
   "metadata": {},
   "source": [
    "### Simulate an attacked FL protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ad44f",
   "metadata": {},
   "source": [
    "True user data is returned only for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dbd868",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_payload = server.distribute_payload()\n",
    "shared_data, true_user_data = user.compute_local_updates(server_payload)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04114974",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(g.mean(), g.std()) for g in shared_data['gradients'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c68628",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.plot(true_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17255c5a",
   "metadata": {},
   "source": [
    "### Reconstruct user data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f62724",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_user_data, stats = attacker.reconstruct(server_payload, shared_data, \n",
    "                                                      server.secrets, dryrun=cfg.dryrun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0e3b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How good is the reconstruction?\n",
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, \n",
    "                                    server_payload, server.model, setup, order_batch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f6a346",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.plot(reconstructed_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2f0092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How good is the reconstruction?\n",
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, \n",
    "                                    server_payload, server.model, setup, order_batch=True)\n",
    "ordered_user_data = dict(data=reconstructed_user_data['data'][metrics['order']],\n",
    "                         labels=reconstructed_user_data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631f4a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.plot(ordered_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb10a0c8",
   "metadata": {},
   "source": [
    "PSNR without parameter modifications and 10 data points: 16-17"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
