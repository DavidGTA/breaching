{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebef44a",
   "metadata": {},
   "source": [
    "# Breaching privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756fc5f",
   "metadata": {},
   "source": [
    "This notebook does the same job as the cmd-line tool `simulate_breach.py`, but also directly visualizes the user data and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "os.chdir('..')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import breaching\n",
    "import logging, sys\n",
    "logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler(sys.stdout)], format='%(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70450821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5e214",
   "metadata": {},
   "source": [
    "### Initialize cfg object and system setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd663b",
   "metadata": {},
   "source": [
    "This will print out all configuration options. \n",
    "There are a lot of possible configurations, but there is usually no need to worry about most of these. Below, a few options are printed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26070d66",
   "metadata": {},
   "source": [
    "Choose `case/data=` `shakespeare`, `wikitext`over `stackoverflow` here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc3a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize(config_path=\"../config\"):\n",
    "    cfg = hydra.compose(config_name='cfg', overrides=['case/data=wikitext', \"case/server=malicious-transformer\",\n",
    "                                                      'attack=tag'])\n",
    "    print(f'Investigating use case {cfg.case.name} with server type {cfg.case.server.name}.')\n",
    "          \n",
    "device = torch.device(f'cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.backends.cudnn.benchmark = cfg.case.impl.benchmark\n",
    "setup = dict(device=device, dtype=torch.float)\n",
    "setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c5fb1",
   "metadata": {},
   "source": [
    "### Modify config options here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0764ef",
   "metadata": {},
   "source": [
    "You can use `.attribute` access to modify any of these configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac118ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.case.user.num_data_points = 32 # How many sentences?\n",
    "cfg.case.user.user_idx = 1 # From which user?\n",
    "cfg.case.data.shape = [32] # This is the sequence length\n",
    "\n",
    "cfg.case.model=  \"bert-base-uncased\"   # \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "cfg.case.server.pretrained=False\n",
    "cfg.case.data.tokenizer = \"bert-base-uncased\"    # \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "cfg.case.data.task =  \"masked-lm\"\n",
    "cfg.case.data.vocab_size =  30522\n",
    "cfg.case.data.disable_mlm=False\n",
    "cfg.case.data.mlm_probability =  0.15\n",
    "\n",
    "cfg.attack.attack_type = \"permutation-optimization\"\n",
    "cfg.attack.label_strategy = \"bias-text\"\n",
    "\n",
    "cfg.case.server.param_modification.v_length = 8\n",
    "cfg.case.server.param_modification.eps = 1e-6\n",
    "cfg.case.server.param_modification.imprint_sentence_position = 0\n",
    "cfg.case.server.param_modification.softmax_skew = 100000000\n",
    "cfg.case.server.param_modification.sequence_token_weight = 1\n",
    "cfg.case.server.param_modification.measurement_scale = 1\n",
    "\n",
    "cfg.case.server.param_modification.equalize_token_weight = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f64389",
   "metadata": {},
   "source": [
    "### Instantiate all parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30235b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user, server, model, loss_fn = breaching.cases.construct_case(cfg.case, setup)\n",
    "attacker = breaching.attacks.prepare_attack(server.model, server.loss, cfg.attack, setup)\n",
    "breaching.utils.overview(server, user, attacker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161c4724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user.model.model.cls.predictions.decoder.weight = torch.nn.Parameter(user.model.model.cls.predictions.decoder.weight.detach().clone())\n",
    "#server.model.model.cls.predictions.decoder.weight = torch.nn.Parameter(server.model.model.cls.predictions.decoder.weight.detach().clone())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c0ad6",
   "metadata": {},
   "source": [
    "### Simulate an attacked FL protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058bcc2",
   "metadata": {},
   "source": [
    "True user data is returned only for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a2e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_payload = server.distribute_payload()\n",
    "shared_data, true_user_data = user.compute_local_updates(server_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.print(true_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2867bcc",
   "metadata": {},
   "source": [
    "# Reconstruct user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04521004",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reconstructed_user_data, stats = attacker.reconstruct([server_payload], [shared_data], \n",
    "#                                                       server.secrets, dryrun=cfg.dryrun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c4ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally return a dict with keys data and labels\n",
    "reconstructed_user_data = dict(data=None, labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b7388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user.print(reconstructed_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fdbf58",
   "metadata": {},
   "source": [
    "### Check metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b4750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "#                                    server.model, cfg_case=cfg.case, setup=setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfdcf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.model.model.cls.predictions.decoder.weight is user.model.model.bert.embeddings.word_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba6ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[g.shape for g in shared_data[\"gradients\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b431ca1",
   "metadata": {},
   "source": [
    "# Tokens from decoder bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad3de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.case.data.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = cfg.case.data.shape\n",
    "num_data_points = cfg.case.user.num_data_points\n",
    "\n",
    "num_missing_tokens = num_data_points * data_shape[0]\n",
    "\n",
    "# This is slightly modified analytic label recovery in the style of Wainakh\n",
    "bias_per_query = [shared_data[\"gradients\"][-5]]\n",
    "assert len(bias_per_query[0]) == cfg.case.data.vocab_size\n",
    "token_list = []\n",
    "# Stage 1\n",
    "average_bias = torch.stack(bias_per_query).mean(dim=0)\n",
    "valid_classes = (average_bias < 0).nonzero()\n",
    "token_list += [*valid_classes.squeeze(dim=-1)]\n",
    "# tokens_in_input = shared_data[\"gradients\"][0].norm(dim=-1).nonzero().squeeze(dim=-1)\n",
    "# for token in tokens_in_input:\n",
    "#     if token not in token_list:\n",
    "#         token_list.append(token)\n",
    "\n",
    "m_impact = average_bias[valid_classes].sum() / num_missing_tokens\n",
    "\n",
    "average_bias[valid_classes] = average_bias[valid_classes] - m_impact\n",
    "# Stage 2\n",
    "while len(token_list) < num_missing_tokens:\n",
    "    selected_idx = average_bias.argmin(dim=-1)\n",
    "    # selected_idx = valid_classes[average_bias[valid_classes].argmin()].squeeze()\n",
    "    # if average_bias[selected_idx]  - m_impact< 0:\n",
    "    token_list.append(selected_idx)\n",
    "    average_bias[selected_idx] -= m_impact\n",
    "#     else:\n",
    "#         token_list.append(torch.tensor(0))\n",
    "# # Stage 2\n",
    "# while len(token_list) < num_missing_tokens:\n",
    "#     token_list.append(valid_classes[torch.randint(0, len(valid_classes), (1,))].squeeze())\n",
    "\n",
    "    \n",
    "    # print(val, average_bias[selected_idx], selected_idx)\n",
    "tokens = torch.stack(token_list).view(num_data_points, data_shape[0])\n",
    "# Total token recovery:\n",
    "breaching.analysis.analysis.count_integer_overlap(tokens.view(-1), true_user_data[\"data\"].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e6eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75863297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All tokens after average_bias[selected_idx]  - m_impact< 0 are useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a5a30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique token recovery:\n",
    "unique_tokens = true_user_data[\"data\"].view(-1).unique()\n",
    "print(len(unique_tokens), len(valid_classes))\n",
    "padded_classes = torch.cat([valid_classes.view(-1), torch.zeros(len(unique_tokens)-len(valid_classes))])\n",
    "breaching.analysis.analysis.count_integer_overlap(padded_classes.view(-1), unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1291cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_labels = tokens.view(-1)\n",
    "true_labels = true_user_data[\"labels\"].view(-1)\n",
    "df = pd.DataFrame(dict(rec_labels=rec_labels.tolist(), true_labels=true_labels.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c75c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x=[\"rec_labels\", \"true_labels\"], opacity=0.8,log_y=True, marginal=\"violin\",\n",
    "                  labels={'rec_labels':'Recovered tokens', \"true_labels\": \"True tokens\"})\n",
    "fig.update_layout(\n",
    "    title_text='Recovered Token Frequency', # title of plot\n",
    "    xaxis_title_text='Token ID', # xaxis label\n",
    "    yaxis_title_text='Count', # yaxis label\n",
    "    bargap=0.2, # gap between bars of adjacent location coordinates\n",
    "    bargroupgap=0.1, # gap between bars of the same location coordinates\n",
    "    barmode='overlay'\n",
    ")\n",
    "fig.update_traces(opacity=0.75)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98002b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_tokens = true_user_data[\"labels\"].view(-1).unique()[1:]\n",
    "breaching.analysis.analysis.count_integer_overlap(mask_tokens.view(-1), valid_classes.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3138d974",
   "metadata": {},
   "source": [
    "### aside from the masked biases nothing nice is in the decoder bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725a4d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(#true_tokens=shared_data[\"gradients\"][0][true_user_data[\"data\"].view(-1)].abs().sum(dim=-1).log().tolist(),\n",
    "    all_bias=average_bias.sort().values.tolist())\n",
    "df = pd.DataFrame(data)\n",
    "true_bias = average_bias[true_user_data[\"data\"].view(-1).unique()].sort().values\n",
    "df[\"true_bias\"] = pd.Series(true_bias.tolist())\n",
    "false_bias = average_bias[~true_user_data[\"data\"].view(-1).unique()].sort().values\n",
    "df[\"false_bias\"] = pd.Series(false_bias.tolist())\n",
    "\n",
    "mask_bias = average_bias[average_bias < 0].sort().values\n",
    "df[\"mask_bias\"] = pd.Series(mask_bias.tolist())\n",
    "\n",
    "fig = px.histogram(df, x=[\"false_bias\", \"true_bias\", \"mask_bias\"], opacity=0.8,log_y=True, marginal=\"violin\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af9db14",
   "metadata": {},
   "source": [
    "# Tokens from encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea318c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_data[\"gradients\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aff2af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_wte = torch.stack(wte_per_query).mean(dim=0)\n",
    "average_wte.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad18f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = cfg.case.data.shape\n",
    "num_data_points = cfg.case.user.num_data_points\n",
    "\n",
    "num_missing_tokens = num_data_points * data_shape[0]\n",
    "\n",
    "wte_per_query = [shared_data[\"gradients\"][0]]\n",
    "token_list = []\n",
    "# Stage 1\n",
    "average_wte_norm = torch.stack(wte_per_query).mean(dim=0).norm(dim=1)\n",
    "# average_wte = torch.stack(wte_per_query).mean(dim=0)\n",
    "# average_wte = average_wte - average_wte.mean(dim=1)\n",
    "# average_wte_norm = average_wte.norm(dim=1)\n",
    "\n",
    "\n",
    "\n",
    "std, mean = torch.std_mean(average_wte_norm.log())\n",
    "cutoff = mean + 3 * std\n",
    "if not cutoff.isfinite():  # tied weights\n",
    "    valid_classes = average_wte_norm.nonzero().squeeze(dim=-1)\n",
    "else:  # untied weights\n",
    "    valid_classes = (average_wte_norm.log() > cutoff).nonzero().squeeze(dim=-1)\n",
    "\n",
    "token_list += [*valid_classes.squeeze(dim=-1)]\n",
    "\n",
    "#top2 = average_wte_norm.log().topk(k=2).values\n",
    "# m_impact = top2[0] - top2[1]\n",
    "# m_impact = 0.0010 \n",
    "m_impact = average_wte_norm[valid_classes].sum() / num_missing_tokens\n",
    "# average_wte_norm_log[valid_classes] = average_wte_norm_log[valid_classes] - m_impact\n",
    "\n",
    "average_wte_norm[valid_classes] = average_wte_norm[valid_classes] - m_impact\n",
    "# Stage 2\n",
    "while len(token_list) < num_missing_tokens:\n",
    "    selected_idx = valid_classes[average_wte_norm[valid_classes].argmax()]\n",
    "    token_list.append(selected_idx)\n",
    "    average_wte_norm[selected_idx] -= m_impact\n",
    "tokens = torch.stack(token_list).view(num_data_points, data_shape[0])\n",
    "breaching.analysis.analysis.count_integer_overlap(tokens.view(-1), true_user_data[\"data\"].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bb86de",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = true_user_data[\"data\"].view(-1).unique()\n",
    "\n",
    "\n",
    "data = dict(#true_tokens=shared_data[\"gradients\"][0][true_user_data[\"data\"].view(-1)].abs().sum(dim=-1).log().tolist(),\n",
    "    valid_norms=average_wte_norm.log()[valid_classes.squeeze()].tolist())\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "true_norms = average_wte_norm[unique_tokens]\n",
    "df[\"true_norms\"] = pd.Series(true_norms.log().tolist())\n",
    "\n",
    "true_dist = average_wte_norm[ true_user_data[\"data\"].view(-1)]\n",
    "df[\"true_dist\"] = pd.Series(true_dist.log().tolist())\n",
    "\n",
    "\n",
    "fig = px.histogram(df, x=[\"valid_norms\", \"true_dist\"], opacity=0.5,log_y=False, marginal=\"violin\")\n",
    "#fig.add_vline(x=cutoff)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a6f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_lookup = {token.item():freq.item() for (token, freq) in zip(*true_user_data[\"data\"].view(-1).unique(return_counts=True))}\n",
    "# freq_lookup = dict(sorted(freq_lookup.items(), key=lambda item: item[1], reverse=True))\n",
    "# [freq_lookup[k.item()] for k in average_wte_norm.topk(k=15).indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bfc263",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = true_user_data[\"data\"].view(-1).unique()\n",
    "print(len(unique_tokens), len(valid_classes))\n",
    "breaching.analysis.analysis.count_integer_overlap(valid_classes.view(-1), \n",
    "                                                  unique_tokens[:len(valid_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a0d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(#true_tokens=shared_data[\"gradients\"][0][true_user_data[\"data\"].view(-1)].abs().sum(dim=-1).log().tolist(),\n",
    "    all_tokens=shared_data[\"gradients\"][0].norm(dim=-1).log().tolist())\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "true_hits = shared_data[\"gradients\"][0].norm(dim=-1)[true_user_data[\"data\"].view(-1).unique()]\n",
    "df[\"true_tokens\"] = pd.Series(true_hits.log().tolist())\n",
    "fig = px.histogram(df, x=[\"all_tokens\", \"true_tokens\"], opacity=0.8,log_y=False, marginal=\"violin\")\n",
    "fig.add_vline(x=cutoff)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c623462a",
   "metadata": {},
   "source": [
    "# Tokens from encoder log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae1efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = cfg.case.data.shape\n",
    "num_data_points = cfg.case.user.num_data_points\n",
    "\n",
    "num_missing_tokens = num_data_points * data_shape[0]\n",
    "\n",
    "wte_per_query = [shared_data[\"gradients\"][0]]\n",
    "token_list = []\n",
    "# Stage 1\n",
    "average_wte_norm = torch.stack(wte_per_query).mean(dim=0).norm(dim=1)\n",
    "std, mean = torch.std_mean(average_wte_norm.log())\n",
    "cutoff = mean + 3 * std\n",
    "if not cutoff.isfinite():  # tied weights\n",
    "    valid_classes = average_wte_norm.nonzero().squeeze(dim=-1)\n",
    "else:  # untied weights\n",
    "    valid_classes = (average_wte_norm.log() > cutoff).nonzero().squeeze(dim=-1)\n",
    "# std, mean = torch.std_mean(average_wte_norm.log())\n",
    "# cutoff = mean + 3 * std\n",
    "# valid_classes = (average_wte_norm.log() > cutoff).nonzero().squeeze(dim=-1)\n",
    "\n",
    "token_list += [*valid_classes]\n",
    "\n",
    "# average_bias = torch.stack(bias_per_query).mean(dim=0)\n",
    "# tokens_in_mask = (average_bias < 0).nonzero().squeeze(dim=-1)\n",
    "# for token in tokens_in_mask:\n",
    "#     if token not in token_list:\n",
    "#         token_list.append(token)\n",
    "#         print(\"app\")\n",
    "\n",
    "#top2 = average_wte_norm.log().topk(k=2).values\n",
    "#m_impact = top2[0] - top2[1]\n",
    "# m_impact = 0.0010 \n",
    "# m_impact = average_wte_norm[valid_classes].median()\n",
    "\n",
    "average_wte_norm_log = average_wte_norm.log()\n",
    "# average_wte_norm_log[valid_classes] = average_wte_norm_log[valid_classes] / valid_classes.log()\n",
    "m_impact = average_wte_norm_log[valid_classes].max() / torch.as_tensor(num_data_points).sqrt()\n",
    "# average_wte_norm_log[valid_classes] = average_wte_norm_log[valid_classes] - m_impact\n",
    "# average_wte_norm[valid_classes] = average_wte_norm[valid_classes] - m_impact\n",
    "\n",
    "# Stage 2\n",
    "while len(token_list) < num_missing_tokens:\n",
    "    selected_idx = valid_classes[average_wte_norm_log[valid_classes].argmax()].squeeze()\n",
    "    token_list.append(selected_idx)\n",
    "    average_wte_norm_log[selected_idx] -= m_impact\n",
    "    # print(selected_idx, average_wte_norm[selected_idx])\n",
    "tokens = torch.stack(token_list).view(num_data_points, data_shape[0])\n",
    "breaching.analysis.analysis.count_integer_overlap(tokens.view(-1), true_user_data[\"data\"].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a013ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = true_user_data[\"data\"].view(-1).unique()\n",
    "print(len(unique_tokens), len(valid_classes))\n",
    "breaching.analysis.analysis.count_integer_overlap(valid_classes.view(-1)[:len(unique_tokens)], \n",
    "                                                  unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e86cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(#true_tokens=shared_data[\"gradients\"][0][true_user_data[\"data\"].view(-1)].abs().sum(dim=-1).log().tolist(),\n",
    "    all_tokens=shared_data[\"gradients\"][0].norm(dim=-1).tolist())\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "true_hits = shared_data[\"gradients\"][0].norm(dim=-1)[true_user_data[\"data\"].view(-1).unique()]\n",
    "df[\"true_tokens\"] = pd.Series(true_hits.tolist())\n",
    "fig = px.histogram(df, x=[\"all_tokens\", \"true_tokens\"], opacity=0.8,log_y=True, marginal=\"violin\")\n",
    "# fig.add_vline(x=cutoff)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631090b8",
   "metadata": {},
   "source": [
    "# Mixed Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f56968",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = cfg.case.data.shape\n",
    "num_data_points = cfg.case.user.num_data_points\n",
    "\n",
    "num_missing_tokens = num_data_points * data_shape[0]\n",
    "\n",
    "# This is slightly modified analytic label recovery in the style of Wainakh\n",
    "bias_per_query = [shared_data[\"gradients\"][-5]]\n",
    "token_list = []\n",
    "# Stage 1\n",
    "average_bias = torch.stack(bias_per_query).mean(dim=0)\n",
    "valid_classes = (average_bias < 0).nonzero()\n",
    "token_list += [*valid_classes.squeeze(dim=-1)]\n",
    "# tokens_in_input = shared_data[\"gradients\"][0].norm(dim=-1).nonzero().squeeze(dim=-1)\n",
    "# for token in tokens_in_input:\n",
    "#     if token not in token_list:\n",
    "#         token_list.append(token)\n",
    "\n",
    "m_impact = average_bias_correct_label = average_bias[valid_classes].sum() / num_missing_tokens\n",
    "\n",
    "average_bias[valid_classes] = average_bias[valid_classes] - m_impact\n",
    "# Stage 2\n",
    "while len(token_list) < num_missing_tokens:\n",
    "    selected_idx = average_bias.argmin()\n",
    "    if average_bias[selected_idx]  - m_impact< 0:\n",
    "        token_list.append(selected_idx)\n",
    "        average_bias[selected_idx] -= m_impact\n",
    "    break\n",
    "    \n",
    "missing_tokens = num_missing_tokens - len(token_list)\n",
    "    \n",
    "average_wte_norm = torch.stack(wte_per_query).mean(dim=0).norm(dim=1)\n",
    "std, mean = torch.std_mean(average_wte_norm.log())\n",
    "cutoff = mean + 2.5 * std\n",
    "uniques_from_wte = (average_wte_norm.log() > cutoff).nonzero()\n",
    "token_list += [*uniques_from_wte.squeeze(dim=-1)]\n",
    "# token_list += [*uniques_from_wte.squeeze(dim=-1)]\n",
    "\n",
    "missing_tokens = num_missing_tokens - len(token_list)\n",
    "\n",
    "\n",
    "token_list = [*token_list, *torch.zeros(num_missing_tokens - len(token_list))]\n",
    "# # Stage 2\n",
    "# while len(token_list) < num_missing_tokens:\n",
    "#     token_list.append(valid_classes[torch.randint(0, len(valid_classes), (1,))].squeeze())\n",
    "\n",
    "    \n",
    "    # print(val, average_bias[selected_idx], selected_idx)\n",
    "tokens = torch.stack(token_list).view(num_data_points, data_shape[0])\n",
    "# Total token recovery:\n",
    "breaching.analysis.analysis.count_integer_overlap(tokens.view(-1), true_user_data[\"data\"].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c2e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = true_user_data[\"data\"].view(-1).unique()\n",
    "valid_classes = tokens.view(-1).unique()\n",
    "\n",
    "print(len(unique_tokens), len(valid_classes))\n",
    "breaching.analysis.analysis.count_integer_overlap(valid_classes[:len(unique_tokens)], unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d895c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(#true_tokens=shared_data[\"gradients\"][0][true_user_data[\"data\"].view(-1)].abs().sum(dim=-1).log().tolist(),\n",
    "    all_tokens=shared_data[\"gradients\"][0].norm(dim=-1).log().tolist())\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "true_hits = shared_data[\"gradients\"][0].norm(dim=-1)[true_user_data[\"data\"].view(-1).unique()]\n",
    "df[\"true_tokens\"] = pd.Series(true_hits.log().tolist())\n",
    "fig = px.histogram(df, x=[\"all_tokens\", \"true_tokens\"], opacity=0.8,log_y=False, marginal=\"violin\")\n",
    "fig.add_vline(x=cutoff)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d58368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
