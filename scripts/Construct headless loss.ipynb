{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebef44a",
   "metadata": {},
   "source": [
    "# Breaching privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756fc5f",
   "metadata": {},
   "source": [
    "This notebook does the same job as the cmd-line tool `breach.py`, but also directly visualizes the user data and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import breaching\n",
    "import logging, sys\n",
    "logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler(sys.stdout)], format='%(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5e214",
   "metadata": {},
   "source": [
    "### Initialize cfg object and system setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd663b",
   "metadata": {},
   "source": [
    "This will print out all configuration options. \n",
    "There are a lot of possible configurations, but there is usually no need to worry about most of these. Below, a few options are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc3a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize(config_path=\"config\"):\n",
    "    cfg = hydra.compose(config_name='cfg', overrides=['case=1_single_image_small'])\n",
    "    print(f'Investigating use case {cfg.case.name} with server type {cfg.case.server.name}.')\n",
    "    print('Attack settings are:')\n",
    "    print(OmegaConf.to_yaml(cfg.attack))\n",
    "          \n",
    "device = torch.device(f'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.backends.cudnn.benchmark = cfg.case.impl.benchmark\n",
    "setup = dict(device=device, dtype=getattr(torch, cfg.case.impl.dtype))\n",
    "setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c5fb1",
   "metadata": {},
   "source": [
    "### Modify config options here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0764ef",
   "metadata": {},
   "source": [
    "You can use `.attribute` access to modify any of these configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac118ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.case.model='convnetsmall'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f64389",
   "metadata": {},
   "source": [
    "### Instantiate all parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3abd955",
   "metadata": {},
   "outputs": [],
   "source": [
    "user, server, model, loss_fn = breaching.cases.construct_case(cfg.case, setup)\n",
    "attacker = breaching.attacks.prepare_attack(server.model, server.loss, cfg.attack, setup)\n",
    "breaching.utils.overview(server, user, attacker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c0ad6",
   "metadata": {},
   "source": [
    "### Simulate an attacked FL protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058bcc2",
   "metadata": {},
   "source": [
    "True user data is returned only for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dbd868",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_payload = server.distribute_payload()\n",
    "shared_data, true_user_data = user.compute_local_updates(server_payload)  \n",
    "# [(g.mean(), g.std()) for g in shared_data['gradients'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c68628",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.plot(true_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf2282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = shared_data['gradients'][0]\n",
    "named_grads = {name: g for (g, (name, param)) in zip(grads, user.model.named_parameters())}\n",
    "named_modules = {name: module for name, module in user.model.named_modules()}\n",
    "named_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe336310",
   "metadata": {},
   "outputs": [],
   "source": [
    "(named_grads['model.linear.weight'] / named_grads['model.linear.bias'][:, None]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47de863",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_grads.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b41eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_classes = named_grads['model.linear.bias'] != 0\n",
    "named_grads_fc_debiased = named_grads['model.linear.weight'][valid_classes] \\\n",
    "                           / named_grads['model.linear.bias'][valid_classes, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aedae7a",
   "metadata": {},
   "source": [
    "### Replicate debiased grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd1b448",
   "metadata": {},
   "outputs": [],
   "source": [
    "presum = user.model(true_user_data['data']).sum()\n",
    "debiased_rec, = torch.autograd.grad(presum, user.model.model.linear.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a9f8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.dist(named_grads_fc_debiased, debiased_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af44dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.model.model.linear = torch.nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731ca98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.dist(named_grads_fc_debiased[(named_grads['model.linear.bias'] < 0).nonzero()].squeeze(),\n",
    "          user.model(true_user_data['data']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354cd1b9",
   "metadata": {},
   "source": [
    "$l = h(cx + b)$, $x\\in \\R^n$, $c, b \\in \\R$, $y=cx+b$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac3b79",
   "metadata": {},
   "source": [
    "$\\frac{\\partial h}{\\partial y_i} = g_i $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90ae80a",
   "metadata": {},
   "source": [
    "$\\frac{\\partial h}{\\partial b} = \\sum_{i=1}^n \\frac{\\partial h}{\\partial y_i} = \\langle g, 1\\rangle $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d6193",
   "metadata": {},
   "source": [
    "$\\frac{\\partial h}{\\partial c} = \\sum_{i=1}^n \\frac{\\partial h}{\\partial y_i} x_i = \\langle g, x\\rangle$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289e60fd",
   "metadata": {},
   "source": [
    "Wish:  $\\langle 1, x\\rangle $ or any $f: \\R^n \\to \\R$ mapping $x$ to a scalar without $g$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43710697",
   "metadata": {},
   "source": [
    "Can do $\\frac{\\langle g, x\\rangle}{\\langle g, 1 \\rangle} kinda smaller ||x|| $ but not great"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887a96f9",
   "metadata": {},
   "source": [
    "### Now do the same for a conv + batchnorm layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1a1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_channels = named_grads['stem.1.bias'] != 0\n",
    "correction = named_modules['stem.1'].running_var / named_modules['stem.1'].weight\n",
    "divisor = named_grads['stem.0.weight'][valid_channels] / named_grads['stem.1.bias'][valid_channels, None, None, None]\n",
    "debiased_conv1 = divisor * correction[valid_channels, None, None, None]\n",
    "\n",
    "# conv1.weight, bn1.weight, bn1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0614f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "presum = user.model.stem[0](true_user_data['data'])[:, valid_channels].sum()\n",
    "debiased_conv_rec, = torch.autograd.grad(presum, user.model.stem[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb53da46",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.dist(debiased_conv_rec, debiased_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806c1e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_grads['stem.1.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ba16a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "debiased_conv_rec[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40a0e1f",
   "metadata": {},
   "source": [
    "## Simpler case: conv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5805d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_channels = named_grads['model.conv0.bias'] != 0\n",
    "divisor = named_grads['model.conv0.weight'][valid_channels] / named_grads['model.conv0.bias'][valid_channels, None, None, None]\n",
    "debiased_conv1 = divisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b17b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "presum = user.model.model.conv0(true_user_data['data'])[:, valid_channels].sum()\n",
    "debiased_conv_rec, = torch.autograd.grad(presum, user.model.model.conv0.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537eab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.dist(debiased_conv_rec, debiased_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17255c5a",
   "metadata": {},
   "source": [
    "### Reconstruct user data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2f0092",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_user_data, stats = attacker.reconstruct(server_payload, shared_data, \n",
    "                                                      server.secrets, dryrun=cfg.dryrun)\n",
    "\n",
    "# How good is the reconstruction?\n",
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, \n",
    "                                    server_payload, server.model, user.dataloader, setup=setup,\n",
    "                                    order_batch=True, compute_full_iip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631f4a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.plot(reconstructed_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cffc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, \n",
    "                                    server_payload, server.model, user.dataloader, setup=setup,\n",
    "                                    order_batch=True, compute_full_iip=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
