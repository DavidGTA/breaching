{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebef44a",
   "metadata": {},
   "source": [
    "# Breaching privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756fc5f",
   "metadata": {},
   "source": [
    "This notebook does the same job as the cmd-line tool `simulate_breach.py`, but also directly visualizes the user data and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import breaching\n",
    "import logging, sys\n",
    "logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler(sys.stdout)], format='%(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70450821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5e214",
   "metadata": {},
   "source": [
    "### Initialize cfg object and system setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd663b",
   "metadata": {},
   "source": [
    "This will print out all configuration options. \n",
    "There are a lot of possible configurations, but there is usually no need to worry about most of these. Below, a few options are printed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26070d66",
   "metadata": {},
   "source": [
    "Choose `case/data=` `shakespeare`, `wikitext`over `stackoverflow` here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc3a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize(config_path=\"config\"):\n",
    "    cfg = hydra.compose(config_name='cfg', overrides=['case/data=stackoverflow', \n",
    "                                                      'attack=tag'])\n",
    "    print(f'Investigating use case {cfg.case.name} with server type {cfg.case.server.name}.')\n",
    "          \n",
    "device = torch.device(f'cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.backends.cudnn.benchmark = cfg.case.impl.benchmark\n",
    "setup = dict(device=device, dtype=torch.float)\n",
    "setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c5fb1",
   "metadata": {},
   "source": [
    "### Modify config options here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0764ef",
   "metadata": {},
   "source": [
    "You can use `.attribute` access to modify any of these configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac118ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.case.user.num_data_points = 32 # How many sentences?\n",
    "cfg.case.user.user_idx = 0 # From which user?\n",
    "cfg.case.data.shape = [128] # This is the sequence length\n",
    "\n",
    "cfg.case.model=\"transformer3t\"\n",
    "cfg.case.server.pretrained=False\n",
    "cfg.case.data.tokenizer = \"bert-base-uncased\"\n",
    "cfg.case.data.task =  \"causal-lm\"\n",
    "# cfg.case.data.vocab_size =  30522\n",
    "cfg.case.data.disable_mlm=False\n",
    "cfg.case.data.mlm_probability =  0.1\n",
    "\n",
    "cfg.attack.attack_type = \"permutation-optimization\"\n",
    "cfg.attack.label_strategy = \"bias-text\"\n",
    "\n",
    "cfg.case.server.has_external_data=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f64389",
   "metadata": {},
   "source": [
    "### Instantiate all parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30235b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user, server, model, loss_fn = breaching.cases.construct_case(cfg.case, setup)\n",
    "attacker = breaching.attacks.prepare_attack(server.model, server.loss, cfg.attack, setup)\n",
    "breaching.utils.overview(server, user, attacker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e202f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(server.external_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c01452",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c0ad6",
   "metadata": {},
   "source": [
    "### Simulate an attacked FL protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058bcc2",
   "metadata": {},
   "source": [
    "True user data is returned only for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a2e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_payload = server.distribute_payload()\n",
    "shared_data, true_user_data = user.compute_local_updates(server_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.print(true_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e5fe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_user_data[\"labels\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2867bcc",
   "metadata": {},
   "source": [
    "# Reconstruct user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04521004",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reconstructed_user_data, stats = attacker.reconstruct([server_payload], [shared_data], \n",
    "#                                                       server.secrets, dryrun=cfg.dryrun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c4ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally return a dict with keys data and labels\n",
    "reconstructed_user_data = dict(data=None, labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b7388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user.print(reconstructed_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee7e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_user_data[\"labels\"].numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fdbf58",
   "metadata": {},
   "source": [
    "### Check metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b4750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "#                                    server.model, cfg_case=cfg.case, setup=setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd727074",
   "metadata": {},
   "outputs": [],
   "source": [
    "[g.shape for g in shared_data[\"gradients\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b431ca1",
   "metadata": {},
   "source": [
    "# Tokens from decoder bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = cfg.case.data.shape\n",
    "num_data_points = cfg.case.user.num_data_points\n",
    "\n",
    "num_missing_tokens = num_data_points * data_shape[0]\n",
    "\n",
    "# This is slightly modified analytic label recovery in the style of Wainakh\n",
    "bias_per_query = [shared_data[\"gradients\"][-1]]\n",
    "token_list = []\n",
    "# Stage 1\n",
    "average_bias = torch.stack(bias_per_query).mean(dim=0)\n",
    "valid_classes = (average_bias < 0).nonzero()\n",
    "token_list += [*valid_classes.squeeze(dim=-1)]\n",
    "# tokens_in_input = shared_data[\"gradients\"][0].norm(dim=-1).nonzero().squeeze(dim=-1)\n",
    "# for token in tokens_in_input:\n",
    "#     if token not in token_list:\n",
    "#         token_list.append(token)\n",
    "\n",
    "m_impact = average_bias[valid_classes].sum() / num_missing_tokens\n",
    "\n",
    "average_bias[valid_classes] = average_bias[valid_classes] - m_impact\n",
    "# Stage 2\n",
    "while len(token_list) < num_missing_tokens:\n",
    "    selected_idx = average_bias.argmin()\n",
    "    token_list.append(selected_idx)\n",
    "    average_bias[selected_idx] -= m_impact\n",
    "tokens = torch.stack(token_list).view(num_data_points, data_shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93668d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total token recovery:\n",
    "breaching.analysis.analysis.count_integer_overlap(tokens.view(-1), true_user_data[\"data\"].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a5a30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique token recovery:\n",
    "unique_tokens = true_user_data[\"data\"].view(-1).unique()\n",
    "print(len(valid_classes), len(unique_tokens))\n",
    "padded_classes = torch.cat([valid_classes.view(-1), torch.zeros(len(unique_tokens)-len(valid_classes))])\n",
    "breaching.analysis.analysis.count_integer_overlap(padded_classes.view(-1), unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1291cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_labels = tokens.view(-1)\n",
    "true_labels = true_user_data[\"labels\"].view(-1)\n",
    "df = pd.DataFrame(dict(rec_labels=rec_labels.tolist(), true_labels=true_labels.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c75c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x=[\"rec_labels\", \"true_labels\"], opacity=0.8,log_y=True, marginal=\"violin\",\n",
    "                  labels={'rec_labels':'Recovered tokens', \"true_labels\": \"True tokens\"})\n",
    "fig.update_layout(\n",
    "    title_text='Recovered Token Frequency', # title of plot\n",
    "    xaxis_title_text='Token ID', # xaxis label\n",
    "    yaxis_title_text='Count', # yaxis label\n",
    "    bargap=0.2, # gap between bars of adjacent location coordinates\n",
    "    bargroupgap=0.1, # gap between bars of the same location coordinates\n",
    "    barmode='overlay'\n",
    ")\n",
    "fig.update_traces(opacity=0.75)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af9db14",
   "metadata": {},
   "source": [
    "# Tokens from encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea318c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_data[\"gradients\"][-2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad18f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = cfg.case.data.shape\n",
    "num_data_points = cfg.case.user.num_data_points\n",
    "\n",
    "num_missing_tokens = num_data_points * data_shape[0]\n",
    "\n",
    "wte_per_query = [shared_data[\"gradients\"][-2]]\n",
    "token_list = []\n",
    "# Stage 1\n",
    "average_wte_norm = torch.stack(wte_per_query).mean(dim=0).norm(dim=1)\n",
    "std, mean = torch.std_mean(average_wte_norm.log())\n",
    "cutoff = mean + 2.5 * std\n",
    "valid_classes = (average_wte_norm.log() > cutoff).nonzero()\n",
    "token_list += [*valid_classes.squeeze(dim=-1)]\n",
    "\n",
    "top2 = average_wte_norm.log().topk(k=2).values\n",
    "# m_impact = top2[0] - top2[1]\n",
    "m_impact = average_wte_norm[valid_classes].sum() / num_missing_tokens\n",
    "# average_wte_norm_log[valid_classes] = average_wte_norm_log[valid_classes] - m_impact\n",
    "\n",
    "average_wte_norm[valid_classes] = average_wte_norm[valid_classes] - m_impact\n",
    "# Stage 2\n",
    "while len(token_list) < num_missing_tokens:\n",
    "    selected_idx = valid_classes[average_wte_norm[valid_classes].argmax()].squeeze()\n",
    "    token_list.append(selected_idx)\n",
    "    # print(selected_idx, average_wte_norm_log[selected_idx])\n",
    "    average_wte_norm[selected_idx] -= m_impact\n",
    "tokens = torch.stack(token_list).view(num_data_points, data_shape[0])\n",
    "breaching.analysis.analysis.count_integer_overlap(tokens.view(-1), true_user_data[\"labels\"].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bfc263",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = true_user_data[\"data\"].view(-1).unique()\n",
    "print(len(valid_classes), len(unique_tokens))\n",
    "breaching.analysis.analysis.count_integer_overlap(valid_classes.view(-1)[:len(unique_tokens)], \n",
    "                                                  unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1989b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(#true_tokens=shared_data[\"gradients\"][0][true_user_data[\"data\"].view(-1)].abs().sum(dim=-1).log().tolist(),\n",
    "    all_tokens=shared_data[\"gradients\"][-2].norm(dim=-1).log().tolist())\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "true_hits = shared_data[\"gradients\"][-2].norm(dim=-1)[true_user_data[\"data\"].view(-1).unique()]\n",
    "df[\"true_tokens\"] = pd.Series(true_hits.log().tolist())\n",
    "fig = px.histogram(df, x=[\"all_tokens\", \"true_tokens\"], opacity=0.8,log_y=False, marginal=\"violin\")\n",
    "fig.add_vline(x=cutoff)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34584dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_labels = tokens.view(-1)\n",
    "true_labels = true_user_data[\"data\"].view(-1)\n",
    "df = pd.DataFrame(dict(rec_labels=rec_labels.tolist(), true_labels=true_labels.tolist()))\n",
    "\n",
    "\n",
    "fig = px.histogram(df, x=[\"rec_labels\", \"true_labels\"], opacity=0.8,log_y=True, marginal=\"violin\",\n",
    "                  labels={'rec_labels':'Recovered tokens', \"true_labels\": \"True tokens\"})\n",
    "fig.update_layout(\n",
    "    title_text='Recovered Token Frequency', # title of plot\n",
    "    xaxis_title_text='Token ID', # xaxis label\n",
    "    yaxis_title_text='Count', # yaxis label\n",
    "    bargap=0.2, # gap between bars of adjacent location coordinates\n",
    "    bargroupgap=0.1, # gap between bars of the same location coordinates\n",
    "    barmode='overlay'\n",
    ")\n",
    "fig.update_traces(opacity=0.75)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed3e5da",
   "metadata": {},
   "source": [
    "# Mixed Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0061e7",
   "metadata": {},
   "source": [
    "Uniques from encoder, frequencies from decoder bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edbca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = cfg.case.data.shape\n",
    "num_data_points = cfg.case.user.num_data_points\n",
    "\n",
    "num_missing_tokens = num_data_points * data_shape[0]\n",
    "\n",
    "wte_per_query = [shared_data[\"gradients\"][-2]]\n",
    "token_list = []\n",
    "# Stage 1\n",
    "average_wte_norm = torch.stack(wte_per_query).mean(dim=0).norm(dim=1)\n",
    "std, mean = torch.std_mean(average_wte_norm.log())\n",
    "cutoff = mean + 2.5 * std\n",
    "valid_classes = (average_wte_norm.log() > cutoff).nonzero()\n",
    "token_list += [*valid_classes.squeeze(dim=-1)]\n",
    "\n",
    "\n",
    "bias_per_query = [shared_data[\"gradients\"][-1]]\n",
    "# Stage 1\n",
    "average_bias = torch.stack(bias_per_query).mean(dim=0)\n",
    "\n",
    "m_impact = average_bias[valid_classes].sum() / num_missing_tokens\n",
    "\n",
    "average_bias[valid_classes] = average_bias[valid_classes] - m_impact\n",
    "# Stage 2\n",
    "while len(token_list) < num_missing_tokens:\n",
    "    selected_idx = valid_classes[average_bias[valid_classes].argmin()].squeeze()\n",
    "    # selected_idx = average_bias.argmin()\n",
    "    token_list.append(selected_idx)\n",
    "    average_bias[selected_idx] -= m_impact\n",
    "tokens = torch.stack(token_list).view(num_data_points, data_shape[0])\n",
    "\n",
    "breaching.analysis.analysis.count_integer_overlap(tokens.view(-1), true_user_data[\"labels\"].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d77b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = true_user_data[\"data\"].view(-1).unique()\n",
    "print(len(valid_classes), len(unique_tokens))\n",
    "breaching.analysis.analysis.count_integer_overlap(valid_classes.view(-1)[:len(unique_tokens)], \n",
    "                                                  unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c8318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_labels = tokens.view(-1)\n",
    "true_labels = true_user_data[\"data\"].view(-1)\n",
    "df = pd.DataFrame(dict(rec_labels=rec_labels.tolist(), true_labels=true_labels.tolist()))\n",
    "\n",
    "\n",
    "fig = px.histogram(df, x=[\"rec_labels\", \"true_labels\"], opacity=0.8,log_y=True, marginal=\"violin\",\n",
    "                  labels={'rec_labels':'Recovered tokens', \"true_labels\": \"True tokens\"})\n",
    "fig.update_layout(\n",
    "    title_text='Recovered Token Frequency', # title of plot\n",
    "    xaxis_title_text='Token ID', # xaxis label\n",
    "    yaxis_title_text='Count', # yaxis label\n",
    "    bargap=0.2, # gap between bars of adjacent location coordinates\n",
    "    bargroupgap=0.1, # gap between bars of the same location coordinates\n",
    "    barmode='overlay'\n",
    ")\n",
    "fig.update_traces(opacity=0.75)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24be298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4fc969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
