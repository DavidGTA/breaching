{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebef44a",
   "metadata": {},
   "source": [
    "# Breaching privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756fc5f",
   "metadata": {},
   "source": [
    "This notebook does the same job as the cmd-line tool `simulate_breach.py`, but also directly visualizes the user data and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import breaching\n",
    "import logging, sys\n",
    "logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler(sys.stdout)], format='%(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376ef846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5e214",
   "metadata": {},
   "source": [
    "### Initialize cfg object and system setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd663b",
   "metadata": {},
   "source": [
    "This will print out all configuration options. \n",
    "There are a lot of possible configurations, but there is usually no need to worry about most of these. Below, a few options are printed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26070d66",
   "metadata": {},
   "source": [
    "Choose `case/data=` `shakespeare`, `wikitext`over `stackoverflow` here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc3a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize(config_path=\"config\"):\n",
    "    cfg = hydra.compose(config_name='cfg', overrides=[\"case/data=wikitext\", \"case/server=malicious-transformer\",\n",
    "                                                      \"case.model=gpt2S\",\n",
    "                                                      \"attack=decepticon\"])\n",
    "    print(f'Investigating use case {cfg.case.name} with server type {cfg.case.server.name}.')\n",
    "          \n",
    "device = torch.device(f'cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.backends.cudnn.benchmark = cfg.case.impl.benchmark\n",
    "setup = dict(device=device, dtype=torch.float)\n",
    "setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c5fb1",
   "metadata": {},
   "source": [
    "### Modify config options here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0764ef",
   "metadata": {},
   "source": [
    "You can use `.attribute` access to modify any of these configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac118ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.case.user.num_data_points = 2 # How many sentences?\n",
    "cfg.case.user.user_idx = 1 # From which user?\n",
    "cfg.case.data.shape = [4] # This is the sequence length\n",
    "\n",
    "cfg.case.data.tokenizer = \"gpt2\"\n",
    "\n",
    "cfg.case.server.has_external_data = True\n",
    "\n",
    "cfg.case.server.param_modification.v_length = 64\n",
    "cfg.case.server.param_modification.imprint_sentence_position = 0\n",
    "cfg.case.server.param_modification.softmax_skew = 10000000\n",
    "cfg.case.server.param_modification.sequence_token_weight = 1\n",
    "\n",
    "cfg.case.server.param_modification.eps = 1e-6\n",
    "\n",
    "cfg.case.server.pretrained=False\n",
    "\n",
    "cfg.attack.token_strategy =\"embedding-norm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f64389",
   "metadata": {},
   "source": [
    "### Instantiate all parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30235b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user, server, model, loss_fn = breaching.cases.construct_case(cfg.case, setup)\n",
    "attacker = breaching.attacks.prepare_attack(server.model, server.loss, cfg.attack, setup)\n",
    "breaching.utils.overview(server, user, attacker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c0ad6",
   "metadata": {},
   "source": [
    "### Simulate an attacked FL protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058bcc2",
   "metadata": {},
   "source": [
    "True user data is returned only for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f997f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_payload = server.distribute_payload()\n",
    "shared_data, true_user_data = user.compute_local_updates(server_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.print(true_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73a3a26",
   "metadata": {},
   "source": [
    "## Run through the initial transformer blocks \"by hand\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0acd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = user.model\n",
    "embedding = model.model.transformer.wte\n",
    "pos_encoder = model.model.transformer.wpe\n",
    "\n",
    "norm_layer0 = model.model.transformer.h[0].ln_1\n",
    "norm_layer1 = model.model.transformer.h[0].ln_2\n",
    "\n",
    "attention_layer = dict()\n",
    "attention_layer[\"in_proj_weight\"] = model.model.transformer.h[0].attn.c_attn.weight\n",
    "attention_layer[\"in_proj_bias\"] = model.model.transformer.h[0].attn.c_attn.bias\n",
    "attention_layer[\"out_proj_weight\"] = model.model.transformer.h[0].attn.c_proj.weight\n",
    "attention_layer[\"out_proj_bias\"] = model.model.transformer.h[0].attn.c_proj.bias\n",
    "\n",
    "first_linear_layers, second_linear_layers, unused_mhas = [], [], []  # collecting all the imprint layers\n",
    "for i, layer in enumerate(model.model.transformer.h):\n",
    "    first_linear_layers.append(layer.mlp.c_fc)\n",
    "    second_linear_layers.append(layer.mlp.c_proj)\n",
    "    if i != 0:\n",
    "        unused_mhas.append(layer.attn.c_proj)\n",
    "\n",
    "\n",
    "hidden_dim, embedding_dim = first_linear_layers[0].weight.T.shape\n",
    "ff_transposed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baebbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = true_user_data[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68891371",
   "metadata": {},
   "outputs": [],
   "source": [
    "trafo_inputs = pos_encoder(torch.arange(inputs.shape[1])[None, :]) + embedding(true_user_data[\"data\"])\n",
    "trafo_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ae9fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_outputs, (K, V), attn_weights = model.model.transformer.h[0].attn(trafo_inputs, \n",
    "                                                                       output_attentions=True, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a599198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_outputs[0, :, :8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b500aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b8ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf9bca2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.corrcoef(attn_outputs.reshape(-1, 768).detach())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f5eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = attn_outputs + trafo_inputs\n",
    "linear_inputs = norm_layer1(residuals)\n",
    "linear_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7179f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_inputs[0, :, 0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68914402",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445a8b0f",
   "metadata": {},
   "source": [
    "### Simulate breached features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc50937",
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation = torch.randperm(32) # torch.randperm(32) # torch.arange(32)\n",
    "num_breached_embeddings = 20\n",
    "reverse_perm = torch.argsort(permutation[:num_breached_embeddings])\n",
    "permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d168faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_features = linear_inputs.permute(0, 1, 2).reshape(-1, 96)[:, :8][permutation][:num_breached_embeddings]\n",
    "seq_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee87d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = torch.as_tensor(np.corrcoef(seq_features.detach()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2867bcc",
   "metadata": {},
   "source": [
    "# Reconstruct user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064adced",
   "metadata": {},
   "outputs": [],
   "source": [
    "attacker.cfg.sentence_algorithm = \"dynamic-threshold\" # \"k-means\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7caae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.print(true_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be88654",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reconstructed_user_data, stats = attacker.reconstruct([server_payload], [shared_data], \n",
    "                                                      server.secrets, dryrun=cfg.dryrun)\n",
    "\n",
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "                                    server.model, cfg_case=cfg.case, setup=setup)\n",
    "user.print(reconstructed_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0421b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedbe36c",
   "metadata": {},
   "source": [
    "# Manually compute attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a20fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = user.model.pos_encoder(user.model.encoder(inputs))\n",
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c6afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = user.model.transformer_encoder.layers[0].self_attn.in_proj_weight[:96, :]\n",
    "K = user.model.transformer_encoder.layers[0].self_attn.in_proj_weight[96:192, :]\n",
    "V = user.model.transformer_encoder.layers[0].self_attn.in_proj_weight[192:, :]\n",
    "q_b = user.model.transformer_encoder.layers[0].self_attn.in_proj_bias[:96]\n",
    "k_b = user.model.transformer_encoder.layers[0].self_attn.in_proj_bias[96:192]\n",
    "v_b = user.model.transformer_encoder.layers[0].self_attn.in_proj_bias[192:]\n",
    "\n",
    "O =  user.model.transformer_encoder.layers[0].self_attn.out_proj.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f24bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8162026",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_attn = user.model.transformer_encoder.layers[0].self_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3307b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_attn.batch_first = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cf1602",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.shape, inputs[0].T.shape, V.shape, K.shape, q_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74baa641",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8305fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qv = ((Q@inputs[0].T).T + q_b)\n",
    "Kv = ((K@inputs[0].T).T + k_b)\n",
    "Vv = ((V@inputs[0].T).T + v_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e175119",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = (Qv.reshape(16, 8, 12) @ Kv.reshape(16, 8, 12).T).softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09385670",
   "metadata": {},
   "outputs": [],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3392821",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "attn_map = torch.zeros(16, 16)\n",
    "for head in range(8):\n",
    "    mapp = (Qv.reshape(16, 8, 12)[:, head, :] @ Kv.reshape(16, 8, 12)[:, head, :].T).softmax(dim=-1)\n",
    "    attn_map += mapp\n",
    "    print(mapp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3242f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qv.reshape(16, 8, 12)[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275eac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kv.reshape(16, 8, 12)[:, 0, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qv @ Kv.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26129e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vv.reshape(16, 8, 12)[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b68af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "(((Qv.reshape(16, 8, 12)[:, head, :] @ Kv.reshape(16, 8, 12)[:, head, :].T).softmax(dim=-1) @ Vv.reshape(16, 8, 12)[:, head, :])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0455da",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Qv.reshape(16, 8, 12)[:, head, :] @ Kv.reshape(16, 8, 12)[:, head, :].T).softmax(dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f2db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, attn_outputs = self_attn(inputs, inputs, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79614b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81416200",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.model.transformer_encoder.layers[0].norm1(outputs + inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f84345",
   "metadata": {},
   "outputs": [],
   "source": [
    "normy = torch.nn.LayerNorm(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367c70d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2, 1, 2], [5, 5, 5, 5], [7, 7,7, 7]]).float()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11683d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "normy(a[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7fc42b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749a4e1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.in_proj_bias[:96].pe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbbf2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, attn_weights = model(inputs, inputs, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcbaa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c4ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_user_data, stats = attacker.reconstruct_single_sentence([server_payload], [shared_data], \n",
    "                                                      server.secrets, dryrun=cfg.dryrun)\n",
    "user.print(reconstructed_user_data)\n",
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "                                    server.model, cfg_case=cfg.case, setup=setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63300a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_user_data, stats = attacker.reconstruct2([server_payload], [shared_data], \n",
    "                                                      server.secrets, dryrun=cfg.dryrun)\n",
    "user.print(reconstructed_user_data)\n",
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "                                    server.model, cfg_case=cfg.case, setup=setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac408b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "permuted_true_data = dict(data=true_user_data[\"data\"][[3, 2, 1, 0]], labels=true_user_data[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a480b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = breaching.analysis.report(permuted_true_data, true_user_data, [server_payload], \n",
    "                                    server.model, cfg_case=cfg.case, setup=setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c39e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = breaching.analysis.report(true_user_data, true_user_data, [server_payload], \n",
    "                                    server.model, cfg_case=cfg.case, setup=setup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
