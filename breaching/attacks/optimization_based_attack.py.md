å½“ç„¶å¯ä»¥ã€‚ä»¥ä¸‹æ˜¯`reconstruct`å‡½æ•°çš„è¯¦ç»†æ­¥éª¤è¯´æ˜ï¼š

1. **åˆå§‹åŒ–æ”»å‡»å‡†å¤‡**ï¼š
    ```python
    rec_models, labels, stats = self.prepare_attack(server_payload, shared_data)
    ```
    - è°ƒç”¨`prepare_attack`å‡½æ•°ï¼Œå‡†å¤‡æ”»å‡»æ‰€éœ€çš„æ¨¡å‹ã€æ ‡ç­¾å’Œç»Ÿè®¡ä¿¡æ¯ã€‚
    - `rec_models`ï¼šä»æœåŠ¡å™¨è´Ÿè½½ä¸­æ„å»ºçš„æ¨¡å‹ã€‚
    - `labels`ï¼šä»å…±äº«æ•°æ®ä¸­æå–çš„æ ‡ç­¾ä¿¡æ¯ã€‚
    - `stats`ï¼šç”¨äºå­˜å‚¨æ”»å‡»è¿‡ç¨‹ä¸­çš„ç»Ÿè®¡ä¿¡æ¯ã€‚

2. **åˆå§‹åŒ–é‡å»ºå¾ªç¯**ï¼š
    ```python
    scores = torch.zeros(self.cfg.restarts.num_trials)
    candidate_solutions = []
    ```
    - åˆå§‹åŒ–ç”¨äºå­˜å‚¨æ¯æ¬¡è¯•éªŒå¾—åˆ†çš„å¼ é‡`scores`ï¼Œå¤§å°ä¸º`num_trials`ã€‚
    - åˆå§‹åŒ–å€™é€‰è§£å†³æ–¹æ¡ˆåˆ—è¡¨`candidate_solutions`ï¼Œç”¨äºå­˜å‚¨æ¯æ¬¡è¯•éªŒçš„é‡å»ºç»“æœã€‚

3. **é‡å»ºè¯•éªŒå¾ªç¯**ï¼š
    ```python
    try:
        for trial in range(self.cfg.restarts.num_trials):
            candidate_solutions += [
                self._run_trial(rec_models, shared_data, labels, stats, trial, initial_data, dryrun)
            ]
            scores[trial] = self._score_trial(candidate_solutions[trial], labels, rec_models, shared_data)
    except KeyboardInterrupt:
        print("Trial procedure manually interruped.")
        pass
    ```
    - è¿›è¡Œå¤šæ¬¡é‡å»ºè¯•éªŒï¼Œæ¯æ¬¡è¯•éªŒè°ƒç”¨`_run_trial`å‡½æ•°æ‰§è¡Œé‡å»ºï¼Œå¹¶å°†ç»“æœå­˜å‚¨åœ¨`candidate_solutions`ä¸­ã€‚
    - è°ƒç”¨`_score_trial`å‡½æ•°å¯¹æ¯æ¬¡è¯•éªŒçš„ç»“æœè¿›è¡Œè¯„åˆ†ï¼Œå¹¶å°†å¾—åˆ†å­˜å‚¨åœ¨`scores`ä¸­ã€‚
    - å¦‚æœæ‰‹åŠ¨ä¸­æ–­è¯•éªŒè¿‡ç¨‹ï¼Œæ•è·`KeyboardInterrupt`å¼‚å¸¸å¹¶æ‰“å°æç¤ºä¿¡æ¯ã€‚

4. **é€‰æ‹©æœ€ä½³é‡å»ºç»“æœ**ï¼š
    ```python
    optimal_solution = self._select_optimal_reconstruction(candidate_solutions, scores, stats)
    ```
    - è°ƒç”¨`_select_optimal_reconstruction`å‡½æ•°ï¼Œä»æ‰€æœ‰è¯•éªŒä¸­é€‰æ‹©å¾—åˆ†æœ€é«˜çš„é‡å»ºç»“æœã€‚

5. **å¤„ç†é‡å»ºæ•°æ®**ï¼š
    ```python
    reconstructed_data = dict(data=optimal_solution, labels=labels)
    if server_payload[0]["metadata"].modality == "text":
        reconstructed_data = self._postprocess_text_data(reconstructed_data)
    if "ClassAttack" in server_secrets:
        true_num_data = server_secrets["ClassAttack"]["true_num_data"]
        reconstructed_data["data"] = torch.zeros([true_num_data, *self.data_shape], **self.setup)
        reconstructed_data["data"][server_secrets["ClassAttack"]["target_indx"]] = optimal_solution
        reconstructed_data["labels"] = server_secrets["ClassAttack"]["all_labels"]
    ```
    - å°†æœ€ä½³é‡å»ºç»“æœå’Œæ ‡ç­¾å­˜å‚¨åœ¨`reconstructed_data`å­—å…¸ä¸­ã€‚
    - å¦‚æœæ•°æ®ç±»å‹æ˜¯æ–‡æœ¬ï¼Œåˆ™è°ƒç”¨`_postprocess_text_data`å‡½æ•°è¿›è¡Œåå¤„ç†ã€‚
    - å¦‚æœå­˜åœ¨`ClassAttack`çš„æœåŠ¡å™¨ç§˜å¯†ï¼Œåˆ™æ ¹æ®ç§˜å¯†ä¿¡æ¯è°ƒæ•´é‡å»ºæ•°æ®ã€‚

6. **è¿”å›é‡å»ºç»“æœå’Œç»Ÿè®¡ä¿¡æ¯**ï¼š
    ```python
    return reconstructed_data, stats
    ```
    - è¿”å›æœ€ç»ˆçš„é‡å»ºæ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯ã€‚

é€šè¿‡ä¸Šè¿°æ­¥éª¤ï¼Œ`reconstruct`å‡½æ•°å®ç°äº†ä»å…±äº«æ•°æ®å’ŒæœåŠ¡å™¨è´Ÿè½½ä¸­é‡å»ºç”¨æˆ·æ•°æ®çš„è¿‡ç¨‹ã€‚

# `prepare_attack`

### **å‡½æ•°è§£æï¼š`prepare_attack`**
è¯¥å‡½æ•°ç”¨äº **æ”»å‡»å‡†å¤‡**ï¼Œä¸»è¦ç›®çš„æ˜¯**è§£ææœåŠ¡å™¨å‘é€çš„ `server_payload` åŠå®¢æˆ·ç«¯è®­ç»ƒåçš„ `shared_data`ï¼Œæ„å»ºæ¢å¤æ¨¡å‹ï¼ˆrec_modelsï¼‰ï¼Œå¹¶å¤„ç†æ¢¯åº¦å’Œæ ‡ç­¾ä¿¡æ¯**ã€‚è¿™æ˜¯è®¸å¤š **é‡å»ºæ”»å‡»ï¼ˆReconstruction Attackï¼‰** æ–¹æ³•çš„åŸºç¡€æ­¥éª¤ã€‚

---

## **1. ä»£ç ç»“æ„**
å‡½æ•°çš„ä¸»è¦æµç¨‹ï¼š
1. **åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯**
2. **æµ…æ‹·è´ `server_payload` å’Œ `shared_data`**
3. **åŠ è½½ `metadata` é¢„å¤„ç†å¸¸æ•°**
4. **åŠ è½½æœåŠ¡å™¨å‚æ•°å¹¶æ„é€ æ¢å¤æ¨¡å‹**
5. **è½¬æ¢ `shared_data`**
6. **æ–‡æœ¬æ•°æ®å¤„ç†**
7. **æ¢å¤æ ‡ç­¾ä¿¡æ¯**
8. **æ¢¯åº¦å½’ä¸€åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰**
9. **è¿”å› `rec_models`ã€`labels` å’Œ `stats`**

---

## **2. è¯¦ç»†ä»£ç è§£æ**

### **(1) åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯**
```python
stats = defaultdict(list)
```
- **ç›®çš„**ï¼šå­˜å‚¨æ”»å‡»è¿‡ç¨‹ä¸­çš„ç»Ÿè®¡æ•°æ®ï¼Œå¦‚æŸå¤±å€¼ã€æ¢¯åº¦ä¿¡æ¯ç­‰ã€‚
- **ä½¿ç”¨ `defaultdict(list)`**ï¼šç¡®ä¿æ¯ä¸ªé”®éƒ½æœ‰é»˜è®¤çš„ `list`ï¼Œé¿å… `KeyError`ã€‚

---

### **(2) æµ…æ‹·è´ `server_payload` å’Œ `shared_data`**
```python
shared_data = shared_data.copy()  # Shallow copy is enough
server_payload = server_payload.copy()
```
- **æµ…æ‹·è´ï¼ˆshallow copyï¼‰**ï¼š
  - **æ‹·è´ `shared_data` å’Œ `server_payload`**ï¼Œé¿å…å¯¹åŸå§‹æ•°æ®ä¿®æ”¹ã€‚
  - **æµ…æ‹·è´ vs æ·±æ‹·è´**ï¼š
    - **æµ…æ‹·è´**ï¼šæ‹·è´å¤–å±‚ç»“æ„ï¼Œå†…éƒ¨å¯¹è±¡ä»ç„¶å…±äº«å¼•ç”¨ã€‚
    - **æ·±æ‹·è´**ï¼ˆ`deepcopy()`ï¼‰ï¼šå®Œå…¨å¤åˆ¶å¯¹è±¡ï¼Œå­å¯¹è±¡ä¹Ÿæ˜¯æ–°å®ä¾‹ã€‚

---

### **(3) è§£æ `metadata`**
```python
metadata = server_payload[0]["metadata"]
self.data_shape = metadata.shape
```
- `metadata` æ¥è‡ª `server_payload`ï¼Œé€šå¸¸åŒ…å«ï¼š
  - `shape`ï¼šæ•°æ®çš„å½¢çŠ¶
  - `mean/std`ï¼šæ•°æ®å½’ä¸€åŒ–å‚æ•°
  - `modality`ï¼šæ•°æ®ç±»å‹ï¼ˆå¦‚ `text`ã€`image`ï¼‰
  
```python
if hasattr(metadata, "mean"):
    self.dm = torch.as_tensor(metadata.mean, **self.setup)[None, :, None, None]
    self.ds = torch.as_tensor(metadata.std, **self.setup)[None, :, None, None]
else:
    self.dm, self.ds = torch.tensor(0, **self.setup), torch.tensor(1, **self.setup)
```
- **ç›®çš„**ï¼šåŠ è½½æ•°æ® **å‡å€¼ (`mean`) å’Œæ ‡å‡†å·® (`std`)** ä»¥ç”¨äºå½’ä¸€åŒ–ã€‚
- **æ•°æ®å½’ä¸€åŒ–æ–¹å¼**ï¼š
  - è‹¥ `metadata` **åŒ…å« `mean` å’Œ `std`**ï¼š
    - `self.dm`ï¼šå½¢çŠ¶ `[1, C, 1, 1]`ï¼ˆç”¨äº `C` ç»´é€šé“å½’ä¸€åŒ–ï¼‰ã€‚
    - `self.ds`ï¼šåŒç†ã€‚
  - è‹¥ `metadata` **ä¸åŒ…å« `mean` å’Œ `std`**ï¼š
    - è®¾ä¸º `0` å’Œ `1`ï¼ˆä¸è¿›è¡Œå½’ä¸€åŒ–ï¼‰ã€‚

---

### **(4) æ„é€ æ¢å¤æ¨¡å‹**
```python
rec_models = self._construct_models_from_payload_and_buffers(server_payload, shared_data)
```
- **è°ƒç”¨ `_construct_models_from_payload_and_buffers`**ï¼š
  - **å‚æ•°**ï¼š
    - `server_payload`ï¼ˆåŒ…å«æœåŠ¡å™¨çš„åˆå§‹å‚æ•°ï¼‰
    - `shared_data`ï¼ˆåŒ…å«å®¢æˆ·ç«¯è®­ç»ƒåçš„æ¢¯åº¦ä¿¡æ¯ï¼‰
  - **ä½œç”¨**ï¼š
    - å¯èƒ½ç”¨äºæ„é€ ä¸€ä¸ª **æ”»å‡»æ¢å¤æ¨¡å‹**ï¼Œç”¨äºé‡å»ºè¾“å…¥æ•°æ®ã€‚
  - **ä½ éœ€è¦æä¾› `_construct_models_from_payload_and_buffers` ä»£ç **ï¼Œå¦åˆ™æ— æ³•ç¡®å®šå…·ä½“é€»è¾‘ã€‚

---

### **(5) å¤„ç† `shared_data`**
```python
shared_data = self._cast_shared_data(shared_data)
```
- **è°ƒç”¨ `_cast_shared_data`**ï¼š
  - å¯èƒ½æ¶‰åŠï¼š
    - å°†æ•°æ®è½¬æ¢ä¸ºç‰¹å®šæ ¼å¼ï¼ˆå¦‚ `torch.Tensor`ï¼‰ã€‚
    - è°ƒæ•´æ•°æ®ç±»å‹ï¼ˆfloat32ã€float16ï¼‰ã€‚
    - é€‚é…ä¸åŒè®¾å¤‡ï¼ˆå¦‚ `CPU` / `GPU`ï¼‰ã€‚
  - **ä½ éœ€è¦æä¾› `_cast_shared_data` ä»£ç **ã€‚

---

### **(6) å¤„ç†æ–‡æœ¬æ•°æ®**
```python
if metadata.modality == "text":
    rec_models, shared_data = self._prepare_for_text_data(shared_data, rec_models)
```
- **`metadata.modality`**ï¼š
  - `"text"` è¡¨ç¤ºæ•°æ®æ˜¯æ–‡æœ¬ï¼ˆå¦‚ `NLP` ä»»åŠ¡ï¼‰ã€‚
  - **ä¸åŒæ•°æ®ç±»å‹å¯èƒ½éœ€è¦ä¸åŒå¤„ç†æ–¹å¼**ï¼š
    - **å›¾åƒ**ï¼ˆ`image`ï¼‰ï¼šæ¢¯åº¦æ¢å¤åƒç´ å€¼ã€‚
    - **æ–‡æœ¬**ï¼ˆ`text`ï¼‰ï¼šæ¢¯åº¦æ¢å¤å•è¯æˆ– tokenã€‚
- **è°ƒç”¨ `_prepare_for_text_data`**ï¼š
  - **ä½œç”¨**ï¼š
    - å¯èƒ½å¯¹ `rec_models` å’Œ `shared_data` è¿›è¡Œç‰¹æ®Šå¤„ç†ï¼ˆå¦‚ `tokenizer`ã€`embedding`ï¼‰ã€‚
  - **ä½ éœ€è¦æä¾› `_prepare_for_text_data` ä»£ç **ã€‚

---

### **(7) å¤„ç†æ ‡ç­¾ä¿¡æ¯**
```python
if shared_data[0]["metadata"]["labels"] is None:
    labels = self._recover_label_information(shared_data, server_payload, rec_models)
else:
    labels = shared_data[0]["metadata"]["labels"].clone()
```
- **æ£€æŸ¥ `labels` æ˜¯å¦å¯ç”¨**ï¼š
  - è‹¥ `shared_data` ä¸­ `labels == None`ï¼š
    - è°ƒç”¨ `_recover_label_information` è¿›è¡Œæ¢å¤ã€‚
  - è‹¥ `labels` å­˜åœ¨ï¼š
    - ç›´æ¥ `clone()`ï¼Œé¿å…ä¿®æ”¹åŸå§‹æ•°æ®ã€‚

```python
labels = self._recover_label_information(shared_data, server_payload, rec_models)
```
- **è°ƒç”¨ `_recover_label_information`**ï¼š
  - **ä½œç”¨**ï¼š
    - å¯èƒ½åŸºäº `gradients`ã€`rec_models` ç­‰ **é€†æ¨æ ‡ç­¾**ã€‚
  - **ä½ éœ€è¦æä¾› `_recover_label_information` ä»£ç **ã€‚

---

### **(8) æ¢¯åº¦å½’ä¸€åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰**
```python
if self.cfg.normalize_gradients:
    shared_data = self._normalize_gradients(shared_data)
```
- **é…ç½®é€‰é¡¹**ï¼š`self.cfg.normalize_gradients`
  - `True`ï¼šå¯¹ `shared_data` æ¢¯åº¦è¿›è¡Œå½’ä¸€åŒ–ã€‚
  - `False`ï¼šä¸å½’ä¸€åŒ–ã€‚
- **è°ƒç”¨ `_normalize_gradients`**ï¼š
  - **å¯èƒ½ä½œç”¨**ï¼š
    - å½’ä¸€åŒ–æ¢¯åº¦ï¼Œé¿å…æ•°å€¼çˆ†ç‚¸/æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚
    - å¯èƒ½ç”¨äº `LPIPS` å½’ä¸€åŒ–ã€æ ‡å‡†åŒ–æ¢¯åº¦åˆ†å¸ƒã€‚
  - **ä½ éœ€è¦æä¾› `_normalize_gradients` ä»£ç **ã€‚

---

### **(9) è¿”å›æ”»å‡»å‡†å¤‡æ•°æ®**
```python
return rec_models, labels, stats
```
- **`rec_models`**ï¼šæ”»å‡»æ¢å¤çš„æ¨¡å‹ï¼ˆç”¨äºæ¢¯åº¦é€†æ¨è¾“å…¥ï¼‰ã€‚
- **`labels`**ï¼šå¯èƒ½æ¢å¤å‡ºçš„æ ‡ç­¾ä¿¡æ¯ã€‚
- **`stats`**ï¼šç»Ÿè®¡ä¿¡æ¯ï¼Œå¦‚æ”»å‡»è¿‡ç¨‹ä¸­çš„æŸå¤±ã€æ¢¯åº¦å˜åŒ–ç­‰ã€‚

---

## **3. æ€»ç»“**
### **æ ¸å¿ƒåŠŸèƒ½**
- è§£æ `server_payload` å’Œ `shared_data`ã€‚
- å½’ä¸€åŒ– `metadata` ç›¸å…³çš„å‡å€¼/æ ‡å‡†å·®ã€‚
- æ„é€ æ”»å‡»æ¢å¤æ¨¡å‹ï¼ˆ`rec_models`ï¼‰ã€‚
- å¤„ç†ä¸åŒ `modality`ï¼ˆå¦‚æ–‡æœ¬ vs å›¾åƒï¼‰ã€‚
- å°è¯•æ¢å¤ `labels`ã€‚
- å½’ä¸€åŒ–æ¢¯åº¦ï¼ˆå¯é€‰ï¼‰ã€‚

### **æ¶‰åŠçš„å¤–éƒ¨å‡½æ•°ï¼ˆä½ éœ€è¦æä¾›ä»£ç ï¼‰**
1. `_construct_models_from_payload_and_buffers(server_payload, shared_data)`
2. `_cast_shared_data(shared_data)`
3. `_prepare_for_text_data(shared_data, rec_models)`
4. `_recover_label_information(shared_data, server_payload, rec_models)`
5. `_normalize_gradients(shared_data)`

---

## **4. é€‚ç”¨åœºæ™¯**
è¿™ä¸ªå‡½æ•°**ä¸»è¦ç”¨äºè”é‚¦å­¦ä¹ æ”»å‡»**ï¼Œå¯èƒ½æ¶‰åŠï¼š
- **æ¢¯åº¦åæ¼”æ”»å‡»ï¼ˆGradient Inversion Attackï¼‰**ï¼šåˆ©ç”¨æ¢¯åº¦ä¿¡æ¯æ¢å¤å®¢æˆ·ç«¯çš„è®­ç»ƒæ•°æ®ã€‚
- **æ¨¡å‹é€†å‘æ”»å‡»ï¼ˆModel Reconstruction Attackï¼‰**ï¼šæ¢å¤æ¨¡å‹å‚æ•°æˆ–è¾“å…¥æ•°æ®ã€‚
- **æ–‡æœ¬æ•°æ®çš„æ¢¯åº¦æ”»å‡»**ï¼šé’ˆå¯¹ `NLP` ä»»åŠ¡çš„æ–‡æœ¬æ¢å¤ã€‚

ä½ å¯ä»¥æä¾›ç¼ºå¤±çš„å‡½æ•°ä»£ç ï¼Œä»¥ä¾¿è¿›ä¸€æ­¥åˆ†ææ•´ä¸ªæ”»å‡»æµç¨‹ã€‚


### **å‡½æ•°è§£æï¼š`_run_trial`**
è¯¥å‡½æ•° **æ‰§è¡Œä¸€æ¬¡æ¢å¤ï¼ˆreconstructionï¼‰å°è¯•**ï¼Œä¸»è¦ç”¨äº **æ”»å‡»è€…åœ¨æ¢¯åº¦ä¿¡æ¯ï¼ˆ`shared_data`ï¼‰çš„åŸºç¡€ä¸Šæ¢å¤å®¢æˆ·ç«¯çš„åŸå§‹æ•°æ®**ã€‚å…¶æ ¸å¿ƒç›®æ ‡æ˜¯ï¼š
1. **åˆå§‹åŒ–æ­£åˆ™åŒ–é¡¹ä¸æŸå¤±å‡½æ•°**ã€‚
2. **åˆ›å»ºæ•°æ®æ¢å¤çš„åˆå§‹çŠ¶æ€**ï¼ˆå¯é€‰åœ°ä» `initial_data` ç»§ç»­ä¼˜åŒ–ï¼‰ã€‚
3. **ä¼˜åŒ–è¿­ä»£**ï¼š
   - è®¡ç®—ç›®æ ‡å‡½æ•°ï¼ˆ`objective`ï¼‰ã€‚
   - ä½¿ç”¨ **æ¢¯åº¦ä¸‹é™** æ–¹æ³•ä¼˜åŒ–æ¢å¤çš„æ•°æ®ã€‚
   - æ–½åŠ  **è¾¹ç•Œçº¦æŸ**ï¼ˆ`projection`ï¼‰ï¼Œé˜²æ­¢æ¢å¤æ•°æ®è¶…å‡ºèŒƒå›´ã€‚
   - è®°å½•æ¢å¤è¿‡ç¨‹ä¸­çš„ **æœ€ä¼˜æ•°æ®**ã€‚
4. **ç»ˆæ­¢æ¡ä»¶**ï¼š
   - è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚
   - ç›®æ ‡å‡½æ•°å€¼å˜å¾— **éæœ‰é™**ï¼ˆå¦‚ `NaN`ï¼‰ã€‚
   - `dryrun=True` æ—¶æå‰ç»ˆæ­¢ã€‚

---

## **1. ä»£ç ç»“æ„**
```python
def _run_trial(self, rec_model, shared_data, labels, stats, trial, initial_data=None, dryrun=False):
    """Run a single reconstruction trial."""
```
**å‡½æ•°å‚æ•°**ï¼š
- **`rec_model`**ï¼šæ¢å¤æ¨¡å‹ï¼ˆä» `_construct_models_from_payload_and_buffers` å¾—åˆ°ï¼‰ã€‚
- **`shared_data`**ï¼šè”é‚¦å­¦ä¹ å®¢æˆ·ç«¯çš„ **æ¢¯åº¦ä¿¡æ¯**ï¼Œç”¨äºåæ¨è¾“å…¥æ•°æ®ã€‚
- **`labels`**ï¼šå·²æ¢å¤çš„æ ‡ç­¾ä¿¡æ¯ï¼ˆå¦‚æœå·²çŸ¥ï¼‰ã€‚
- **`stats`**ï¼šå­˜å‚¨æ¢å¤è¿‡ç¨‹çš„ç»Ÿè®¡æ•°æ®ã€‚
- **`trial`**ï¼šå½“å‰å°è¯•ç¼–å·ï¼ˆç”¨äºå¤šæ¬¡å®éªŒï¼‰ã€‚
- **`initial_data`**ï¼ˆå¯é€‰ï¼‰ï¼šåˆå§‹åŒ–æ•°æ®ï¼ˆå¦‚å·²éƒ¨åˆ†æ¢å¤çš„æ•°æ®ï¼‰ã€‚
- **`dryrun`**ï¼ˆé»˜è®¤ `False`ï¼‰ï¼šå¦‚æœä¸º `True`ï¼Œåˆ™è¿è¡Œä¸€æ¬¡å¹¶ç«‹å³åœæ­¢ï¼ˆç”¨äºæµ‹è¯•ä»£ç ï¼‰ã€‚

---

## **2. è¯¦ç»†ä»£ç è§£æ**

### **(1) åˆå§‹åŒ–æŸå¤±å‡½æ•°å’Œæ­£åˆ™é¡¹**
```python
for regularizer in self.regularizers:
    regularizer.initialize(rec_model, shared_data, labels)
self.objective.initialize(self.loss_fn, self.cfg.impl, shared_data[0]["metadata"]["local_hyperparams"])
```
- **éå† `self.regularizers`**ï¼š
  - **è°ƒç”¨ `initialize(rec_model, shared_data, labels)`** è¿›è¡Œåˆå§‹åŒ–ã€‚
  - `regularizer` å¯èƒ½ç”¨äº **æ¢¯åº¦æ­£åˆ™åŒ–** æˆ– **é‡å»ºæ•°æ®çš„é¢å¤–çº¦æŸ**ï¼ˆå¦‚ TV å…ˆéªŒï¼‰ã€‚
  
- **åˆå§‹åŒ–ç›®æ ‡å‡½æ•° `self.objective`**ï¼š
  - `self.loss_fn`ï¼šæŸå¤±å‡½æ•°ï¼ˆå¦‚ `MSELoss`ã€`CrossEntropyLoss`ï¼‰ã€‚
  - `self.cfg.impl`ï¼šå®ç°æ–¹å¼ï¼ˆå¯èƒ½å†³å®šè®¡ç®—æ–¹å¼ï¼Œå¦‚ `PyTorch` vs `JIT`ï¼‰ã€‚
  - `shared_data[0]["metadata"]["local_hyperparams"]`ï¼šæœ¬åœ°è¶…å‚æ•°ï¼ˆå¦‚å­¦ä¹ ç‡ã€æ‰¹æ¬¡å¤§å°ï¼‰ã€‚

â— **ä½ éœ€è¦æä¾› `self.objective.initialize()` å’Œ `regularizer.initialize()` çš„ä»£ç ï¼Œæ‰èƒ½è¿›ä¸€æ­¥åˆ†æå®ƒä»¬çš„ä½œç”¨ã€‚**

---

### **(2) åˆå§‹åŒ–æ¢å¤æ•°æ®**
```python
candidate = self._initialize_data([shared_data[0]["metadata"]["num_data_points"], *self.data_shape])
if initial_data is not None:
    candidate.data = initial_data.data.clone().to(**self.setup)
```
- **è°ƒç”¨ `_initialize_data()`**ï¼š
  - **åˆ›å»ºä¸€ä¸ª `candidate`ï¼ˆæ¢å¤æ•°æ®çš„å˜é‡ï¼‰**ã€‚
  - å½¢çŠ¶ä¸º `[num_data_points, *self.data_shape]`ï¼Œå³ä¸å®¢æˆ·ç«¯æ•°æ®å½¢çŠ¶åŒ¹é…ã€‚

- **å¦‚æœ `initial_data` å­˜åœ¨**ï¼š
  - ç›´æ¥å¤åˆ¶å·²æœ‰æ•°æ®ï¼ˆ`initial_data.data.clone().to(**self.setup)`ï¼‰ã€‚
  - **è¿™æ ·å¯ä»¥åœ¨å·²æœ‰çš„æ¢å¤ç»“æœä¸Šç»§ç»­ä¼˜åŒ–**ã€‚

ğŸ“Œ **ä½ éœ€è¦æä¾› `_initialize_data()` ä»£ç ï¼Œä»¥ç¡®å®šå®ƒå¦‚ä½•åˆå§‹åŒ–æ•°æ®ï¼ˆæ˜¯å¦éšæœºï¼Ÿæ˜¯å¦åŸºäº `shared_data`ï¼‰**ã€‚

---

### **(3) è®°å½•å½“å‰æœ€ä¼˜æ¢å¤ç»“æœ**
```python
best_candidate = candidate.detach().clone()
minimal_value_so_far = torch.as_tensor(float("inf"), **self.setup)
```
- **`best_candidate`**ï¼šå­˜å‚¨ **æœ€ä¼˜æ¢å¤æ•°æ®**ï¼ˆç”¨äºé€‰å–æœ€å°æŸå¤±æ—¶çš„ `candidate`ï¼‰ã€‚
- **`minimal_value_so_far`**ï¼šåˆå§‹åŒ–ä¸º **æ­£æ— ç©·**ï¼Œç”¨äºè·Ÿè¸ªæœ€å°æŸå¤±ã€‚

---

### **(4) åˆå§‹åŒ–ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨**
```python
optimizer, scheduler = self._init_optimizer([candidate])
```
- **è°ƒç”¨ `_init_optimizer([candidate])`**ï¼š
  - å¯èƒ½è¿”å›ï¼š
    - `optimizer`ï¼ˆä¼˜åŒ–å™¨ï¼Œå¦‚ `Adam`ã€`SGD`ï¼‰ã€‚
    - `scheduler`ï¼ˆå­¦ä¹ ç‡è°ƒåº¦å™¨ï¼‰ã€‚
  
ğŸ“Œ **ä½ éœ€è¦æä¾› `_init_optimizer()` ä»£ç ï¼Œä»¥ç¡®å®šä¼˜åŒ–å™¨çš„é…ç½®æ–¹å¼**ã€‚

---

### **(5) è¿›å…¥ä¼˜åŒ–è¿­ä»£**
```python
current_wallclock = time.time()
try:
    for iteration in range(self.cfg.optim.max_iterations):
```
- **è¿­ä»£ `max_iterations` æ¬¡**ï¼Œä¼˜åŒ– `candidate`ã€‚
- **è®°å½•å¼€å§‹æ—¶é—´**ï¼ˆ`current_wallclock`ï¼‰ï¼Œç”¨äºè®¡ç®—æ—¶é—´æ¶ˆè€—ã€‚

---

### **(6) è®¡ç®—ç›®æ ‡å‡½æ•°å¹¶ä¼˜åŒ–**
```python
closure = self._compute_objective(candidate, labels, rec_model, optimizer, shared_data, iteration)
objective_value, task_loss = optimizer.step(closure), self.current_task_loss
scheduler.step()
```
- **è°ƒç”¨ `_compute_objective()`**ï¼š
  - è®¡ç®—æ¢å¤æŸå¤±ï¼ˆå¯èƒ½åŸºäº `MSE` æˆ– `KL æ•£åº¦`ï¼‰ã€‚
  - è¿”å› `closure` ä¾› `optimizer.step(closure)` è®¡ç®—æ¢¯åº¦ã€‚
- **ä¼˜åŒ–æ­¥éª¤**ï¼š
  - `optimizer.step(closure)`ï¼šæ‰§è¡Œæ¢¯åº¦æ›´æ–°ã€‚
  - `scheduler.step()`ï¼šè°ƒæ•´å­¦ä¹ ç‡ã€‚

ğŸ“Œ **ä½ éœ€è¦æä¾› `_compute_objective()` ä»£ç ï¼Œä»¥ç¡®å®šå¦‚ä½•è®¡ç®—æ¢å¤æŸå¤±**ã€‚

---

### **(7) æŠ•å½±åˆ°åˆæ³•å€¼èŒƒå›´**
```python
with torch.no_grad():
    if self.cfg.optim.boxed:
        candidate.data = torch.max(torch.min(candidate, (1 - self.dm) / self.ds), -self.dm / self.ds)
```
- **ä½œç”¨**ï¼š
  - è‹¥ `self.cfg.optim.boxed = True`ï¼Œåˆ™ **é™åˆ¶æ¢å¤æ•°æ® `candidate` åœ¨åˆæ³•èŒƒå›´å†…**ã€‚
  - ä¾‹å¦‚ï¼š
    - `image` æ•°æ®é€šå¸¸åœ¨ `[0, 1]` ä¹‹é—´ã€‚
    - `text embedding` å¯èƒ½æœ‰ç‰¹å®šèŒƒå›´çº¦æŸã€‚

---

### **(8) è®°å½•æœ€ä¼˜æ¢å¤æ•°æ®**
```python
if objective_value < minimal_value_so_far:
    minimal_value_so_far = objective_value.detach()
    best_candidate = candidate.detach().clone()
```
- **å¦‚æœå½“å‰ `objective_value` æ›´ä¼˜**ï¼š
  - è®°å½•æœ€å°æŸå¤± `minimal_value_so_far`ã€‚
  - æ›´æ–° `best_candidate`ã€‚

---

### **(9) è®°å½•æ—¥å¿—**
```python
if iteration + 1 == self.cfg.optim.max_iterations or iteration % self.cfg.optim.callback == 0:
    timestamp = time.time()
    log.info(
        f"| It: {iteration + 1} | Rec. loss: {objective_value.item():2.4f} | "
        f" Task loss: {task_loss.item():2.4f} | T: {timestamp - current_wallclock:4.2f}s"
    )
    current_wallclock = timestamp
```
- **æ¯ `callback` è½®æ‰“å°æ—¥å¿—**ï¼š
  - **æ¢å¤æŸå¤± `objective_value`**ã€‚
  - **ä»»åŠ¡æŸå¤± `task_loss`**ï¼ˆå¯èƒ½æ˜¯åŸä»»åŠ¡çš„æŸå¤±ï¼‰ã€‚
  - **æ—¶é—´æ¶ˆè€— `T`**ã€‚

---

### **(10) ç»ˆæ­¢æ¡ä»¶**
```python
if not torch.isfinite(objective_value):
    log.info(f"Recovery loss is non-finite in iteration {iteration}. Cancelling reconstruction!")
    break
```
- **è‹¥ `objective_value` å˜ä¸º `NaN` æˆ– `Inf`**ï¼Œåˆ™æå‰ç»ˆæ­¢ã€‚

---

### **(11) è®°å½•ç»Ÿè®¡ä¿¡æ¯**
```python
stats[f"Trial_{trial}_Val"].append(objective_value.item())
```
- è®°å½•å½“å‰ `trial` è¿‡ç¨‹ä¸­çš„ `objective_value`ã€‚

---

### **(12) å¤„ç† `dryrun`**
```python
if dryrun:
    break
```
- è‹¥ `dryrun=True`ï¼Œåˆ™åªè¿è¡Œä¸€æ¬¡å¹¶é€€å‡ºã€‚

---

### **(13) å¤„ç†ä¸­æ–­**
```python
except KeyboardInterrupt:
    print(f"Recovery interrupted manually in iteration {iteration}!")
    pass
```
- æ”¯æŒ **æ‰‹åŠ¨ç»ˆæ­¢æ¢å¤**ï¼ˆ`Ctrl+C`ï¼‰ã€‚

---

### **(14) è¿”å›æœ€ä½³æ¢å¤ç»“æœ**
```python
return best_candidate.detach()
```
- è¿”å› **æœ€ä¼˜æ¢å¤æ•°æ® `best_candidate`**ã€‚

---

## **3. æ€»ç»“**
**`_run_trial` çš„ä¸»è¦åŠŸèƒ½**ï¼š
- **ä¼˜åŒ–æ¢å¤æ•°æ® `candidate`**ï¼Œä½¿å…¶é€¼è¿‘åŸå§‹å®¢æˆ·ç«¯æ•°æ®ã€‚
- **ä½¿ç”¨ `shared_data` å’Œ `labels`** è®¡ç®—ç›®æ ‡å‡½æ•°ã€‚
- **ä¼˜åŒ–æ­¥éª¤**ï¼š
  - `optimizer.step(closure)` è®¡ç®—æ¢¯åº¦å¹¶æ›´æ–° `candidate`ã€‚
  - `scheduler.step()` è°ƒæ•´å­¦ä¹ ç‡ã€‚
- **åº”ç”¨çº¦æŸï¼ˆå¦‚ `boxed` é™åˆ¶ï¼‰** ä»¥ç¡®ä¿æ¢å¤æ•°æ®åˆç†ã€‚
- **è®°å½•æ—¥å¿—å’Œæ¢å¤æŸå¤±**ï¼Œç¡®ä¿å®éªŒå¯å¤ç°ã€‚

ğŸ“Œ **ä½ éœ€è¦æä¾›ä»¥ä¸‹å‡½æ•°çš„ä»£ç ï¼Œä»¥å®Œæˆæ•´ä½“åˆ†æ**ï¼š
1. `self.objective.initialize()`
2. `_initialize_data()`
3. `_init_optimizer()`
4. `_compute_objective()`

---

### **å‡½æ•°è§£æï¼š`_initialize_data`**
è¯¥å‡½æ•°ç”¨äº **åˆå§‹åŒ–æ¢å¤æ•°æ® `candidate`**ï¼Œåœ¨æ”»å‡»ï¼ˆå¦‚æ¢¯åº¦åæ¼”æ”»å‡»ï¼‰ä¸­ï¼Œ`candidate` ä»£è¡¨æ”»å‡»è€… **è¯•å›¾æ¢å¤çš„åŸå§‹æ•°æ®**ã€‚å®ƒçš„åˆå§‹åŒ–æ–¹å¼ä¼šå½±å“æ”»å‡»çš„æ”¶æ•›é€Ÿåº¦å’Œæœ€ç»ˆæ¢å¤çš„è´¨é‡ã€‚

---

## **1. ä»£ç ç»“æ„**
```python
def _initialize_data(self, data_shape):
```
**å‚æ•°**ï¼š
- **`data_shape`**ï¼šæ•°æ®å½¢çŠ¶ï¼Œé€šå¸¸ä¸º `[batch_size, channels, height, width]`ï¼ˆå›¾åƒï¼‰æˆ– `[batch_size, seq_len]`ï¼ˆæ–‡æœ¬ï¼‰ã€‚

**è¿”å›å€¼**ï¼š
- **`candidate`**ï¼šä¸€ä¸ª `torch.Tensor`ï¼ŒåŒ…å«æ¢å¤æ•°æ®çš„åˆå§‹å€¼ï¼Œä¸” **å¼€å¯æ¢¯åº¦è®¡ç®—**ï¼ˆ`requires_grad=True`ï¼‰ã€‚

---

## **2. è¯¦ç»†ä»£ç è§£æ**

### **(1) è¯»å–åˆå§‹åŒ–æ–¹å¼**
```python
init_type = self.cfg.init
```
- `self.cfg.init` å†³å®šåˆå§‹åŒ–æ–¹å¼ï¼Œä¾‹å¦‚ï¼š
  - `randn`ï¼ˆæ­£æ€åˆ†å¸ƒï¼‰
  - `rand`ï¼ˆå‡åŒ€åˆ†å¸ƒï¼‰
  - `zeros`ï¼ˆå…¨é›¶ï¼‰
  - `patterned`ï¼ˆç‰¹å®šæ¨¡å¼ï¼‰
  - `wei`ï¼ˆWei ç­‰äººæå‡ºçš„æ–¹æ³•ï¼‰
  - `red`, `green`, `blue`, `dark`, `light`ï¼ˆé¢œè‰²é€šé“ç‰¹å®šåˆå§‹åŒ–ï¼‰

---

### **(2) å¸¸è§éšæœºåˆå§‹åŒ–**
```python
if init_type == "randn":
    candidate = torch.randn(data_shape, **self.setup)
elif init_type == "randn-trunc":
    candidate = (torch.randn(data_shape, **self.setup) * 0.1).clamp(-0.1, 0.1)
elif init_type == "rand":
    candidate = (torch.rand(data_shape, **self.setup) * 2) - 1.0
elif init_type == "zeros":
    candidate = torch.zeros(data_shape, **self.setup)
```
- **`randn`**ï¼ˆæ­£æ€åˆ†å¸ƒï¼‰ï¼š`N(0,1)`
- **`randn-trunc`**ï¼ˆæˆªæ–­æ­£æ€åˆ†å¸ƒï¼‰ï¼š`N(0, 0.1)`ï¼Œè£å‰ªåˆ° `[-0.1, 0.1]` èŒƒå›´
- **`rand`**ï¼ˆå‡åŒ€åˆ†å¸ƒï¼‰ï¼š`[-1,1]`
- **`zeros`**ï¼ˆå…¨é›¶ï¼‰ï¼š`0`

è¿™äº›æ–¹å¼ä¸»è¦ç”¨äº**å›¾åƒæˆ–æ–‡æœ¬åµŒå…¥æ¢å¤æ”»å‡»**ï¼Œé€šè¿‡æ¢¯åº¦ä¼˜åŒ–è°ƒæ•´ `candidate` é€¼è¿‘çœŸå®æ•°æ®ã€‚

---

### **(3) é¢œè‰²é€šé“ç‰¹å®šåˆå§‹åŒ–**
```python
elif any(c in init_type for c in ["red", "green", "blue", "dark", "light"]):
    candidate = torch.zeros(data_shape, **self.setup)
    if "light" in init_type:
        candidate = torch.ones(data_shape, **self.setup)
    else:
        nonzero_channel = 0 if "red" in init_type else 1 if "green" in init_type else 2
        candidate[:, nonzero_channel, :, :] = 1
    if "-true" in init_type:
        candidate = (candidate - self.dm) / self.ds
```
- **é€‚ç”¨äº RGB å›¾åƒæ•°æ®**ï¼š
  - `"red"`ï¼šçº¢è‰²é€šé“è®¾ä¸º `1`ï¼Œå…¶ä»–é€šé“ `0`ã€‚
  - `"green"`ï¼šç»¿è‰²é€šé“è®¾ä¸º `1`ï¼Œå…¶ä»–é€šé“ `0`ã€‚
  - `"blue"`ï¼šè“è‰²é€šé“è®¾ä¸º `1`ï¼Œå…¶ä»–é€šé“ `0`ã€‚
  - `"dark"`ï¼šåˆå§‹åŒ–ä¸º **å…¨é›¶**ã€‚
  - `"light"`ï¼šåˆå§‹åŒ–ä¸º **å…¨ä¸€**ã€‚

- **`"-true"` é€‰é¡¹**ï¼š
  - è‹¥ `init_type` ç»“å°¾åŒ…å« `-true`ï¼Œåˆ™ **åº”ç”¨ `self.dm` å’Œ `self.ds` è¿›è¡Œå½’ä¸€åŒ–**ã€‚

---

### **(4) ç‰¹å®šæ¨¡å¼åˆå§‹åŒ–**
```python
elif "patterned" in init_type:
    pattern_width = int("".join(filter(str.isdigit, init_type)))
    if "randn" in init_type:
        seed = torch.randn([data_shape[0], 3, pattern_width, pattern_width], **self.setup)
    elif "rand" in init_type:
        seed = (torch.rand([data_shape[0], 3, pattern_width, pattern_width], **self.setup) * 2) - 1
    else:
        seed = torch.randn([data_shape[0], 3, pattern_width, pattern_width], **self.setup)
    
    x_factor, y_factor = (
        torch.as_tensor(data_shape[2] / pattern_width).ceil(),
        torch.as_tensor(data_shape[3] / pattern_width).ceil(),
    )
    candidate = (
        torch.tile(seed, (1, 1, int(x_factor), int(y_factor)))[:, :, : data_shape[2], : data_shape[3]]
        .contiguous()
        .clone()
    )
```
- **é€‚ç”¨äºå›¾åƒæ•°æ®**
- **æ€è·¯**ï¼š
  1. ç”Ÿæˆä¸€ä¸ª **`pattern_width x pattern_width`** å¤§å°çš„éšæœºå™ªå£°å›¾æ¡ˆï¼ˆ`seed`ï¼‰ã€‚
  2. **é‡å¤æ‰©å±• `seed`** ä½¿å…¶åŒ¹é… `data_shape`ã€‚
  3. **ä½¿ç”¨ `.tile()`** æ–¹æ³•è¿›è¡Œæ‰©å±•ï¼Œä½¿å…¶å…·æœ‰ **è§„åˆ™æ¨¡å¼**ã€‚

- **é€‚ç”¨åœºæ™¯**ï¼š
  - **éšç§ä¿æŠ¤è¯„ä¼°**ï¼ˆWei et al., 2020 æå‡ºçš„è¯„ä¼°æ¡†æ¶ï¼‰ã€‚
  - **å¯è§†åŒ–æ”»å‡»æ•ˆæœ**ï¼Œé€šè¿‡æ¨¡å¼åˆå§‹åŒ–è§‚å¯Ÿæ¢¯åº¦åæ¼”æ•ˆæœã€‚

---

### **(5) `wei` åˆå§‹åŒ–**
```python
elif "wei" in init_type:
    pattern_width = int("".join(filter(str.isdigit, init_type)))
    if "rand" in init_type:
        seed = (torch.rand([data_shape[0], 3, pattern_width, pattern_width], **self.setup) * 2) - 1
    else:
        seed = torch.randn([data_shape[0], 3, pattern_width, pattern_width], **self.setup)
    
    x_factor, y_factor = (
        torch.as_tensor(data_shape[2] / pattern_width).ceil(),
        torch.as_tensor(data_shape[3] / pattern_width).ceil(),
    )
    candidate = (
        torch.tile(seed, (1, 1, int(x_factor), int(y_factor)))[:, :, : data_shape[2], : data_shape[3]]
        .contiguous()
        .clone()
    )
```
- **ç±»ä¼¼ `patterned` åˆå§‹åŒ–**ï¼Œä½†å¯èƒ½ç”¨äºä¸åŒå®éªŒã€‚
- **ç›®çš„**ï¼š
  - ç”Ÿæˆ **å±€éƒ¨ä¸€è‡´çš„åˆå§‹åŒ–**ï¼Œæµ‹è¯•ä¸åŒæ”»å‡»æ–¹æ¡ˆå¯¹åˆå§‹åŒ–çš„æ•æ„Ÿæ€§ã€‚

---

### **(6) å¤„ç†æœªçŸ¥åˆå§‹åŒ–æ–¹å¼**
```python
else:
    raise ValueError(f"Unknown initialization scheme {init_type} given.")
```
- **è‹¥ `init_type` ä¸æ˜¯å·²çŸ¥ç±»å‹**ï¼ŒæŠ›å‡ºé”™è¯¯ã€‚

---

### **(7) ä½¿ `candidate` å¯è®­ç»ƒ**
```python
candidate.to(memory_format=self.memory_format)
candidate.requires_grad = True
candidate.grad = torch.zeros_like(candidate)
```
- **ç¡®ä¿ `candidate` åœ¨ GPU/CPU ä¸Šçš„æ­£ç¡®æ ¼å¼**ã€‚
- **å¼€å¯æ¢¯åº¦è®¡ç®—**ï¼š
  - `candidate.requires_grad = True`ï¼Œè¿™æ ·æ¢¯åº¦åæ¼”æ”»å‡»å¯ä»¥ä¼˜åŒ–å®ƒã€‚
- **åˆå§‹åŒ–æ¢¯åº¦**ï¼š
  - `candidate.grad = torch.zeros_like(candidate)` ç¡®ä¿æ¢¯åº¦ä¸ä¼šæ˜¯ `None`ã€‚

---

## **3. æ€»ç»“**
### **ä¸»è¦åŠŸèƒ½**
- **åˆå§‹åŒ–æ¢å¤æ•°æ® `candidate`**ï¼Œä½œä¸ºæ”»å‡»ç›®æ ‡ã€‚
- **æ”¯æŒå¤šç§åˆå§‹åŒ–æ–¹å¼**ï¼š
  - **éšæœºåˆå§‹åŒ–**ï¼ˆ`randn`, `rand`, `zeros`ï¼‰
  - **RGB é¢œè‰²åˆå§‹åŒ–**ï¼ˆ`red`, `green`, `blue`ï¼‰
  - **æ¨¡å¼åŒ–åˆå§‹åŒ–**ï¼ˆ`patterned`, `wei`ï¼‰
- **ä¿è¯ `candidate` å¯è®­ç»ƒ**ï¼š
  - è®¾å®š `requires_grad=True`ï¼Œæ”¯æŒæ¢¯åº¦ä¼˜åŒ–ã€‚

### **é€‚ç”¨åœºæ™¯**
- **æ¢¯åº¦åæ¼”æ”»å‡»**ï¼šå°è¯•æ¢å¤å›¾åƒ/æ–‡æœ¬è¾“å…¥ã€‚
- **éšç§ä¿æŠ¤è¯„ä¼°**ï¼šæµ‹è¯•ä¸åŒåˆå§‹åŒ–å¯¹æ”»å‡»æ•ˆæœçš„å½±å“ã€‚
- **æ•°æ®æ¢å¤ä¼˜åŒ–**ï¼šç»“åˆ `_run_trial()` è¿›è¡Œä¼˜åŒ–ï¼Œä½¿ `candidate` é€¼è¿‘çœŸå®æ•°æ®ã€‚

ğŸ“Œ **ä½ å¯ä»¥æä¾› `self.cfg.init` çš„å¯èƒ½å€¼ï¼Œç¡®è®¤æ˜¯å¦æœ‰å…¶ä»–ç‰¹æ®Šåˆå§‹åŒ–æ–¹å¼ã€‚**